{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "999ea11e",
   "metadata": {},
   "source": [
    "### Import libraries, define helper functions, load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e401a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6) # Set default figure size\n",
    "plt.rcParams['figure.dpi'] = 100 # Set default dots per inch for resolution\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b1c0f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Helper Functions Defined ---\n"
     ]
    }
   ],
   "source": [
    "def load_csv(filepath, name, header_row=0, skip_rows_list=None):\n",
    "    \"\"\"\n",
    "    Loads a CSV file (typically Census data) with error handling and basic column cleanup.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, header=header_row, skiprows=skip_rows_list)\n",
    "        print(f\"{name} loaded successfully from: {filepath}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {name} file not found at {filepath}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {name} data from {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to load GeoJSON/Shapefiles\n",
    "def load_geo_data(filepath, name):\n",
    "    try:\n",
    "        gdf = gpd.read_file(filepath)\n",
    "        print(f\"{name} loaded successfully from: {filepath}\")\n",
    "        return gdf\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {name} file not found at {filepath}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {name} data from {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"--- Helper Functions Defined ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383023ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COTA Bus Stops loaded successfully from: ../data/COTA/Stops_2023_09.shp\n",
      "Decennial DHC2020.P1 loaded successfully from: ../data/US_Census/DECENNIALDHC2020.P1-Data.csv\n",
      "ACS S0101 (Age and Sex) loaded successfully from: ../data/US_Census/ACSST5Y2023.S0101-Data.csv\n",
      "ACS B08101 (Transportation by Age) loaded successfully from: ../data/US_Census/ACSDT5Y2023.B08101-Data.csv\n",
      "ACS B08119 (Transportation by Earnings) loaded successfully from: ../data/US_Census/ACSDT5Y2023.B08119-Data.csv\n",
      "ACS B08122 (Transportation by Poverty) loaded successfully from: ../data/US_Census/ACSDT5Y2023.B08122-Data.csv\n",
      "ACS B08141 (Vehicles Available) loaded successfully from: ../data/US_Census/ACSDT5Y2023.B08141-Data.csv\n",
      "MORPC TAZ Forecasts loaded successfully from: ../data/MORPC/TAZ20_OfficialMTP2024_Forecasts.shp\n",
      "Columbus Building Permits loaded successfully from: ../data/City_of_Columbus/BuildingPermits.shp\n",
      "FTA Monthly Ridership data loaded successfully from: ../data/FTA/May2025_RawMonthlyRidership.xlsx\n",
      "\n",
      "--- All Data Loading Attempts Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Load COTA Bus Stops Data ---\n",
    "cota_stops_path = \"../data/COTA/Stops_2023_09.shp\"\n",
    "cota_stops_gdf = load_geo_data(cota_stops_path, \"COTA Bus Stops\")\n",
    "\n",
    "# --- Load Decennial Census 2020 DHC.P1 Data ---\n",
    "decennial_dhc_p1_path = \"../data/US_Census/DECENNIALDHC2020.P1-Data.csv\"\n",
    "decennial_dhc_p1_df = load_csv(decennial_dhc_p1_path, \"Decennial DHC2020.P1\", 1)\n",
    "\n",
    "# --- Load ACS 5-Year Estimate: S0101 (Age and Sex) ---\n",
    "acs_s0101_path = \"../data/US_Census/ACSST5Y2023.S0101-Data.csv\"\n",
    "acs_s0101_df = load_csv(acs_s0101_path, \"ACS S0101 (Age and Sex)\", 1)\n",
    "\n",
    "# --- Load ACS 5-Year Estimate: B08101 (Means of Transportation to Work by Age) ---\n",
    "acs_b08101_path = \"../data/US_Census/ACSDT5Y2023.B08101-Data.csv\"\n",
    "acs_b08101_df = load_csv(acs_b08101_path, \"ACS B08101 (Transportation by Age)\", 1)\n",
    "\n",
    "# --- Load ACS 5-Year Estimate: B08119 (Means of Transportation to Work by Workers' Earnings) ---\n",
    "acs_b08119_path = \"../data/US_Census/ACSDT5Y2023.B08119-Data.csv\"\n",
    "acs_b08119_df = load_csv(acs_b08119_path, \"ACS B08119 (Transportation by Earnings)\", 1)\n",
    "\n",
    "# --- Load ACS 5-Year Estimate: B08122 (Means of Transportation to Work by Poverty Status) ---\n",
    "acs_b08122_path = \"../data/US_Census/ACSDT5Y2023.B08122-Data.csv\"\n",
    "acs_b08122_df = load_csv(acs_b08122_path, \"ACS B08122 (Transportation by Poverty)\", 1)\n",
    "\n",
    "# --- Load ACS 5-Year Estimate: B08141 (Means of Transportation to Work by Vehicles Available) ---\n",
    "acs_b08141_path = \"../data/US_Census/ACSDT5Y2023.B08141-Data.csv\"\n",
    "acs_b08141_df = load_csv(acs_b08141_path, \"ACS B08141 (Vehicles Available)\", 1)\n",
    "\n",
    "# --- Load MORPC TAZ Forecast Data ---\n",
    "morpc_taz_path = \"../data/MORPC/TAZ20_OfficialMTP2024_Forecasts.shp\"\n",
    "morpc_taz_gdf = load_geo_data(morpc_taz_path, \"MORPC TAZ Forecasts\")\n",
    "\n",
    "# --- Load City of Columbus Building Permits Data ---\n",
    "columbus_permits_path = \"../data/City_of_Columbus/BuildingPermits.shp\"\n",
    "columbus_permits_gdf = load_geo_data(columbus_permits_path, \"Columbus Building Permits\")\n",
    "\n",
    "# --- Load FTA Monthly Ridership Data ---\n",
    "fta_ridership_path = \"../data/FTA/May2025_RawMonthlyRidership.xlsx\"\n",
    "try:\n",
    "    fta_ridership_df = pd.read_excel(fta_ridership_path, skiprows=0)\n",
    "    print(f\"FTA Monthly Ridership data loaded successfully from: {fta_ridership_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: FTA Monthly Ridership file not found at {fta_ridership_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading FTA Monthly Ridership data from {fta_ridership_path}: {e}\")\n",
    "    \n",
    "print(\"\\n--- All Data Loading Attempts Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a36178",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5138fa",
   "metadata": {},
   "source": [
    "#### Cleaning COTA bus stops data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6d3b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initial Inspection: COTA Stops GDF ---\n",
      "['StopId', 'StopAbbr', 'StopName', 'OnStreet', 'AtStreet', 'InService_', 'Shelter', 'Lighting', 'Garbage', 'Ons_2023_0', 'Offs_2023_', 'Jurisdicti', 'Ons_2023_1', 'Offs_20231', 'Ons_2023_2', 'Offs_20232', 'Amenity_Ow', 'GlobalID', 'Ons_2024_0', 'Offs_2024_', 'Lines_Serv', 'Ons_2024_1', 'Offs_20241', 'Ons_2024_2', 'Offs_20242', 'geometry']\n",
      "\n",
      "Raw Data Types and Non-Null Counts:\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 2966 entries, 0 to 2965\n",
      "Data columns (total 26 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   StopId      2966 non-null   int64   \n",
      " 1   StopAbbr    2966 non-null   object  \n",
      " 2   StopName    2966 non-null   object  \n",
      " 3   OnStreet    2966 non-null   object  \n",
      " 4   AtStreet    2749 non-null   object  \n",
      " 5   InService_  2966 non-null   object  \n",
      " 6   Shelter     2966 non-null   object  \n",
      " 7   Lighting    2965 non-null   object  \n",
      " 8   Garbage     2966 non-null   object  \n",
      " 9   Ons_2023_0  2966 non-null   int64   \n",
      " 10  Offs_2023_  2966 non-null   int64   \n",
      " 11  Jurisdicti  2965 non-null   object  \n",
      " 12  Ons_2023_1  2966 non-null   int64   \n",
      " 13  Offs_20231  2966 non-null   int64   \n",
      " 14  Ons_2023_2  2966 non-null   int64   \n",
      " 15  Offs_20232  2966 non-null   int64   \n",
      " 16  Amenity_Ow  2965 non-null   object  \n",
      " 17  GlobalID    2966 non-null   object  \n",
      " 18  Ons_2024_0  2966 non-null   int64   \n",
      " 19  Offs_2024_  2966 non-null   int64   \n",
      " 20  Lines_Serv  2964 non-null   object  \n",
      " 21  Ons_2024_1  2966 non-null   float64 \n",
      " 22  Offs_20241  2966 non-null   float64 \n",
      " 23  Ons_2024_2  2966 non-null   float64 \n",
      " 24  Offs_20242  2966 non-null   float64 \n",
      " 25  geometry    2966 non-null   geometry\n",
      "dtypes: float64(4), geometry(1), int64(9), object(12)\n",
      "memory usage: 602.6+ KB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "StopId          0\n",
      "StopAbbr        0\n",
      "StopName        0\n",
      "OnStreet        0\n",
      "AtStreet      217\n",
      "InService_      0\n",
      "Shelter         0\n",
      "Lighting        1\n",
      "Garbage         0\n",
      "Ons_2023_0      0\n",
      "Offs_2023_      0\n",
      "Jurisdicti      1\n",
      "Ons_2023_1      0\n",
      "Offs_20231      0\n",
      "Ons_2023_2      0\n",
      "Offs_20232      0\n",
      "Amenity_Ow      1\n",
      "GlobalID        0\n",
      "Ons_2024_0      0\n",
      "Offs_2024_      0\n",
      "Lines_Serv      2\n",
      "Ons_2024_1      0\n",
      "Offs_20241      0\n",
      "Ons_2024_2      0\n",
      "Offs_20242      0\n",
      "geometry        0\n",
      "dtype: int64\n",
      "\n",
      "First 5 rows of ACS S0101 Raw Data:\n",
      "   StopId  StopAbbr                         StopName  \\\n",
      "0    8076  HERCOLWB   HERITAGE CLUB DR & COLONIAL DR   \n",
      "1    6842   MAISCIS        MAIN ST & SCIOTO DARBY RD   \n",
      "2    8077   HERMAIE       HERITAGE CLUB DR & MAIN ST   \n",
      "3    6841   MAISCIN  MAIN ST & SCIOTO DARBY CREEK RD   \n",
      "4    3334   MAILUTS              MAIN ST & LUTHER LN   \n",
      "\n",
      "                         OnStreet          AtStreet InService_ Shelter  \\\n",
      "0  HERITAGE CLUB DR & COLONIAL DR              None          1      No   \n",
      "1                         MAIN ST   SCIOTO DARBY RD          1     Yes   \n",
      "2                HERITAGE CLUB DR  HILLIARD ROME RD          1      No   \n",
      "3                         MAIN ST   SCIOTO DARBY RD          1      No   \n",
      "4                         MAIN ST         LUTHER LN          1      No   \n",
      "\n",
      "  Lighting Garbage  Ons_2023_0  ...  Amenity_Ow  \\\n",
      "0       No       0           3  ...  COTA Owned   \n",
      "1       No       1          10  ...  COTA Owned   \n",
      "2       No       0           7  ...  COTA Owned   \n",
      "3       No       0           4  ...  COTA Owned   \n",
      "4       No       0           4  ...  COTA Owned   \n",
      "\n",
      "                               GlobalID  Ons_2024_0  Offs_2024_  \\\n",
      "0  07992ba9-fa51-4db0-8f74-5e41fbb4842a           4           4   \n",
      "1  1f0566e6-206c-4cc0-8c5c-3a61b12ad209          14          13   \n",
      "2  d4cb86cb-777a-4f92-9ec8-6252caff0594           6           6   \n",
      "3  d09443d3-990c-4dd2-98e0-7727e20cac77           6           7   \n",
      "4  6b6c9bd5-86ce-41aa-85ec-781e31c510c2           2           0   \n",
      "\n",
      "      Lines_Serv  Ons_2024_1 Offs_20241 Ons_2024_2  Offs_20242  \\\n",
      "0       032, 071         5.5        5.5        4.8         6.2   \n",
      "1  021, 032, 071        16.2       13.1       17.2        12.9   \n",
      "2       032, 071         9.0        7.2       10.2         8.8   \n",
      "3  021, 032, 071         6.8        8.1        6.2         7.9   \n",
      "4       021, 071         2.5        0.9        2.3         1.1   \n",
      "\n",
      "                     geometry  \n",
      "0  POINT (-83.16265 40.02516)  \n",
      "1  POINT (-83.16106 40.02766)  \n",
      "2  POINT (-83.16098 40.02215)  \n",
      "3  POINT (-83.16076 40.02728)  \n",
      "4  POINT (-83.16027 40.02259)  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Initial Inspection: COTA Stops GDF ---\")\n",
    "print(cota_stops_gdf.columns.tolist()) # List all raw column names\n",
    "\n",
    "print(\"\\nRaw Data Types and Non-Null Counts:\")\n",
    "print(cota_stops_gdf.info()) # Get info for raw DataFrame\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(cota_stops_gdf.isnull().sum()) # Count missing values per column\n",
    "\n",
    "print(\"\\nFirst 5 rows of ACS S0101 Raw Data:\")\n",
    "print(cota_stops_gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359d9509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cleaning COTA Bus Stops Data ---\n",
      "Columns renamed.\n",
      "Amenity columns converted to 0/1.\n",
      "Missing values handled.\n",
      "stop_id converted to string.\n",
      "Dropped unneccesary columns.\n",
      "\n",
      "--- COTA Bus Stops Data Cleaned ---\n",
      "Cleaned COTA Stops DataFrame Info (verify types and non-nulls):\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 2966 entries, 0 to 2965\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   stop_id            2966 non-null   object  \n",
      " 1   stop_abbr          2966 non-null   object  \n",
      " 2   stop_name          2966 non-null   object  \n",
      " 3   on_street          2966 non-null   object  \n",
      " 4   at_street          2966 non-null   object  \n",
      " 5   has_shelter        2966 non-null   int32   \n",
      " 6   has_lighting       2966 non-null   int32   \n",
      " 7   has_garbage_can    2966 non-null   int32   \n",
      " 8   onboards_2023_T1   2966 non-null   int64   \n",
      " 9   offboards_2023_T1  2966 non-null   int64   \n",
      " 10  jurisdiction       2966 non-null   object  \n",
      " 11  onboards_2023_T2   2966 non-null   int64   \n",
      " 12  offboards_2023_T2  2966 non-null   int64   \n",
      " 13  onboards_2023_T3   2966 non-null   int64   \n",
      " 14  offboards_2023_T3  2966 non-null   int64   \n",
      " 15  onboards_2024_T1   2966 non-null   int64   \n",
      " 16  offboards_2024_T1  2966 non-null   int64   \n",
      " 17  lines_served       2966 non-null   object  \n",
      " 18  onboards_2024_T2   2966 non-null   float64 \n",
      " 19  offboards_2024_T2  2966 non-null   float64 \n",
      " 20  onboards_2024_T3   2966 non-null   float64 \n",
      " 21  offboards_2024_T3  2966 non-null   float64 \n",
      " 22  geometry           2966 non-null   geometry\n",
      "dtypes: float64(4), geometry(1), int32(3), int64(8), object(7)\n",
      "memory usage: 498.3+ KB\n",
      "None\n",
      "\n",
      "Cleaned COTA Stops Head (first few rows to verify cleanliness):\n",
      "  stop_id stop_abbr                        stop_name  \\\n",
      "0    8076  HERCOLWB   HERITAGE CLUB DR & COLONIAL DR   \n",
      "1    6842   MAISCIS        MAIN ST & SCIOTO DARBY RD   \n",
      "2    8077   HERMAIE       HERITAGE CLUB DR & MAIN ST   \n",
      "3    6841   MAISCIN  MAIN ST & SCIOTO DARBY CREEK RD   \n",
      "4    3334   MAILUTS              MAIN ST & LUTHER LN   \n",
      "\n",
      "                        on_street         at_street  has_shelter  \\\n",
      "0  HERITAGE CLUB DR & COLONIAL DR           Unknown            0   \n",
      "1                         MAIN ST   SCIOTO DARBY RD            1   \n",
      "2                HERITAGE CLUB DR  HILLIARD ROME RD            0   \n",
      "3                         MAIN ST   SCIOTO DARBY RD            0   \n",
      "4                         MAIN ST         LUTHER LN            0   \n",
      "\n",
      "   has_lighting  has_garbage_can  onboards_2023_T1  offboards_2023_T1  ...  \\\n",
      "0             0                0                 3                  4  ...   \n",
      "1             0                1                10                  8  ...   \n",
      "2             0                0                 7                  5  ...   \n",
      "3             0                0                 4                  8  ...   \n",
      "4             0                0                 4                  1  ...   \n",
      "\n",
      "  onboards_2023_T3  offboards_2023_T3  onboards_2024_T1  offboards_2024_T1  \\\n",
      "0                5                  5                 4                  4   \n",
      "1               11                  9                14                 13   \n",
      "2               10                  8                 6                  6   \n",
      "3                5                  6                 6                  7   \n",
      "4                2                  1                 2                  0   \n",
      "\n",
      "    lines_served  onboards_2024_T2  offboards_2024_T2 onboards_2024_T3  \\\n",
      "0       032, 071               5.5                5.5              4.8   \n",
      "1  021, 032, 071              16.2               13.1             17.2   \n",
      "2       032, 071               9.0                7.2             10.2   \n",
      "3  021, 032, 071               6.8                8.1              6.2   \n",
      "4       021, 071               2.5                0.9              2.3   \n",
      "\n",
      "   offboards_2024_T3                    geometry  \n",
      "0                6.2  POINT (-83.16265 40.02516)  \n",
      "1               12.9  POINT (-83.16106 40.02766)  \n",
      "2                8.8  POINT (-83.16098 40.02215)  \n",
      "3                7.9  POINT (-83.16076 40.02728)  \n",
      "4                1.1  POINT (-83.16027 40.02259)  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "Unique values in final cleaned amenity columns (should be [0, 1]):\n",
      "has_shelter: [0 1]\n",
      "has_lighting: [0 1]\n",
      "has_garbage_can: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# --- Clean COTA Bus Stops Data ---\n",
    "print(\"--- Cleaning COTA Bus Stops Data ---\")\n",
    "if cota_stops_gdf is not None:\n",
    "    # 1. Standardize All Column Names\n",
    "    cota_stops_gdf = cota_stops_gdf.rename(columns={\n",
    "        'StopId': 'stop_id',\n",
    "        'StopAbbr': 'stop_abbr',\n",
    "        'StopName': 'stop_name',\n",
    "        'OnStreet': 'on_street',\n",
    "        'AtStreet': 'at_street',\n",
    "        'InService_': 'in_service',\n",
    "        'Jurisdicti': 'jurisdiction',\n",
    "        'Amenity_Ow': 'amenity_owner',\n",
    "        'Lines_Serv': 'lines_served',\n",
    "        \n",
    "        'Shelter': 'has_shelter',\n",
    "        'Lighting': 'has_lighting',\n",
    "        'Garbage': 'has_garbage_can',\n",
    "\n",
    "        # ------- Ridership Columns (Onboards) -------\n",
    "        # Avg Daily Onboardings January 2023 Trimester\n",
    "        'Ons_2023_0': 'onboards_2023_T1',\n",
    "        # Avg Daily Onboardings May 2023 Trimester\n",
    "        'Ons_2023_1': 'onboards_2023_T2',\n",
    "        # Avg Daily Onboardings September 2023 Trimester\n",
    "        'Ons_2023_2': 'onboards_2023_T3',\n",
    "        \n",
    "        # Avg Daily Onboardings January 2024 Trimester\n",
    "        'Ons_2024_0': 'onboards_2024_T1',\n",
    "        # Avg Daily Onboardings May 2024 Trimester\n",
    "        'Ons_2024_1': 'onboards_2024_T2',\n",
    "        # Avg Daily Onboardings September 2024 Trimester\n",
    "        'Ons_2024_2': 'onboards_2024_T3',\n",
    "\n",
    "        # ------- Ridership Columns (Offboards) -------\n",
    "        # Avg Daily Alightings January 2023 Trimester\n",
    "        'Offs_2023_': 'offboards_2023_T1',\n",
    "        # Avg Daily Alightings May 2023 Trimester\n",
    "        'Offs_20231': 'offboards_2023_T2',\n",
    "        # Avg Daily Alightings September 2023 Trimester\n",
    "        'Offs_20232': 'offboards_2023_T3',\n",
    "\n",
    "        # Avg Daily Alightings January 2024 Trimester\n",
    "        'Offs_2024_': 'offboards_2024_T1',\n",
    "        # Avg Daily Alightings May 2024 Trimester\n",
    "        'Offs_20241': 'offboards_2024_T2',\n",
    "        # Avg Daily Alightings September 2024 Trimester\n",
    "        'Offs_20242': 'offboards_2024_T3',\n",
    "    })\n",
    "    print(\"Columns renamed.\")\n",
    "\n",
    "    # 2. Convert Amenity Columns to Binary\n",
    "    # For 'has_shelter'\n",
    "    cota_stops_gdf['has_shelter'] = cota_stops_gdf['has_shelter'].map({'Yes': 1, 'No': 0}).fillna(0).astype(int)\n",
    "\n",
    "    # For 'has_lighting'\n",
    "    cota_stops_gdf['has_lighting'] = cota_stops_gdf['has_lighting'].replace({'Solar': 'Yes', 'Other': 'Yes', 'CMAX': 'Yes'})\n",
    "    cota_stops_gdf['has_lighting'] = cota_stops_gdf['has_lighting'].map({'Yes': 1, 'No': 0}).fillna(0).astype(int)\n",
    "\n",
    "    # For 'has_garbage_can': Convert to int\n",
    "    cota_stops_gdf['has_garbage_can'] = pd.to_numeric(cota_stops_gdf['has_garbage_can'], errors='coerce').fillna(0).astype(int)\n",
    "    print(\"Amenity columns converted to 0/1.\")\n",
    "\n",
    "    # 3. Handle Missing Values\n",
    "    # Fill 'at_street' with 'Unknown' for stops not at intersections\n",
    "    cota_stops_gdf['at_street'] = cota_stops_gdf['at_street'].fillna('Unknown')\n",
    "    \n",
    "    # Fill remaining small number of missing values for categorical columns with 'Unknown'\n",
    "    for col in ['jurisdiction', 'lines_served']:\n",
    "        if cota_stops_gdf[col].isnull().any(): # Only process if missing values exist\n",
    "            cota_stops_gdf[col] = cota_stops_gdf[col].fillna('Unknown')\n",
    "    print(\"Missing values handled.\")\n",
    "\n",
    "    # 4. Convert StopId to object\n",
    "    cota_stops_gdf['stop_id'] = cota_stops_gdf['stop_id'].astype(str)\n",
    "    print(\"stop_id converted to string.\")\n",
    "\n",
    "    # 5. Drop Unnecessary Columns\n",
    "    cota_stops_gdf = cota_stops_gdf.drop(columns=['amenity_owner'])\n",
    "    cota_stops_gdf = cota_stops_gdf.drop(columns=['in_service'])\n",
    "    cota_stops_gdf = cota_stops_gdf.drop(columns=['GlobalID'])\n",
    "    print(\"Dropped unneccesary columns.\")\n",
    "\n",
    "    print(\"\\n--- COTA Bus Stops Data Cleaned ---\")\n",
    "    print(\"Cleaned COTA Stops DataFrame Info (verify types and non-nulls):\")\n",
    "    print(cota_stops_gdf.info())\n",
    "    print(\"\\nCleaned COTA Stops Head (first few rows to verify cleanliness):\")\n",
    "    print(cota_stops_gdf.head())\n",
    "    print(\"\\nUnique values in final cleaned amenity columns (should be [0, 1]):\")\n",
    "    print(\"has_shelter:\", cota_stops_gdf['has_shelter'].unique())\n",
    "    print(\"has_lighting:\", cota_stops_gdf['has_lighting'].unique())\n",
    "    print(\"has_garbage_can:\", cota_stops_gdf['has_garbage_can'].unique())\n",
    "\n",
    "else:\n",
    "    print(\"COTA Bus Stops GeoDataFrame not loaded. Cleaning skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be083b83",
   "metadata": {},
   "source": [
    "#### Cleaning ACS_S0101 (Age and Sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Initial Inspection: ACS S0101 ---\")\n",
    "print(\"\\nACS S0101 Raw Columns:\")\n",
    "print(acs_s0101_df.columns.tolist()) # List all raw column names\n",
    "\n",
    "print(\"\\nACS S0101 Raw Data Types and Non-Null Counts:\")\n",
    "print(acs_s0101_df.info()) # Get info for raw DataFrame\n",
    "\n",
    "print(\"\\nMissing Values in ACS S0101 Raw Data:\")\n",
    "print(acs_s0101_df.isnull().sum()) # Count missing values per column\n",
    "\n",
    "print(\"\\nFirst 5 rows of ACS S0101 Raw Data:\")\n",
    "print(acs_s0101_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f61812c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cleaning ACS S0101 Data ---\n",
      "Dropped 'Unnamed: 458' column.\n",
      "Dropped 348 error/percentage/allocation columns initially.\n",
      "Columns renamed using direct mapping.\n",
      "All relevant population columns converted to numeric.\n",
      "NaN values filled with 0.\n",
      "\n",
      "--- Performing Age Group Feature Engineering ---\n",
      "Created 'pop_age_5_to_14' column.\n",
      "Filtered to 37 final key population columns.\n",
      "\n",
      "--- ACS S0101 Data Cleaned ---\n",
      "Cleaned ACS S0101 DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 328 entries, 0 to 327\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   geo_id                                328 non-null    object \n",
      " 1   geographic_area_name                  328 non-null    object \n",
      " 2   pop_total                             328 non-null    int64  \n",
      " 3   pop_age_under_5                       328 non-null    int64  \n",
      " 4   pop_age_15_to_19                      328 non-null    int64  \n",
      " 5   pop_age_20_to_24                      328 non-null    int64  \n",
      " 6   pop_age_25_to_29                      328 non-null    int64  \n",
      " 7   pop_age_30_to_34                      328 non-null    int64  \n",
      " 8   pop_age_35_to_39                      328 non-null    int64  \n",
      " 9   pop_age_40_to_44                      328 non-null    int64  \n",
      " 10  pop_age_45_to_49                      328 non-null    int64  \n",
      " 11  pop_age_50_to_54                      328 non-null    int64  \n",
      " 12  pop_age_55_to_59                      328 non-null    int64  \n",
      " 13  pop_age_60_to_64                      328 non-null    int64  \n",
      " 14  pop_age_65_to_69                      328 non-null    int64  \n",
      " 15  pop_age_70_to_74                      328 non-null    int64  \n",
      " 16  pop_age_75_to_79                      328 non-null    int64  \n",
      " 17  pop_age_80_to_84                      328 non-null    int64  \n",
      " 18  pop_age_85_plus                       328 non-null    int64  \n",
      " 19  pop_selected_age_under_18             328 non-null    int64  \n",
      " 20  pop_selected_age_18_to_24             328 non-null    int64  \n",
      " 21  pop_selected_age_15_to_44             328 non-null    int64  \n",
      " 22  pop_selected_age_16_plus              328 non-null    int64  \n",
      " 23  pop_selected_age_18_plus              328 non-null    int64  \n",
      " 24  pop_selected_age_21_plus              328 non-null    int64  \n",
      " 25  pop_selected_age_60_plus              328 non-null    int64  \n",
      " 26  pop_selected_age_62_plus              328 non-null    int64  \n",
      " 27  pop_selected_age_65_plus              328 non-null    int64  \n",
      " 28  pop_selected_age_75_plus              328 non-null    int64  \n",
      " 29  summary_ind_median_age_years          328 non-null    float64\n",
      " 30  summary_ind_sex_ratio                 328 non-null    float64\n",
      " 31  summary_ind_age_dependency_ratio      328 non-null    float64\n",
      " 32  summary_ind_old_age_dependency_ratio  328 non-null    float64\n",
      " 33  summary_ind_child_dependency_ratio    328 non-null    float64\n",
      " 34  male_pop_total                        328 non-null    int64  \n",
      " 35  female_pop_total                      328 non-null    int64  \n",
      " 36  pop_age_5_to_14                       328 non-null    int64  \n",
      "dtypes: float64(5), int64(30), object(2)\n",
      "memory usage: 94.9+ KB\n",
      "None\n",
      "\n",
      "Cleaned ACS S0101 Head:\n",
      "                 geo_id                      geographic_area_name  pop_total  \\\n",
      "0  1400000US39049000110  Census Tract 1.10; Franklin County; Ohio       3354   \n",
      "1  1400000US39049000120  Census Tract 1.20; Franklin County; Ohio       3307   \n",
      "2  1400000US39049000210  Census Tract 2.10; Franklin County; Ohio       3116   \n",
      "3  1400000US39049000220  Census Tract 2.20; Franklin County; Ohio       4183   \n",
      "4  1400000US39049000310  Census Tract 3.10; Franklin County; Ohio       2887   \n",
      "\n",
      "   pop_age_under_5  pop_age_15_to_19  pop_age_20_to_24  pop_age_25_to_29  \\\n",
      "0              226                81                56               262   \n",
      "1               99               187                19               131   \n",
      "2               99                68                55               211   \n",
      "3              205                60               119               277   \n",
      "4              175                26                85               335   \n",
      "\n",
      "   pop_age_30_to_34  pop_age_35_to_39  pop_age_40_to_44  ...  \\\n",
      "0               329               275               274  ...   \n",
      "1               196               227               316  ...   \n",
      "2               323               225               276  ...   \n",
      "3               363               342               283  ...   \n",
      "4               318               232               188  ...   \n",
      "\n",
      "   pop_selected_age_65_plus  pop_selected_age_75_plus  \\\n",
      "0                       723                       175   \n",
      "1                       829                       343   \n",
      "2                       575                       147   \n",
      "3                      1019                       433   \n",
      "4                       410                       201   \n",
      "\n",
      "   summary_ind_median_age_years  summary_ind_sex_ratio  \\\n",
      "0                          45.6                  100.5   \n",
      "1                          48.0                   97.6   \n",
      "2                          44.5                  105.0   \n",
      "3                          46.0                   93.0   \n",
      "4                          35.7                   92.2   \n",
      "\n",
      "   summary_ind_age_dependency_ratio  summary_ind_old_age_dependency_ratio  \\\n",
      "0                              52.1                                  32.8   \n",
      "1                              67.1                                  41.9   \n",
      "2                              51.6                                  28.0   \n",
      "3                              63.0                                  39.7   \n",
      "4                              57.5                                  22.4   \n",
      "\n",
      "   summary_ind_child_dependency_ratio  male_pop_total  female_pop_total  \\\n",
      "0                                19.3            1681              1673   \n",
      "1                                25.2            1633              1674   \n",
      "2                                23.6            1596              1520   \n",
      "3                                23.3            2016              2167   \n",
      "4                                35.1            1385              1502   \n",
      "\n",
      "   pop_age_5_to_14  \n",
      "0              130  \n",
      "1              219  \n",
      "2              331  \n",
      "3              357  \n",
      "4              469  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erolz\\AppData\\Local\\Temp\\ipykernel_39920\\677997387.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  acs_s0101_cleaned_df['pop_age_5_to_14'] = acs_s0101_cleaned_df['pop_age_5_to_9'] + acs_s0101_cleaned_df['pop_age_10_to_14']\n"
     ]
    }
   ],
   "source": [
    "# --- Clean ACS S0101 (Age and Sex) Data ---\n",
    "print(\"--- Cleaning ACS S0101 Data ---\")\n",
    "if acs_s0101_df is not None:\n",
    "    # IMPORTANT: Create a copy to work on, preserving the original loaded DataFrame\n",
    "    acs_s0101_cleaned_df = acs_s0101_df.copy() \n",
    "\n",
    "    # Drop the 'Unnamed' column if it exists and is empty\n",
    "    if 'Unnamed: 458' in acs_s0101_cleaned_df.columns and acs_s0101_cleaned_df['Unnamed: 458'].isnull().all():\n",
    "        acs_s0101_cleaned_df = acs_s0101_cleaned_df.drop(columns=['Unnamed: 458'])\n",
    "        print(\"Dropped 'Unnamed: 458' column.\")\n",
    "\n",
    "    # 1. Drop Margin of Error, Percent-based Estimates, and Allocation columns FIRST\n",
    "    # These columns are not needed for our direct analysis/modeling estimates.\n",
    "    cols_to_drop_initial = [col for col in acs_s0101_cleaned_df.columns if \n",
    "                            'Margin of Error' in col or \n",
    "                            'PERCENT ALLOCATED' in col or\n",
    "                            'Estimate!!Percent' in col # Catches 'Estimate!!Percent!!Total population' etc.\n",
    "                           ]\n",
    "    acs_s0101_cleaned_df = acs_s0101_cleaned_df.drop(columns=cols_to_drop_initial)\n",
    "    print(f\"Dropped {len(cols_to_drop_initial)} error/percentage/allocation columns initially.\")\n",
    "\n",
    "    # --- Direct Mapping for S0101 Column Renaming (HIGHLY ROBUST) ---\n",
    "    # This dictionary maps the EXACT original column names (after load_csv's basic cleanup)\n",
    "    # to your desired clean, snake_case names. This guarantees a match.\n",
    "    # We obtained these exact names from your 'Raw ACS S0101 DataFrame Columns after load_csv' output.\n",
    "    s0101_column_rename_map = {\n",
    "        'Geography': 'geo_id',\n",
    "        'Geographic Area Name': 'geographic_area_name',\n",
    "        'Estimate!!Total!!Total population': 'pop_total',\n",
    "        'Estimate!!Total!!Total population!!AGE!!Under 5 years': 'pop_age_under_5',\n",
    "        'Estimate!!Total!!Total population!!AGE!!5 to 9 years': 'pop_age_5_to_9',\n",
    "        'Estimate!!Total!!Total population!!AGE!!10 to 14 years': 'pop_age_10_to_14',\n",
    "        'Estimate!!Total!!Total population!!AGE!!15 to 19 years': 'pop_age_15_to_19',\n",
    "        'Estimate!!Total!!Total population!!AGE!!20 to 24 years': 'pop_age_20_to_24',\n",
    "        'Estimate!!Total!!Total population!!AGE!!25 to 29 years': 'pop_age_25_to_29',\n",
    "        'Estimate!!Total!!Total population!!AGE!!30 to 34 years': 'pop_age_30_to_34',\n",
    "        'Estimate!!Total!!Total population!!AGE!!35 to 39 years': 'pop_age_35_to_39',\n",
    "        'Estimate!!Total!!Total population!!AGE!!40 to 44 years': 'pop_age_40_to_44',\n",
    "        'Estimate!!Total!!Total population!!AGE!!45 to 49 years': 'pop_age_45_to_49',\n",
    "        'Estimate!!Total!!Total population!!AGE!!50 to 54 years': 'pop_age_50_to_54',\n",
    "        'Estimate!!Total!!Total population!!AGE!!55 to 59 years': 'pop_age_55_to_59',\n",
    "        'Estimate!!Total!!Total population!!AGE!!60 to 64 years': 'pop_age_60_to_64',\n",
    "        'Estimate!!Total!!Total population!!AGE!!65 to 69 years': 'pop_age_65_to_69',\n",
    "        'Estimate!!Total!!Total population!!AGE!!70 to 74 years': 'pop_age_70_to_74',\n",
    "        'Estimate!!Total!!Total population!!AGE!!75 to 79 years': 'pop_age_75_to_79',\n",
    "        'Estimate!!Total!!Total population!!AGE!!80 to 84 years': 'pop_age_80_to_84',\n",
    "        'Estimate!!Total!!Total population!!AGE!!85 years and over': 'pop_age_85_plus',\n",
    "        'Estimate!!Total!!Total population!!SELECTED AGE CATEGORIES!!5 to 14 years': 'pop_selected_age_5_to_14',\n",
    "        'Estimate!!Total!!Total population!!SELECTED AGE CATEGORIES!!15 to 17 years': 'pop_selected_age_15_to_17',\n",
    "        'Estimate!!Total!!Total population!!SELECTED AGE CATEGORIES!!Under 18 years': 'pop_selected_age_under_18',\n",
    "        'Estimate!!Total!!Total population!!SELECTED AGE CATEGORIES!!18 to 24 years': 'pop_selected_age_18_to_24',\n",
    "        'Estimate!!Total!!Total population!!SELECTED AGE CATEGORIES!!15 to 44 years': 'pop_selected_age_15_to_44',\n",
    "        'Estimate!!Total!!Total population!!SELECTED AGE CATEGORIES!!16 years and over': 'pop_selected_age_16_plus',\n",
    "        'Estimate!!Total!!Total population!!SELECTED AGE CATEGORIES!!18 years and over': 'pop_selected_age_18_plus',\n",
    "        'Estimate!!Total!!Total population!!SELECTED AGE CATEGORIES!!21 years and over': 'pop_selected_age_21_plus',\n",
    "        'Estimate!!Total!!Total population!!SELECTED AGE CATEGORIES!!60 years and over': 'pop_selected_age_60_plus',\n",
    "        'Estimate!!Total!!Total population!!SELECTED AGE CATEGORIES!!62 years and over': 'pop_selected_age_62_plus',\n",
    "        'Estimate!!Total!!Total population!!SELECTED AGE CATEGORIES!!65 years and over': 'pop_selected_age_65_plus',\n",
    "        'Estimate!!Total!!Total population!!SELECTED AGE CATEGORIES!!75 years and over': 'pop_selected_age_75_plus',\n",
    "        'Estimate!!Total!!Total population!!SUMMARY INDICATORS!!Median age (years)': 'summary_ind_median_age_years',\n",
    "        'Estimate!!Total!!Total population!!SUMMARY INDICATORS!!Sex ratio (males per 100 females)': 'summary_ind_sex_ratio',\n",
    "        'Estimate!!Total!!Total population!!SUMMARY INDICATORS!!Age dependency ratio': 'summary_ind_age_dependency_ratio',\n",
    "        'Estimate!!Total!!Total population!!SUMMARY INDICATORS!!Old-age dependency ratio': 'summary_ind_old_age_dependency_ratio',\n",
    "        'Estimate!!Total!!Total population!!SUMMARY INDICATORS!!Child dependency ratio': 'summary_ind_child_dependency_ratio',\n",
    "        'Estimate!!Male!!Total population': 'male_pop_total',\n",
    "        'Estimate!!Female!!Total population': 'female_pop_total'\n",
    "    }\n",
    "\n",
    "    # Apply the direct renaming. Only rename columns that exist in our DataFrame.\n",
    "    acs_s0101_cleaned_df = acs_s0101_cleaned_df.rename(columns={k: v for k, v in s0101_column_rename_map.items() if k in acs_s0101_cleaned_df.columns})\n",
    "    print(\"Columns renamed using direct mapping.\")\n",
    "\n",
    "    # 2. Convert all relevant population columns to numeric and fill NaNs\n",
    "    # Iterate through all columns that are *now* in the DataFrame after renaming,\n",
    "    # and convert them to numeric, excluding the identifier columns.\n",
    "    for col in acs_s0101_cleaned_df.columns:\n",
    "        if col not in ['geo_id', 'geographic_area_name']:\n",
    "            acs_s0101_cleaned_df[col] = pd.to_numeric(acs_s0101_cleaned_df[col], errors='coerce')\n",
    "    print(\"All relevant population columns converted to numeric.\")\n",
    "\n",
    "    # Handle any remaining NaN values (e.g., from (X) suppressions) - fill with 0\n",
    "    acs_s0101_cleaned_df = acs_s0101_cleaned_df.fillna(0)\n",
    "    print(\"NaN values filled with 0.\")\n",
    "    \n",
    "    # 3. Feature Engineering: Create Aggregated Age Groups by Summing Granular Ones\n",
    "    # This is the step your insight highlighted!\n",
    "    print(\"\\n--- Performing Age Group Feature Engineering ---\")\n",
    "\n",
    "    # Example: 5 to 14 years = 5 to 9 years + 10 to 14 years\n",
    "    if 'pop_age_5_to_9' in acs_s0101_cleaned_df.columns and 'pop_age_10_to_14' in acs_s0101_cleaned_df.columns:\n",
    "        acs_s0101_cleaned_df['pop_age_5_to_14'] = acs_s0101_cleaned_df['pop_age_5_to_9'] + acs_s0101_cleaned_df['pop_age_10_to_14']\n",
    "        print(\"Created 'pop_age_5_to_14' column.\")\n",
    "    else:\n",
    "        print(\"Could not create 'pop_age_5_to_14': required granular columns missing.\")\n",
    "\n",
    "    # Define the final list of columns we want to keep after all cleaning and feature engineering\n",
    "    # This list includes the directly renamed columns AND the newly engineered columns.\n",
    "    final_s0101_cols_to_keep = [\n",
    "        'geo_id',\n",
    "        'geographic_area_name',\n",
    "        'pop_total',\n",
    "        'pop_age_under_5',\n",
    "        'pop_age_5_to_14',            # Newly created\n",
    "        'pop_age_15_to_19',\n",
    "        'pop_age_20_to_24',\n",
    "        'pop_age_25_to_29',\n",
    "        'pop_age_30_to_34',\n",
    "        'pop_age_35_to_39',\n",
    "        'pop_age_40_to_44',\n",
    "        'pop_age_45_to_49',\n",
    "        'pop_age_50_to_54',\n",
    "        'pop_age_55_to_59',\n",
    "        'pop_age_60_to_64',\n",
    "        'pop_age_65_to_69',\n",
    "        'pop_age_70_to_74',\n",
    "        'pop_age_75_to_79',\n",
    "        'pop_age_80_to_84',\n",
    "        'pop_age_85_plus',\n",
    "        'pop_selected_age_under_18',\n",
    "        'pop_selected_age_18_to_24',\n",
    "        'pop_selected_age_15_to_44',\n",
    "        'pop_selected_age_16_plus',\n",
    "        'pop_selected_age_18_plus',\n",
    "        'pop_selected_age_21_plus',\n",
    "        'pop_selected_age_60_plus',\n",
    "        'pop_selected_age_62_plus',\n",
    "        'pop_selected_age_65_plus',\n",
    "        'pop_selected_age_75_plus',\n",
    "        'summary_ind_median_age_years',\n",
    "        'summary_ind_sex_ratio',\n",
    "        'summary_ind_age_dependency_ratio',\n",
    "        'summary_ind_old_age_dependency_ratio',\n",
    "        'summary_ind_child_dependency_ratio',\n",
    "        'male_pop_total',\n",
    "        'female_pop_total' \n",
    "    ]\n",
    "\n",
    "    # Filter to keep only the final desired columns.\n",
    "    acs_s0101_cleaned_df = acs_s0101_cleaned_df[acs_s0101_cleaned_df.columns.intersection(final_s0101_cols_to_keep)].copy()\n",
    "    print(f\"Filtered to {len(acs_s0101_cleaned_df.columns)} final key population columns.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- ACS S0101 Data Cleaned ---\")\n",
    "    print(\"Cleaned ACS S0101 DataFrame Info:\")\n",
    "    print(acs_s0101_cleaned_df.info())\n",
    "    print(\"\\nCleaned ACS S0101 Head:\")\n",
    "    print(acs_s0101_cleaned_df.head())\n",
    "    \n",
    "else:\n",
    "    print(\"ACS S0101 DataFrame not loaded. Cleaning skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f4271d",
   "metadata": {},
   "source": [
    "#### Cleaning ACS_B08141 (Vehicles Available Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db781bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ACS B08141 Columns:\n",
      "['Geography', 'Geographic Area Name', 'Estimate!!Total:', 'Margin of Error!!Total:', 'Estimate!!Total:!!No vehicle available', 'Margin of Error!!Total:!!No vehicle available', 'Estimate!!Total:!!1 vehicle available', 'Margin of Error!!Total:!!1 vehicle available', 'Estimate!!Total:!!2 vehicles available', 'Margin of Error!!Total:!!2 vehicles available', 'Estimate!!Total:!!3 or more vehicles available', 'Margin of Error!!Total:!!3 or more vehicles available', 'Estimate!!Total:!!Car, truck, or van - drove alone:', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!No vehicle available', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!No vehicle available', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!1 vehicle available', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!1 vehicle available', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!2 vehicles available', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!2 vehicles available', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!3 or more vehicles available', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!3 or more vehicles available', 'Estimate!!Total:!!Car, truck, or van - carpooled:', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!No vehicle available', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!No vehicle available', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!1 vehicle available', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!1 vehicle available', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!2 vehicles available', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!2 vehicles available', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!3 or more vehicles available', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!3 or more vehicles available', 'Estimate!!Total:!!Public transportation (excluding taxicab):', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!No vehicle available', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!No vehicle available', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!1 vehicle available', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!1 vehicle available', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!2 vehicles available', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!2 vehicles available', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!3 or more vehicles available', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!3 or more vehicles available', 'Estimate!!Total:!!Walked:', 'Margin of Error!!Total:!!Walked:', 'Estimate!!Total:!!Walked:!!No vehicle available', 'Margin of Error!!Total:!!Walked:!!No vehicle available', 'Estimate!!Total:!!Walked:!!1 vehicle available', 'Margin of Error!!Total:!!Walked:!!1 vehicle available', 'Estimate!!Total:!!Walked:!!2 vehicles available', 'Margin of Error!!Total:!!Walked:!!2 vehicles available', 'Estimate!!Total:!!Walked:!!3 or more vehicles available', 'Margin of Error!!Total:!!Walked:!!3 or more vehicles available', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!No vehicle available', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!No vehicle available', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!1 vehicle available', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!1 vehicle available', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!2 vehicles available', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!2 vehicles available', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!3 or more vehicles available', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!3 or more vehicles available', 'Estimate!!Total:!!Worked from home:', 'Margin of Error!!Total:!!Worked from home:', 'Estimate!!Total:!!Worked from home:!!No vehicle available', 'Margin of Error!!Total:!!Worked from home:!!No vehicle available', 'Estimate!!Total:!!Worked from home:!!1 vehicle available', 'Margin of Error!!Total:!!Worked from home:!!1 vehicle available', 'Estimate!!Total:!!Worked from home:!!2 vehicles available', 'Margin of Error!!Total:!!Worked from home:!!2 vehicles available', 'Estimate!!Total:!!Worked from home:!!3 or more vehicles available', 'Margin of Error!!Total:!!Worked from home:!!3 or more vehicles available', 'Unnamed: 72']\n",
      "\n",
      "ACS B08141 Data Types and Non-Null Counts:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 328 entries, 0 to 327\n",
      "Data columns (total 73 columns):\n",
      " #   Column                                                                                                Non-Null Count  Dtype  \n",
      "---  ------                                                                                                --------------  -----  \n",
      " 0   Geography                                                                                             328 non-null    object \n",
      " 1   Geographic Area Name                                                                                  328 non-null    object \n",
      " 2   Estimate!!Total:                                                                                      328 non-null    int64  \n",
      " 3   Margin of Error!!Total:                                                                               328 non-null    int64  \n",
      " 4   Estimate!!Total:!!No vehicle available                                                                328 non-null    int64  \n",
      " 5   Margin of Error!!Total:!!No vehicle available                                                         328 non-null    int64  \n",
      " 6   Estimate!!Total:!!1 vehicle available                                                                 328 non-null    int64  \n",
      " 7   Margin of Error!!Total:!!1 vehicle available                                                          328 non-null    int64  \n",
      " 8   Estimate!!Total:!!2 vehicles available                                                                328 non-null    int64  \n",
      " 9   Margin of Error!!Total:!!2 vehicles available                                                         328 non-null    int64  \n",
      " 10  Estimate!!Total:!!3 or more vehicles available                                                        328 non-null    int64  \n",
      " 11  Margin of Error!!Total:!!3 or more vehicles available                                                 328 non-null    int64  \n",
      " 12  Estimate!!Total:!!Car, truck, or van - drove alone:                                                   328 non-null    int64  \n",
      " 13  Margin of Error!!Total:!!Car, truck, or van - drove alone:                                            328 non-null    int64  \n",
      " 14  Estimate!!Total:!!Car, truck, or van - drove alone:!!No vehicle available                             328 non-null    int64  \n",
      " 15  Margin of Error!!Total:!!Car, truck, or van - drove alone:!!No vehicle available                      328 non-null    int64  \n",
      " 16  Estimate!!Total:!!Car, truck, or van - drove alone:!!1 vehicle available                              328 non-null    int64  \n",
      " 17  Margin of Error!!Total:!!Car, truck, or van - drove alone:!!1 vehicle available                       328 non-null    int64  \n",
      " 18  Estimate!!Total:!!Car, truck, or van - drove alone:!!2 vehicles available                             328 non-null    int64  \n",
      " 19  Margin of Error!!Total:!!Car, truck, or van - drove alone:!!2 vehicles available                      328 non-null    int64  \n",
      " 20  Estimate!!Total:!!Car, truck, or van - drove alone:!!3 or more vehicles available                     328 non-null    int64  \n",
      " 21  Margin of Error!!Total:!!Car, truck, or van - drove alone:!!3 or more vehicles available              328 non-null    int64  \n",
      " 22  Estimate!!Total:!!Car, truck, or van - carpooled:                                                     328 non-null    int64  \n",
      " 23  Margin of Error!!Total:!!Car, truck, or van - carpooled:                                              328 non-null    int64  \n",
      " 24  Estimate!!Total:!!Car, truck, or van - carpooled:!!No vehicle available                               328 non-null    int64  \n",
      " 25  Margin of Error!!Total:!!Car, truck, or van - carpooled:!!No vehicle available                        328 non-null    int64  \n",
      " 26  Estimate!!Total:!!Car, truck, or van - carpooled:!!1 vehicle available                                328 non-null    int64  \n",
      " 27  Margin of Error!!Total:!!Car, truck, or van - carpooled:!!1 vehicle available                         328 non-null    int64  \n",
      " 28  Estimate!!Total:!!Car, truck, or van - carpooled:!!2 vehicles available                               328 non-null    int64  \n",
      " 29  Margin of Error!!Total:!!Car, truck, or van - carpooled:!!2 vehicles available                        328 non-null    int64  \n",
      " 30  Estimate!!Total:!!Car, truck, or van - carpooled:!!3 or more vehicles available                       328 non-null    int64  \n",
      " 31  Margin of Error!!Total:!!Car, truck, or van - carpooled:!!3 or more vehicles available                328 non-null    int64  \n",
      " 32  Estimate!!Total:!!Public transportation (excluding taxicab):                                          328 non-null    int64  \n",
      " 33  Margin of Error!!Total:!!Public transportation (excluding taxicab):                                   328 non-null    int64  \n",
      " 34  Estimate!!Total:!!Public transportation (excluding taxicab):!!No vehicle available                    328 non-null    int64  \n",
      " 35  Margin of Error!!Total:!!Public transportation (excluding taxicab):!!No vehicle available             328 non-null    int64  \n",
      " 36  Estimate!!Total:!!Public transportation (excluding taxicab):!!1 vehicle available                     328 non-null    int64  \n",
      " 37  Margin of Error!!Total:!!Public transportation (excluding taxicab):!!1 vehicle available              328 non-null    int64  \n",
      " 38  Estimate!!Total:!!Public transportation (excluding taxicab):!!2 vehicles available                    328 non-null    int64  \n",
      " 39  Margin of Error!!Total:!!Public transportation (excluding taxicab):!!2 vehicles available             328 non-null    int64  \n",
      " 40  Estimate!!Total:!!Public transportation (excluding taxicab):!!3 or more vehicles available            328 non-null    int64  \n",
      " 41  Margin of Error!!Total:!!Public transportation (excluding taxicab):!!3 or more vehicles available     328 non-null    int64  \n",
      " 42  Estimate!!Total:!!Walked:                                                                             328 non-null    int64  \n",
      " 43  Margin of Error!!Total:!!Walked:                                                                      328 non-null    int64  \n",
      " 44  Estimate!!Total:!!Walked:!!No vehicle available                                                       328 non-null    int64  \n",
      " 45  Margin of Error!!Total:!!Walked:!!No vehicle available                                                328 non-null    int64  \n",
      " 46  Estimate!!Total:!!Walked:!!1 vehicle available                                                        328 non-null    int64  \n",
      " 47  Margin of Error!!Total:!!Walked:!!1 vehicle available                                                 328 non-null    int64  \n",
      " 48  Estimate!!Total:!!Walked:!!2 vehicles available                                                       328 non-null    int64  \n",
      " 49  Margin of Error!!Total:!!Walked:!!2 vehicles available                                                328 non-null    int64  \n",
      " 50  Estimate!!Total:!!Walked:!!3 or more vehicles available                                               328 non-null    int64  \n",
      " 51  Margin of Error!!Total:!!Walked:!!3 or more vehicles available                                        328 non-null    int64  \n",
      " 52  Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:                                       328 non-null    int64  \n",
      " 53  Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:                                328 non-null    int64  \n",
      " 54  Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!No vehicle available                 328 non-null    int64  \n",
      " 55  Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!No vehicle available          328 non-null    int64  \n",
      " 56  Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!1 vehicle available                  328 non-null    int64  \n",
      " 57  Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!1 vehicle available           328 non-null    int64  \n",
      " 58  Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!2 vehicles available                 328 non-null    int64  \n",
      " 59  Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!2 vehicles available          328 non-null    int64  \n",
      " 60  Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!3 or more vehicles available         328 non-null    int64  \n",
      " 61  Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!3 or more vehicles available  328 non-null    int64  \n",
      " 62  Estimate!!Total:!!Worked from home:                                                                   328 non-null    int64  \n",
      " 63  Margin of Error!!Total:!!Worked from home:                                                            328 non-null    int64  \n",
      " 64  Estimate!!Total:!!Worked from home:!!No vehicle available                                             328 non-null    int64  \n",
      " 65  Margin of Error!!Total:!!Worked from home:!!No vehicle available                                      328 non-null    int64  \n",
      " 66  Estimate!!Total:!!Worked from home:!!1 vehicle available                                              328 non-null    int64  \n",
      " 67  Margin of Error!!Total:!!Worked from home:!!1 vehicle available                                       328 non-null    int64  \n",
      " 68  Estimate!!Total:!!Worked from home:!!2 vehicles available                                             328 non-null    int64  \n",
      " 69  Margin of Error!!Total:!!Worked from home:!!2 vehicles available                                      328 non-null    int64  \n",
      " 70  Estimate!!Total:!!Worked from home:!!3 or more vehicles available                                     328 non-null    int64  \n",
      " 71  Margin of Error!!Total:!!Worked from home:!!3 or more vehicles available                              328 non-null    int64  \n",
      " 72  Unnamed: 72                                                                                           0 non-null      float64\n",
      "dtypes: float64(1), int64(70), object(2)\n",
      "memory usage: 187.2+ KB\n",
      "None\n",
      "\n",
      "Missing Values in ACS B08141:\n",
      "Geography                                                                     0\n",
      "Geographic Area Name                                                          0\n",
      "Estimate!!Total:                                                              0\n",
      "Margin of Error!!Total:                                                       0\n",
      "Estimate!!Total:!!No vehicle available                                        0\n",
      "                                                                           ... \n",
      "Estimate!!Total:!!Worked from home:!!2 vehicles available                     0\n",
      "Margin of Error!!Total:!!Worked from home:!!2 vehicles available              0\n",
      "Estimate!!Total:!!Worked from home:!!3 or more vehicles available             0\n",
      "Margin of Error!!Total:!!Worked from home:!!3 or more vehicles available      0\n",
      "Unnamed: 72                                                                 328\n",
      "Length: 73, dtype: int64\n",
      "\n",
      "First 5 rows of ACS B08141:\n",
      "              Geography                      Geographic Area Name  \\\n",
      "0  1400000US39049000110  Census Tract 1.10; Franklin County; Ohio   \n",
      "1  1400000US39049000120  Census Tract 1.20; Franklin County; Ohio   \n",
      "2  1400000US39049000210  Census Tract 2.10; Franklin County; Ohio   \n",
      "3  1400000US39049000220  Census Tract 2.20; Franklin County; Ohio   \n",
      "4  1400000US39049000310  Census Tract 3.10; Franklin County; Ohio   \n",
      "\n",
      "   Estimate!!Total:  Margin of Error!!Total:  \\\n",
      "0              2245                      304   \n",
      "1              1962                      248   \n",
      "2              1949                      288   \n",
      "3              2405                      213   \n",
      "4              1397                      185   \n",
      "\n",
      "   Estimate!!Total:!!No vehicle available  \\\n",
      "0                                       0   \n",
      "1                                      87   \n",
      "2                                     117   \n",
      "3                                      21   \n",
      "4                                       0   \n",
      "\n",
      "   Margin of Error!!Total:!!No vehicle available  \\\n",
      "0                                             13   \n",
      "1                                             84   \n",
      "2                                            113   \n",
      "3                                             25   \n",
      "4                                             13   \n",
      "\n",
      "   Estimate!!Total:!!1 vehicle available  \\\n",
      "0                                    532   \n",
      "1                                    427   \n",
      "2                                    583   \n",
      "3                                    502   \n",
      "4                                    399   \n",
      "\n",
      "   Margin of Error!!Total:!!1 vehicle available  \\\n",
      "0                                           269   \n",
      "1                                           167   \n",
      "2                                           262   \n",
      "3                                           137   \n",
      "4                                           140   \n",
      "\n",
      "   Estimate!!Total:!!2 vehicles available  \\\n",
      "0                                    1352   \n",
      "1                                    1155   \n",
      "2                                     850   \n",
      "3                                    1499   \n",
      "4                                     663   \n",
      "\n",
      "   Margin of Error!!Total:!!2 vehicles available  ...  \\\n",
      "0                                            232  ...   \n",
      "1                                            277  ...   \n",
      "2                                            164  ...   \n",
      "3                                            230  ...   \n",
      "4                                            146  ...   \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home:  \\\n",
      "0                                         148   \n",
      "1                                         199   \n",
      "2                                         180   \n",
      "3                                         130   \n",
      "4                                         105   \n",
      "\n",
      "   Estimate!!Total:!!Worked from home:!!No vehicle available  \\\n",
      "0                                                  0           \n",
      "1                                                 59           \n",
      "2                                                  0           \n",
      "3                                                  0           \n",
      "4                                                  0           \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home:!!No vehicle available  \\\n",
      "0                                                 13                  \n",
      "1                                                 59                  \n",
      "2                                                 13                  \n",
      "3                                                 13                  \n",
      "4                                                 13                  \n",
      "\n",
      "   Estimate!!Total:!!Worked from home:!!1 vehicle available  \\\n",
      "0                                                 79          \n",
      "1                                                203          \n",
      "2                                                277          \n",
      "3                                                157          \n",
      "4                                                 91          \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home:!!1 vehicle available  \\\n",
      "0                                                 46                 \n",
      "1                                                135                 \n",
      "2                                                155                 \n",
      "3                                                 93                 \n",
      "4                                                 80                 \n",
      "\n",
      "   Estimate!!Total:!!Worked from home:!!2 vehicles available  \\\n",
      "0                                                302           \n",
      "1                                                388           \n",
      "2                                                264           \n",
      "3                                                372           \n",
      "4                                                107           \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home:!!2 vehicles available  \\\n",
      "0                                                111                  \n",
      "1                                                164                  \n",
      "2                                                 96                  \n",
      "3                                                118                  \n",
      "4                                                 51                  \n",
      "\n",
      "   Estimate!!Total:!!Worked from home:!!3 or more vehicles available  \\\n",
      "0                                                 82                   \n",
      "1                                                 84                   \n",
      "2                                                 72                   \n",
      "3                                                 47                   \n",
      "4                                                 25                   \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home:!!3 or more vehicles available  \\\n",
      "0                                                101                          \n",
      "1                                                 45                          \n",
      "2                                                 55                          \n",
      "3                                                 33                          \n",
      "4                                                 25                          \n",
      "\n",
      "   Unnamed: 72  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "\n",
      "[5 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Inspect ACS B08141 (Vehicles Available) Data ---\n",
    "print(\"\\nACS B08141 Columns:\")\n",
    "print(acs_b08141_df.columns.tolist()) # List all column names\n",
    "\n",
    "print(\"\\nACS B08141 Data Types and Non-Null Counts:\")\n",
    "print(acs_b08141_df.info()) # Get info again for clarity\n",
    "\n",
    "print(\"\\nMissing Values in ACS B08141:\")\n",
    "print(acs_b08141_df.isnull().sum()) # Count missing values per column\n",
    "\n",
    "print(\"\\nFirst 5 rows of ACS B08141:\")\n",
    "print(acs_b08141_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0d423ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning ACS B08141 Data ---\n",
      "Dropped 1 'Unnamed' columns.\n",
      "Dropped 35 'Margin of Error' columns.\n",
      "Columns renamed to clean, snake_case format.\n",
      "Filtered to 16 key vehicle availability and commuting columns.\n",
      "Numerical columns converted to int and NaNs filled with 0.\n",
      "\n",
      "--- ACS B08141 Data Cleaned ---\n",
      "Cleaned ACS B08141 DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 328 entries, 0 to 327\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                  Non-Null Count  Dtype \n",
      "---  ------                                  --------------  ----- \n",
      " 0   geo_id                                  328 non-null    object\n",
      " 1   geographic_area_name                    328 non-null    object\n",
      " 2   households_total                        328 non-null    int32 \n",
      " 3   households_no_vehicle                   328 non-null    int32 \n",
      " 4   households_1_vehicle                    328 non-null    int32 \n",
      " 5   households_2_vehicles                   328 non-null    int32 \n",
      " 6   households_3_plus_vehicles              328 non-null    int32 \n",
      " 7   commute_drove_alone_total               328 non-null    int32 \n",
      " 8   commute_public_transit_total            328 non-null    int32 \n",
      " 9   commute_public_transit_no_vehicle       328 non-null    int32 \n",
      " 10  commute_public_transit_1_vehicle        328 non-null    int32 \n",
      " 11  commute_public_transit_2_vehicles       328 non-null    int32 \n",
      " 12  commute_public_transit_3_plus_vehicles  328 non-null    int32 \n",
      " 13  commute_walked_total                    328 non-null    int32 \n",
      " 14  commute_other_means_total               328 non-null    int32 \n",
      " 15  commute_worked_from_home_total          328 non-null    int32 \n",
      "dtypes: int32(14), object(2)\n",
      "memory usage: 23.2+ KB\n",
      "None\n",
      "\n",
      "Cleaned ACS B08141 Head:\n",
      "                 geo_id                      geographic_area_name  \\\n",
      "0  1400000US39049000110  Census Tract 1.10; Franklin County; Ohio   \n",
      "1  1400000US39049000120  Census Tract 1.20; Franklin County; Ohio   \n",
      "2  1400000US39049000210  Census Tract 2.10; Franklin County; Ohio   \n",
      "3  1400000US39049000220  Census Tract 2.20; Franklin County; Ohio   \n",
      "4  1400000US39049000310  Census Tract 3.10; Franklin County; Ohio   \n",
      "\n",
      "   households_total  households_no_vehicle  households_1_vehicle  \\\n",
      "0              2245                      0                   532   \n",
      "1              1962                     87                   427   \n",
      "2              1949                    117                   583   \n",
      "3              2405                     21                   502   \n",
      "4              1397                      0                   399   \n",
      "\n",
      "   households_2_vehicles  households_3_plus_vehicles  \\\n",
      "0                   1352                         361   \n",
      "1                   1155                         293   \n",
      "2                    850                         399   \n",
      "3                   1499                         383   \n",
      "4                    663                         335   \n",
      "\n",
      "   commute_drove_alone_total  commute_public_transit_total  \\\n",
      "0                       1551                             9   \n",
      "1                       1114                            36   \n",
      "2                        978                           130   \n",
      "3                       1530                            39   \n",
      "4                        979                             0   \n",
      "\n",
      "   commute_public_transit_no_vehicle  commute_public_transit_1_vehicle  \\\n",
      "0                                  0                                 0   \n",
      "1                                 28                                 8   \n",
      "2                                 88                                17   \n",
      "3                                  0                                39   \n",
      "4                                  0                                 0   \n",
      "\n",
      "   commute_public_transit_2_vehicles  commute_public_transit_3_plus_vehicles  \\\n",
      "0                                  9                                       0   \n",
      "1                                  0                                       0   \n",
      "2                                 25                                       0   \n",
      "3                                  0                                       0   \n",
      "4                                  0                                       0   \n",
      "\n",
      "   commute_walked_total  commute_other_means_total  \\\n",
      "0                     9                        157   \n",
      "1                    19                         16   \n",
      "2                    52                         52   \n",
      "3                    31                         76   \n",
      "4                     0                         18   \n",
      "\n",
      "   commute_worked_from_home_total  \n",
      "0                             463  \n",
      "1                             734  \n",
      "2                             613  \n",
      "3                             576  \n",
      "4                             223  \n"
     ]
    }
   ],
   "source": [
    "# --- Clean ACS B08141 (Vehicles Available) Data ---\n",
    "print(\"\\n--- Cleaning ACS B08141 Data ---\")\n",
    "if acs_b08141_df is not None:\n",
    "    acs_b08141_cleaned_df = acs_b08141_df.copy() # Create a copy to work on\n",
    "\n",
    "    # Drop 'Unnamed' columns if they exist and are empty\n",
    "    cols_to_drop_unnamed = [col for col in acs_b08141_cleaned_df.columns if 'Unnamed' in col and acs_b08141_cleaned_df[col].isnull().all()]\n",
    "    if cols_to_drop_unnamed:\n",
    "        acs_b08141_cleaned_df = acs_b08141_cleaned_df.drop(columns=cols_to_drop_unnamed)\n",
    "        print(f\"Dropped {len(cols_to_drop_unnamed)} 'Unnamed' columns.\")\n",
    "\n",
    "    # Drop Margin of Error columns (using the same 'Margin of Error' string search)\n",
    "    cols_to_drop_moe = [col for col in acs_b08141_cleaned_df.columns if 'Margin of Error' in col]\n",
    "    acs_b08141_cleaned_df = acs_b08141_cleaned_df.drop(columns=cols_to_drop_moe)\n",
    "    print(f\"Dropped {len(cols_to_drop_moe)} 'Margin of Error' columns.\")\n",
    "\n",
    "    # --- Direct Mapping for B08141 Column Renaming ---\n",
    "    # This maps the EXACT original column names (after load_csv's basic cleanup)\n",
    "    # to your desired clean, snake_case names.\n",
    "    b08141_column_rename_map = {\n",
    "        'Geography': 'geo_id',\n",
    "        'Geographic Area Name': 'geographic_area_name',\n",
    "        \n",
    "        # Vehicle Availability for Households (Universe: Households)\n",
    "        'Estimate!!Total:': 'households_total', # Universe: Households\n",
    "        'Estimate!!Total:!!No vehicle available': 'households_no_vehicle',\n",
    "        'Estimate!!Total:!!1 vehicle available': 'households_1_vehicle',\n",
    "        'Estimate!!Total:!!2 vehicles available': 'households_2_vehicles',\n",
    "        'Estimate!!Total:!!3 or more vehicles available': 'households_3_plus_vehicles',\n",
    "\n",
    "        # Means of Transportation to Work (Universe: Workers 16 years and over)\n",
    "        # Note: B08101 and B08122 also cover means of transportation.\n",
    "        # This table gives us the crucial 'means of transport *by vehicle availability*'.\n",
    "        \n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):': 'commute_public_transit_total',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!No vehicle available': 'commute_public_transit_no_vehicle',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!1 vehicle available': 'commute_public_transit_1_vehicle',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!2 vehicles available': 'commute_public_transit_2_vehicles',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!3 or more vehicles available': 'commute_public_transit_3_plus_vehicles',\n",
    "        \n",
    "        'Estimate!!Total:!!Car, truck, or van - drove alone:': 'commute_drove_alone_total',\n",
    "        'Estimate!!Total:!!Car, truck, or van - drove alone:!!No vehicle available': 'commute_drove_alone_no_vehicle',\n",
    "        # ... you can add more vehicle availability breakdowns for other modes if needed.\n",
    "        \n",
    "        'Estimate!!Total:!!Walked:': 'commute_walked_total',\n",
    "        'Estimate!!Total:!!Worked from home:': 'commute_worked_from_home_total',\n",
    "        'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:': 'commute_other_means_total'\n",
    "    }\n",
    "\n",
    "    # Apply the direct renaming. Only rename columns that exist in our DataFrame.\n",
    "    acs_b08141_cleaned_df = acs_b08141_cleaned_df.rename(columns={k: v for k, v in b08141_column_rename_map.items() if k in acs_b08141_cleaned_df.columns})\n",
    "    print(\"Columns renamed to clean, snake_case format.\")\n",
    "\n",
    "    # --- Select Key Columns for Analysis from B08141 ---\n",
    "    final_b08141_cols = [\n",
    "        'geo_id',\n",
    "        'geographic_area_name',\n",
    "        'households_total',\n",
    "        'households_no_vehicle',\n",
    "        'households_1_vehicle',\n",
    "        'households_2_vehicles',\n",
    "        'households_3_plus_vehicles',\n",
    "        'commute_public_transit_total',\n",
    "        'commute_public_transit_no_vehicle',\n",
    "        'commute_public_transit_1_vehicle',\n",
    "        'commute_public_transit_2_vehicles',\n",
    "        'commute_public_transit_3_plus_vehicles',\n",
    "        'commute_drove_alone_total',\n",
    "        'commute_walked_total',\n",
    "        'commute_worked_from_home_total',\n",
    "        'commute_other_means_total'\n",
    "    ]\n",
    "    acs_b08141_cleaned_df = acs_b08141_cleaned_df[acs_b08141_cleaned_df.columns.intersection(final_b08141_cols)].copy()\n",
    "    print(f\"Filtered to {len(acs_b08141_cleaned_df.columns)} key vehicle availability and commuting columns.\")\n",
    "\n",
    "    # Convert all numerical columns to numeric and fill NaNs with 0\n",
    "    for col in acs_b08141_cleaned_df.columns:\n",
    "        if col not in ['geo_id', 'geographic_area_name']:\n",
    "            acs_b08141_cleaned_df[col] = pd.to_numeric(acs_b08141_cleaned_df[col], errors='coerce').fillna(0).astype(int)\n",
    "    print(\"Numerical columns converted to int and NaNs filled with 0.\")\n",
    "\n",
    "    print(\"\\n--- ACS B08141 Data Cleaned ---\")\n",
    "    print(\"Cleaned ACS B08141 DataFrame Info:\")\n",
    "    print(acs_b08141_cleaned_df.info())\n",
    "    print(\"\\nCleaned ACS B08141 Head:\")\n",
    "    print(acs_b08141_cleaned_df.head())\n",
    "\n",
    "else:\n",
    "    print(\"ACS B08141 DataFrame not loaded. Cleaning skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7760f9b6",
   "metadata": {},
   "source": [
    "#### Cleaning ACS_B08101 (Transportation by Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cec26eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initial Inspection: ACS B08101 ---\n",
      "\n",
      "ACS B08101 Columns:\n",
      "['Geography', 'Geographic Area Name', 'Estimate!!Total:', 'Margin of Error!!Total:', 'Estimate!!Total:!!16 to 19 years', 'Margin of Error!!Total:!!16 to 19 years', 'Estimate!!Total:!!20 to 24 years', 'Margin of Error!!Total:!!20 to 24 years', 'Estimate!!Total:!!25 to 44 years', 'Margin of Error!!Total:!!25 to 44 years', 'Estimate!!Total:!!45 to 54 years', 'Margin of Error!!Total:!!45 to 54 years', 'Estimate!!Total:!!55 to 59 years', 'Margin of Error!!Total:!!55 to 59 years', 'Estimate!!Total:!!60 to 64 years', 'Margin of Error!!Total:!!60 to 64 years', 'Estimate!!Total:!!65 years and over', 'Margin of Error!!Total:!!65 years and over', 'Estimate!!Total:!!Car, truck, or van - drove alone:', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!16 to 19 years', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!16 to 19 years', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!20 to 24 years', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!20 to 24 years', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!25 to 44 years', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!25 to 44 years', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!45 to 54 years', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!45 to 54 years', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!55 to 59 years', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!55 to 59 years', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!60 to 64 years', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!60 to 64 years', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!65 years and over', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!65 years and over', 'Estimate!!Total:!!Car, truck, or van - carpooled:', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!16 to 19 years', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!16 to 19 years', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!20 to 24 years', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!20 to 24 years', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!25 to 44 years', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!25 to 44 years', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!45 to 54 years', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!45 to 54 years', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!55 to 59 years', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!55 to 59 years', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!60 to 64 years', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!60 to 64 years', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!65 years and over', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!65 years and over', 'Estimate!!Total:!!Public transportation (excluding taxicab):', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!16 to 19 years', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!16 to 19 years', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!20 to 24 years', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!20 to 24 years', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!25 to 44 years', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!25 to 44 years', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!45 to 54 years', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!45 to 54 years', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!55 to 59 years', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!55 to 59 years', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!60 to 64 years', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!60 to 64 years', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!65 years and over', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!65 years and over', 'Estimate!!Total:!!Walked:', 'Margin of Error!!Total:!!Walked:', 'Estimate!!Total:!!Walked:!!16 to 19 years', 'Margin of Error!!Total:!!Walked:!!16 to 19 years', 'Estimate!!Total:!!Walked:!!20 to 24 years', 'Margin of Error!!Total:!!Walked:!!20 to 24 years', 'Estimate!!Total:!!Walked:!!25 to 44 years', 'Margin of Error!!Total:!!Walked:!!25 to 44 years', 'Estimate!!Total:!!Walked:!!45 to 54 years', 'Margin of Error!!Total:!!Walked:!!45 to 54 years', 'Estimate!!Total:!!Walked:!!55 to 59 years', 'Margin of Error!!Total:!!Walked:!!55 to 59 years', 'Estimate!!Total:!!Walked:!!60 to 64 years', 'Margin of Error!!Total:!!Walked:!!60 to 64 years', 'Estimate!!Total:!!Walked:!!65 years and over', 'Margin of Error!!Total:!!Walked:!!65 years and over', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!16 to 19 years', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!16 to 19 years', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!20 to 24 years', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!20 to 24 years', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!25 to 44 years', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!25 to 44 years', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!45 to 54 years', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!45 to 54 years', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!55 to 59 years', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!55 to 59 years', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!60 to 64 years', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!60 to 64 years', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!65 years and over', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!65 years and over', 'Estimate!!Total:!!Worked from home', 'Margin of Error!!Total:!!Worked from home', 'Estimate!!Total:!!Worked from home!!16 to 19 years', 'Margin of Error!!Total:!!Worked from home!!16 to 19 years', 'Estimate!!Total:!!Worked from home!!20 to 24 years', 'Margin of Error!!Total:!!Worked from home!!20 to 24 years', 'Estimate!!Total:!!Worked from home!!25 to 44 years', 'Margin of Error!!Total:!!Worked from home!!25 to 44 years', 'Estimate!!Total:!!Worked from home!!45 to 54 years', 'Margin of Error!!Total:!!Worked from home!!45 to 54 years', 'Estimate!!Total:!!Worked from home!!55 to 59 years', 'Margin of Error!!Total:!!Worked from home!!55 to 59 years', 'Estimate!!Total:!!Worked from home!!60 to 64 years', 'Margin of Error!!Total:!!Worked from home!!60 to 64 years', 'Estimate!!Total:!!Worked from home!!65 years and over', 'Margin of Error!!Total:!!Worked from home!!65 years and over', 'Unnamed: 114']\n",
      "\n",
      "ACS B08101 Data Types and Non-Null Counts:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 328 entries, 0 to 327\n",
      "Columns: 115 entries, Geography to Unnamed: 114\n",
      "dtypes: float64(1), int64(112), object(2)\n",
      "memory usage: 294.8+ KB\n",
      "None\n",
      "\n",
      "Missing Values in ACS B08101:\n",
      "Geography                                                         0\n",
      "Geographic Area Name                                              0\n",
      "Estimate!!Total:                                                  0\n",
      "Margin of Error!!Total:                                           0\n",
      "Estimate!!Total:!!16 to 19 years                                  0\n",
      "                                                               ... \n",
      "Estimate!!Total:!!Worked from home!!60 to 64 years                0\n",
      "Margin of Error!!Total:!!Worked from home!!60 to 64 years         0\n",
      "Estimate!!Total:!!Worked from home!!65 years and over             0\n",
      "Margin of Error!!Total:!!Worked from home!!65 years and over      0\n",
      "Unnamed: 114                                                    328\n",
      "Length: 115, dtype: int64\n",
      "\n",
      "First 5 rows of ACS B08101:\n",
      "              Geography                      Geographic Area Name  \\\n",
      "0  1400000US39049000110  Census Tract 1.10; Franklin County; Ohio   \n",
      "1  1400000US39049000120  Census Tract 1.20; Franklin County; Ohio   \n",
      "2  1400000US39049000210  Census Tract 2.10; Franklin County; Ohio   \n",
      "3  1400000US39049000220  Census Tract 2.20; Franklin County; Ohio   \n",
      "4  1400000US39049000310  Census Tract 3.10; Franklin County; Ohio   \n",
      "\n",
      "   Estimate!!Total:  Margin of Error!!Total:  \\\n",
      "0              2245                      304   \n",
      "1              1963                      248   \n",
      "2              1949                      288   \n",
      "3              2405                      213   \n",
      "4              1397                      185   \n",
      "\n",
      "   Estimate!!Total:!!16 to 19 years  Margin of Error!!Total:!!16 to 19 years  \\\n",
      "0                                 0                                       13   \n",
      "1                                25                                       21   \n",
      "2                                36                                       39   \n",
      "3                                22                                       27   \n",
      "4                                17                                       23   \n",
      "\n",
      "   Estimate!!Total:!!20 to 24 years  Margin of Error!!Total:!!20 to 24 years  \\\n",
      "0                                41                                       25   \n",
      "1                                13                                       21   \n",
      "2                                45                                       49   \n",
      "3                               119                                       76   \n",
      "4                                53                                       40   \n",
      "\n",
      "   Estimate!!Total:!!25 to 44 years  Margin of Error!!Total:!!25 to 44 years  \\\n",
      "0                              1019                                      159   \n",
      "1                               804                                      150   \n",
      "2                               909                                      167   \n",
      "3                              1060                                      177   \n",
      "4                               840                                      171   \n",
      "\n",
      "   ...  Margin of Error!!Total:!!Worked from home!!25 to 44 years  \\\n",
      "0  ...                                                105           \n",
      "1  ...                                                 87           \n",
      "2  ...                                                120           \n",
      "3  ...                                                 88           \n",
      "4  ...                                                 93           \n",
      "\n",
      "   Estimate!!Total:!!Worked from home!!45 to 54 years  \\\n",
      "0                                                119    \n",
      "1                                                303    \n",
      "2                                                165    \n",
      "3                                                 65    \n",
      "4                                                 33    \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home!!45 to 54 years  \\\n",
      "0                                                105           \n",
      "1                                                159           \n",
      "2                                                122           \n",
      "3                                                 34           \n",
      "4                                                 29           \n",
      "\n",
      "   Estimate!!Total:!!Worked from home!!55 to 59 years  \\\n",
      "0                                                 18    \n",
      "1                                                 33    \n",
      "2                                                 53    \n",
      "3                                                146    \n",
      "4                                                 36    \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home!!55 to 59 years  \\\n",
      "0                                                 22           \n",
      "1                                                 20           \n",
      "2                                                 49           \n",
      "3                                                 89           \n",
      "4                                                 46           \n",
      "\n",
      "   Estimate!!Total:!!Worked from home!!60 to 64 years  \\\n",
      "0                                                 10    \n",
      "1                                                 34    \n",
      "2                                                 24    \n",
      "3                                                105    \n",
      "4                                                  7    \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home!!60 to 64 years  \\\n",
      "0                                                 13           \n",
      "1                                                 25           \n",
      "2                                                 21           \n",
      "3                                                 53           \n",
      "4                                                 14           \n",
      "\n",
      "   Estimate!!Total:!!Worked from home!!65 years and over  \\\n",
      "0                                                  7       \n",
      "1                                                114       \n",
      "2                                                 27       \n",
      "3                                                 32       \n",
      "4                                                  5       \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home!!65 years and over  Unnamed: 114  \n",
      "0                                                 11                      NaN  \n",
      "1                                                 92                      NaN  \n",
      "2                                                 24                      NaN  \n",
      "3                                                 25                      NaN  \n",
      "4                                                 10                      NaN  \n",
      "\n",
      "[5 rows x 115 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Initial Inspection: ACS B08101 (Transportation by Age) ---\n",
    "print(\"\\n--- Initial Inspection: ACS B08101 ---\")\n",
    "print(\"\\nACS B08101 Columns:\")\n",
    "print(acs_b08101_df.columns.tolist()) # List all column names\n",
    "\n",
    "print(\"\\nACS B08101 Data Types and Non-Null Counts:\")\n",
    "print(acs_b08101_df.info()) # Get info again for clarity\n",
    "\n",
    "print(\"\\nMissing Values in ACS B08101:\")\n",
    "print(acs_b08101_df.isnull().sum()) # Count missing values per column\n",
    "\n",
    "print(\"\\nFirst 5 rows of ACS B08101:\")\n",
    "print(acs_b08101_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc547716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning ACS B08101 Data ---\n",
      "Dropped 1 'Unnamed' columns.\n",
      "Dropped 56 'Margin of Error' columns.\n",
      "Columns renamed to clean, snake_case format.\n",
      "Filtered to 23 key commuting by age columns.\n",
      "Numerical columns converted to int and NaNs filled with 0.\n",
      "\n",
      "--- ACS B08101 Data Cleaned ---\n",
      "Cleaned ACS B08101 DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 328 entries, 0 to 327\n",
      "Data columns (total 23 columns):\n",
      " #   Column                               Non-Null Count  Dtype \n",
      "---  ------                               --------------  ----- \n",
      " 0   geo_id                               328 non-null    object\n",
      " 1   geographic_area_name                 328 non-null    object\n",
      " 2   workers_total                        328 non-null    int32 \n",
      " 3   workers_age_16_to_19                 328 non-null    int32 \n",
      " 4   workers_age_20_to_24                 328 non-null    int32 \n",
      " 5   workers_age_25_to_44                 328 non-null    int32 \n",
      " 6   workers_age_45_to_54                 328 non-null    int32 \n",
      " 7   workers_age_55_to_59                 328 non-null    int32 \n",
      " 8   workers_age_60_to_64                 328 non-null    int32 \n",
      " 9   workers_age_65_plus                  328 non-null    int32 \n",
      " 10  commute_drove_alone_total            328 non-null    int32 \n",
      " 11  commute_carpooled_total              328 non-null    int32 \n",
      " 12  commute_public_transit_total         328 non-null    int32 \n",
      " 13  commute_public_transit_age_16_to_19  328 non-null    int32 \n",
      " 14  commute_public_transit_age_20_to_24  328 non-null    int32 \n",
      " 15  commute_public_transit_age_25_to_44  328 non-null    int32 \n",
      " 16  commute_public_transit_age_45_to_54  328 non-null    int32 \n",
      " 17  commute_public_transit_age_55_to_59  328 non-null    int32 \n",
      " 18  commute_public_transit_age_60_to_64  328 non-null    int32 \n",
      " 19  commute_public_transit_age_65_plus   328 non-null    int32 \n",
      " 20  commute_walked_total                 328 non-null    int32 \n",
      " 21  commute_other_means_total            328 non-null    int32 \n",
      " 22  commute_worked_from_home_total       328 non-null    int32 \n",
      "dtypes: int32(21), object(2)\n",
      "memory usage: 32.2+ KB\n",
      "None\n",
      "\n",
      "Cleaned ACS B08101 Head:\n",
      "                 geo_id                      geographic_area_name  \\\n",
      "0  1400000US39049000110  Census Tract 1.10; Franklin County; Ohio   \n",
      "1  1400000US39049000120  Census Tract 1.20; Franklin County; Ohio   \n",
      "2  1400000US39049000210  Census Tract 2.10; Franklin County; Ohio   \n",
      "3  1400000US39049000220  Census Tract 2.20; Franklin County; Ohio   \n",
      "4  1400000US39049000310  Census Tract 3.10; Franklin County; Ohio   \n",
      "\n",
      "   workers_total  workers_age_16_to_19  workers_age_20_to_24  \\\n",
      "0           2245                     0                    41   \n",
      "1           1963                    25                    13   \n",
      "2           1949                    36                    45   \n",
      "3           2405                    22                   119   \n",
      "4           1397                    17                    53   \n",
      "\n",
      "   workers_age_25_to_44  workers_age_45_to_54  workers_age_55_to_59  \\\n",
      "0                  1019                   485                   227   \n",
      "1                   804                   591                   135   \n",
      "2                   909                   433                   232   \n",
      "3                  1060                   428                   278   \n",
      "4                   840                   228                   110   \n",
      "\n",
      "   workers_age_60_to_64  workers_age_65_plus  ...  \\\n",
      "0                   138                  335  ...   \n",
      "1                   167                  228  ...   \n",
      "2                   153                  141  ...   \n",
      "3                   267                  231  ...   \n",
      "4                   106                   43  ...   \n",
      "\n",
      "   commute_public_transit_age_16_to_19  commute_public_transit_age_20_to_24  \\\n",
      "0                                    0                                    0   \n",
      "1                                    0                                    0   \n",
      "2                                    0                                    0   \n",
      "3                                    0                                   10   \n",
      "4                                    0                                    0   \n",
      "\n",
      "   commute_public_transit_age_25_to_44  commute_public_transit_age_45_to_54  \\\n",
      "0                                    0                                    0   \n",
      "1                                   28                                    8   \n",
      "2                                   72                                   38   \n",
      "3                                   29                                    0   \n",
      "4                                    0                                    0   \n",
      "\n",
      "   commute_public_transit_age_55_to_59  commute_public_transit_age_60_to_64  \\\n",
      "0                                    0                                    9   \n",
      "1                                    0                                    0   \n",
      "2                                    7                                    0   \n",
      "3                                    0                                    0   \n",
      "4                                    0                                    0   \n",
      "\n",
      "   commute_public_transit_age_65_plus  commute_walked_total  \\\n",
      "0                                   0                     9   \n",
      "1                                   0                    20   \n",
      "2                                  13                    52   \n",
      "3                                   0                    31   \n",
      "4                                   0                     0   \n",
      "\n",
      "   commute_other_means_total  commute_worked_from_home_total  \n",
      "0                        157                             463  \n",
      "1                         16                             734  \n",
      "2                         52                             613  \n",
      "3                         76                             576  \n",
      "4                         18                             223  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Clean ACS B08101 (Means of Transportation to Work by Age) Data ---\n",
    "print(\"\\n--- Cleaning ACS B08101 Data ---\")\n",
    "if acs_b08101_df is not None:\n",
    "    acs_b08101_cleaned_df = acs_b08101_df.copy() # Create a copy to work on\n",
    "\n",
    "    # Drop 'Unnamed' columns if they exist and are empty\n",
    "    cols_to_drop_unnamed = [col for col in acs_b08101_cleaned_df.columns if 'Unnamed' in col and acs_b08101_cleaned_df[col].isnull().all()]\n",
    "    if cols_to_drop_unnamed:\n",
    "        acs_b08101_cleaned_df = acs_b08101_cleaned_df.drop(columns=cols_to_drop_unnamed)\n",
    "        print(f\"Dropped {len(cols_to_drop_unnamed)} 'Unnamed' columns.\")\n",
    "\n",
    "    # Drop Margin of Error columns\n",
    "    cols_to_drop_moe = [col for col in acs_b08101_cleaned_df.columns if 'Margin of Error' in col]\n",
    "    acs_b08101_cleaned_df = acs_b08101_cleaned_df.drop(columns=cols_to_drop_moe)\n",
    "    print(f\"Dropped {len(cols_to_drop_moe)} 'Margin of Error' columns.\")\n",
    "\n",
    "    # --- Direct Mapping for B08101 Column Renaming ---\n",
    "    # This maps the EXACT original column names to your desired clean, snake_case names.\n",
    "    b08101_column_rename_map = {\n",
    "        'Geography': 'geo_id',\n",
    "        'Geographic Area Name': 'geographic_area_name',\n",
    "        \n",
    "        # Total Workers by Age Group (Universe: Workers 16 years and over)\n",
    "        'Estimate!!Total:': 'workers_total', # Overall total workers\n",
    "        'Estimate!!Total:!!16 to 19 years': 'workers_age_16_to_19',\n",
    "        'Estimate!!Total:!!20 to 24 years': 'workers_age_20_to_24',\n",
    "        'Estimate!!Total:!!25 to 44 years': 'workers_age_25_to_44',\n",
    "        'Estimate!!Total:!!45 to 54 years': 'workers_age_45_to_54',\n",
    "        'Estimate!!Total:!!55 to 59 years': 'workers_age_55_to_59',\n",
    "        'Estimate!!Total:!!60 to 64 years': 'workers_age_60_to_64',\n",
    "        'Estimate!!Total:!!65 years and over': 'workers_age_65_plus',\n",
    "\n",
    "        # Commute by Public Transportation (excluding taxicab) by Age Group\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):': 'commute_public_transit_total',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!16 to 19 years': 'commute_public_transit_age_16_to_19',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!20 to 24 years': 'commute_public_transit_age_20_to_24',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!25 to 44 years': 'commute_public_transit_age_25_to_44',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!45 to 54 years': 'commute_public_transit_age_45_to_54',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!55 to 59 years': 'commute_public_transit_age_55_to_59',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!60 to 64 years': 'commute_public_transit_age_60_to_64',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!65 years and over': 'commute_public_transit_age_65_plus',\n",
    "\n",
    "        # Commute by Car, Truck, or Van - Drove Alone by Age Group (for comparison)\n",
    "        'Estimate!!Total:!!Car, truck, or van - drove alone:': 'commute_drove_alone_total',\n",
    "        'Estimate!!Total:!!Car, truck, or van - drove alone:!!16 to 19 years': 'commute_drove_alone_age_16_to_19',\n",
    "        'Estimate!!Total:!!Car, truck, or van - drove alone:!!20 to 24 years': 'commute_drove_alone_age_20_to_24',\n",
    "        'Estimate!!Total:!!Car, truck, or van - drove alone:!!25 to 44 years': 'commute_drove_alone_age_25_to_44',\n",
    "        'Estimate!!Total:!!Car, truck, or van - drove alone:!!45 to 54 years': 'commute_drove_alone_age_45_to_54',\n",
    "        'Estimate!!Total:!!Car, truck, or van - drove alone:!!55 to 59 years': 'commute_drove_alone_age_55_to_59',\n",
    "        'Estimate!!Total:!!Car, truck, or van - drove alone:!!60 to 64 years': 'commute_drove_alone_age_60_to_64',\n",
    "        'Estimate!!Total:!!Car, truck, or van - drove alone:!!65 years and over': 'commute_drove_alone_age_65_plus',\n",
    "\n",
    "        # Commute by Worked from home by Age Group\n",
    "        'Estimate!!Total:!!Worked from home': 'commute_worked_from_home_total',\n",
    "        'Estimate!!Total:!!Worked from home!!16 to 19 years': 'commute_worked_from_home_age_16_to_19',\n",
    "        'Estimate!!Total:!!Worked from home!!20 to 24 years': 'commute_worked_from_home_age_20_to_24',\n",
    "        'Estimate!!Total:!!Worked from home!!25 to 44 years': 'commute_worked_from_home_age_25_to_44',\n",
    "        'Estimate!!Total:!!Worked from home!!45 to 54 years': 'commute_worked_from_home_age_45_to_54',\n",
    "        'Estimate!!Total:!!Worked from home!!55 to 59 years': 'commute_worked_from_home_age_55_to_59',\n",
    "        'Estimate!!Total:!!Worked from home!!60 to 64 years': 'commute_worked_from_home_age_60_to_64',\n",
    "        'Estimate!!Total:!!Worked from home!!65 years and over': 'commute_worked_from_home_age_65_plus',\n",
    "\n",
    "        # Other useful overall commute modes (not by age breakdown in this map, but their total is useful)\n",
    "        'Estimate!!Total:!!Car, truck, or van - carpooled:': 'commute_carpooled_total',\n",
    "        'Estimate!!Total:!!Walked:': 'commute_walked_total',\n",
    "        'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:': 'commute_other_means_total'\n",
    "    }\n",
    "\n",
    "    # Apply the direct renaming. Only rename columns that exist in our DataFrame.\n",
    "    acs_b08101_cleaned_df = acs_b08101_cleaned_df.rename(columns={k: v for k, v in b08101_column_rename_map.items() if k in acs_b08101_cleaned_df.columns})\n",
    "    print(\"Columns renamed to clean, snake_case format.\")\n",
    "\n",
    "    # --- Select Key Columns for Analysis from B08101 ---\n",
    "    # This list defines the specific columns we want to keep after renaming.\n",
    "    final_b08101_cols = [\n",
    "        'geo_id',\n",
    "        'geographic_area_name',\n",
    "        'workers_total', # Overall total workers 16+\n",
    "        \n",
    "        # Total Workers by Age Group\n",
    "        'workers_age_16_to_19',\n",
    "        'workers_age_20_to_24',\n",
    "        'workers_age_25_to_44',\n",
    "        'workers_age_45_to_54',\n",
    "        'workers_age_55_to_59',\n",
    "        'workers_age_60_to_64',\n",
    "        'workers_age_65_plus',\n",
    "\n",
    "        # Commute by Public Transportation (excluding taxicab) by Age Group\n",
    "        'commute_public_transit_total',\n",
    "        'commute_public_transit_age_16_to_19',\n",
    "        'commute_public_transit_age_20_to_24',\n",
    "        'commute_public_transit_age_25_to_44',\n",
    "        'commute_public_transit_age_45_to_54',\n",
    "        'commute_public_transit_age_55_to_59',\n",
    "        'commute_public_transit_age_60_to_64',\n",
    "        'commute_public_transit_age_65_plus',\n",
    "\n",
    "        # Other useful total commute modes\n",
    "        'commute_drove_alone_total',\n",
    "        'commute_carpooled_total',\n",
    "        'commute_walked_total',\n",
    "        'commute_worked_from_home_total',\n",
    "        'commute_other_means_total'\n",
    "    ]\n",
    "    acs_b08101_cleaned_df = acs_b08101_cleaned_df[acs_b08101_cleaned_df.columns.intersection(final_b08101_cols)].copy()\n",
    "    print(f\"Filtered to {len(acs_b08101_cleaned_df.columns)} key commuting by age columns.\")\n",
    "\n",
    "    # Convert all numerical columns to numeric and fill NaNs with 0\n",
    "    for col in acs_b08101_cleaned_df.columns:\n",
    "        if col not in ['geo_id', 'geographic_area_name']:\n",
    "            acs_b08101_cleaned_df[col] = pd.to_numeric(acs_b08101_cleaned_df[col], errors='coerce').fillna(0).astype(int)\n",
    "    print(\"Numerical columns converted to int and NaNs filled with 0.\")\n",
    "\n",
    "    print(\"\\n--- ACS B08101 Data Cleaned ---\")\n",
    "    print(\"Cleaned ACS B08101 DataFrame Info:\")\n",
    "    print(acs_b08101_cleaned_df.info())\n",
    "    print(\"\\nCleaned ACS B08101 Head:\")\n",
    "    print(acs_b08101_cleaned_df.head())\n",
    "\n",
    "else:\n",
    "    print(\"ACS B08101 DataFrame not loaded. Cleaning skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5fcf71",
   "metadata": {},
   "source": [
    "#### Cleaning ACS_B08119 (Means of Transportation to Work by Workers' Earnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43824e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initial Inspection: ACS B08119 ---\n",
      "\n",
      "ACS B08119 Columns:\n",
      "['Geography', 'Geographic Area Name', 'Estimate!!Total:', 'Margin of Error!!Total:', 'Estimate!!Total:!!$1 to $9,999 or loss', 'Margin of Error!!Total:!!$1 to $9,999 or loss', 'Estimate!!Total:!!$10,000 to $14,999', 'Margin of Error!!Total:!!$10,000 to $14,999', 'Estimate!!Total:!!$15,000 to $24,999', 'Margin of Error!!Total:!!$15,000 to $24,999', 'Estimate!!Total:!!$25,000 to $34,999', 'Margin of Error!!Total:!!$25,000 to $34,999', 'Estimate!!Total:!!$35,000 to $49,999', 'Margin of Error!!Total:!!$35,000 to $49,999', 'Estimate!!Total:!!$50,000 to $64,999', 'Margin of Error!!Total:!!$50,000 to $64,999', 'Estimate!!Total:!!$65,000 to $74,999', 'Margin of Error!!Total:!!$65,000 to $74,999', 'Estimate!!Total:!!$75,000 or more', 'Margin of Error!!Total:!!$75,000 or more', 'Estimate!!Total:!!Car, truck, or van - drove alone:', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!$1 to $9,999 or loss', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!$1 to $9,999 or loss', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!$10,000 to $14,999', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!$10,000 to $14,999', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!$15,000 to $24,999', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!$15,000 to $24,999', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!$25,000 to $34,999', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!$25,000 to $34,999', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!$35,000 to $49,999', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!$35,000 to $49,999', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!$50,000 to $64,999', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!$50,000 to $64,999', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!$65,000 to $74,999', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!$65,000 to $74,999', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!$75,000 or more', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!$75,000 or more', 'Estimate!!Total:!!Car, truck, or van - carpooled:', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!$1 to $9,999 or loss', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!$1 to $9,999 or loss', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!$10,000 to $14,999', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!$10,000 to $14,999', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!$15,000 to $24,999', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!$15,000 to $24,999', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!$25,000 to $34,999', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!$25,000 to $34,999', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!$35,000 to $49,999', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!$35,000 to $49,999', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!$50,000 to $64,999', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!$50,000 to $64,999', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!$65,000 to $74,999', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!$65,000 to $74,999', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!$75,000 or more', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!$75,000 or more', 'Estimate!!Total:!!Public transportation (excluding taxicab):', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!$1 to $9,999 or loss', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!$1 to $9,999 or loss', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!$10,000 to $14,999', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!$10,000 to $14,999', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!$15,000 to $24,999', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!$15,000 to $24,999', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!$25,000 to $34,999', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!$25,000 to $34,999', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!$35,000 to $49,999', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!$35,000 to $49,999', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!$50,000 to $64,999', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!$50,000 to $64,999', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!$65,000 to $74,999', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!$65,000 to $74,999', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!$75,000 or more', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!$75,000 or more', 'Estimate!!Total:!!Walked:', 'Margin of Error!!Total:!!Walked:', 'Estimate!!Total:!!Walked:!!$1 to $9,999 or loss', 'Margin of Error!!Total:!!Walked:!!$1 to $9,999 or loss', 'Estimate!!Total:!!Walked:!!$10,000 to $14,999', 'Margin of Error!!Total:!!Walked:!!$10,000 to $14,999', 'Estimate!!Total:!!Walked:!!$15,000 to $24,999', 'Margin of Error!!Total:!!Walked:!!$15,000 to $24,999', 'Estimate!!Total:!!Walked:!!$25,000 to $34,999', 'Margin of Error!!Total:!!Walked:!!$25,000 to $34,999', 'Estimate!!Total:!!Walked:!!$35,000 to $49,999', 'Margin of Error!!Total:!!Walked:!!$35,000 to $49,999', 'Estimate!!Total:!!Walked:!!$50,000 to $64,999', 'Margin of Error!!Total:!!Walked:!!$50,000 to $64,999', 'Estimate!!Total:!!Walked:!!$65,000 to $74,999', 'Margin of Error!!Total:!!Walked:!!$65,000 to $74,999', 'Estimate!!Total:!!Walked:!!$75,000 or more', 'Margin of Error!!Total:!!Walked:!!$75,000 or more', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$1 to $9,999 or loss', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$1 to $9,999 or loss', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$10,000 to $14,999', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$10,000 to $14,999', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$15,000 to $24,999', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$15,000 to $24,999', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$25,000 to $34,999', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$25,000 to $34,999', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$35,000 to $49,999', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$35,000 to $49,999', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$50,000 to $64,999', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$50,000 to $64,999', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$65,000 to $74,999', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$65,000 to $74,999', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$75,000 or more', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!$75,000 or more', 'Estimate!!Total:!!Worked from home:', 'Margin of Error!!Total:!!Worked from home:', 'Estimate!!Total:!!Worked from home:!!$1 to $9,999 or loss', 'Margin of Error!!Total:!!Worked from home:!!$1 to $9,999 or loss', 'Estimate!!Total:!!Worked from home:!!$10,000 to $14,999', 'Margin of Error!!Total:!!Worked from home:!!$10,000 to $14,999', 'Estimate!!Total:!!Worked from home:!!$15,000 to $24,999', 'Margin of Error!!Total:!!Worked from home:!!$15,000 to $24,999', 'Estimate!!Total:!!Worked from home:!!$25,000 to $34,999', 'Margin of Error!!Total:!!Worked from home:!!$25,000 to $34,999', 'Estimate!!Total:!!Worked from home:!!$35,000 to $49,999', 'Margin of Error!!Total:!!Worked from home:!!$35,000 to $49,999', 'Estimate!!Total:!!Worked from home:!!$50,000 to $64,999', 'Margin of Error!!Total:!!Worked from home:!!$50,000 to $64,999', 'Estimate!!Total:!!Worked from home:!!$65,000 to $74,999', 'Margin of Error!!Total:!!Worked from home:!!$65,000 to $74,999', 'Estimate!!Total:!!Worked from home:!!$75,000 or more', 'Margin of Error!!Total:!!Worked from home:!!$75,000 or more', 'Unnamed: 128']\n",
      "\n",
      "ACS B08119 Data Types and Non-Null Counts:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 328 entries, 0 to 327\n",
      "Columns: 129 entries, Geography to Unnamed: 128\n",
      "dtypes: float64(1), int64(126), object(2)\n",
      "memory usage: 330.7+ KB\n",
      "None\n",
      "\n",
      "Missing Values in ACS B08119:\n",
      "Geography                                                           0\n",
      "Geographic Area Name                                                0\n",
      "Estimate!!Total:                                                    0\n",
      "Margin of Error!!Total:                                             0\n",
      "Estimate!!Total:!!$1 to $9,999 or loss                              0\n",
      "                                                                 ... \n",
      "Estimate!!Total:!!Worked from home:!!$65,000 to $74,999             0\n",
      "Margin of Error!!Total:!!Worked from home:!!$65,000 to $74,999      0\n",
      "Estimate!!Total:!!Worked from home:!!$75,000 or more                0\n",
      "Margin of Error!!Total:!!Worked from home:!!$75,000 or more         0\n",
      "Unnamed: 128                                                      328\n",
      "Length: 129, dtype: int64\n",
      "\n",
      "First 5 rows of ACS B08119:\n",
      "              Geography                      Geographic Area Name  \\\n",
      "0  1400000US39049000110  Census Tract 1.10; Franklin County; Ohio   \n",
      "1  1400000US39049000120  Census Tract 1.20; Franklin County; Ohio   \n",
      "2  1400000US39049000210  Census Tract 2.10; Franklin County; Ohio   \n",
      "3  1400000US39049000220  Census Tract 2.20; Franklin County; Ohio   \n",
      "4  1400000US39049000310  Census Tract 3.10; Franklin County; Ohio   \n",
      "\n",
      "   Estimate!!Total:  Margin of Error!!Total:  \\\n",
      "0              2245                      304   \n",
      "1              1963                      248   \n",
      "2              1949                      288   \n",
      "3              2405                      213   \n",
      "4              1397                      185   \n",
      "\n",
      "   Estimate!!Total:!!$1 to $9,999 or loss  \\\n",
      "0                                     130   \n",
      "1                                     188   \n",
      "2                                      90   \n",
      "3                                     206   \n",
      "4                                     123   \n",
      "\n",
      "   Margin of Error!!Total:!!$1 to $9,999 or loss  \\\n",
      "0                                             45   \n",
      "1                                             80   \n",
      "2                                             68   \n",
      "3                                             89   \n",
      "4                                             88   \n",
      "\n",
      "   Estimate!!Total:!!$10,000 to $14,999  \\\n",
      "0                                    88   \n",
      "1                                    20   \n",
      "2                                    45   \n",
      "3                                    85   \n",
      "4                                   104   \n",
      "\n",
      "   Margin of Error!!Total:!!$10,000 to $14,999  \\\n",
      "0                                           37   \n",
      "1                                           16   \n",
      "2                                           37   \n",
      "3                                           59   \n",
      "4                                           53   \n",
      "\n",
      "   Estimate!!Total:!!$15,000 to $24,999  \\\n",
      "0                                   100   \n",
      "1                                    79   \n",
      "2                                   140   \n",
      "3                                   168   \n",
      "4                                   166   \n",
      "\n",
      "   Margin of Error!!Total:!!$15,000 to $24,999  ...  \\\n",
      "0                                           52  ...   \n",
      "1                                           56  ...   \n",
      "2                                           74  ...   \n",
      "3                                           81  ...   \n",
      "4                                           92  ...   \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home:!!$25,000 to $34,999  \\\n",
      "0                                                 13                \n",
      "1                                                 13                \n",
      "2                                                 51                \n",
      "3                                                 24                \n",
      "4                                                 76                \n",
      "\n",
      "   Estimate!!Total:!!Worked from home:!!$35,000 to $49,999  \\\n",
      "0                                                 23         \n",
      "1                                                105         \n",
      "2                                                 44         \n",
      "3                                                 74         \n",
      "4                                                 60         \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home:!!$35,000 to $49,999  \\\n",
      "0                                                 24                \n",
      "1                                                 93                \n",
      "2                                                 48                \n",
      "3                                                 63                \n",
      "4                                                 43                \n",
      "\n",
      "   Estimate!!Total:!!Worked from home:!!$50,000 to $64,999  \\\n",
      "0                                                129         \n",
      "1                                                 16         \n",
      "2                                                 44         \n",
      "3                                                 66         \n",
      "4                                                 33         \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home:!!$50,000 to $64,999  \\\n",
      "0                                                101                \n",
      "1                                                 18                \n",
      "2                                                 36                \n",
      "3                                                 62                \n",
      "4                                                 27                \n",
      "\n",
      "   Estimate!!Total:!!Worked from home:!!$65,000 to $74,999  \\\n",
      "0                                                 77         \n",
      "1                                                 17         \n",
      "2                                                 18         \n",
      "3                                                 21         \n",
      "4                                                  0         \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home:!!$65,000 to $74,999  \\\n",
      "0                                                 52                \n",
      "1                                                 19                \n",
      "2                                                 21                \n",
      "3                                                 23                \n",
      "4                                                 13                \n",
      "\n",
      "   Estimate!!Total:!!Worked from home:!!$75,000 or more  \\\n",
      "0                                                204      \n",
      "1                                                487      \n",
      "2                                                369      \n",
      "3                                                307      \n",
      "4                                                 27      \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home:!!$75,000 or more  Unnamed: 128  \n",
      "0                                                 75                     NaN  \n",
      "1                                                185                     NaN  \n",
      "2                                                146                     NaN  \n",
      "3                                                 86                     NaN  \n",
      "4                                                 29                     NaN  \n",
      "\n",
      "[5 rows x 129 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Initial Inspection: ACS B08119 (Transportation by Earnings) ---\n",
    "print(\"\\n--- Initial Inspection: ACS B08119 ---\")\n",
    "print(\"\\nACS B08119 Columns:\")\n",
    "print(acs_b08119_df.columns.tolist()) # List all column names\n",
    "\n",
    "print(\"\\nACS B08119 Data Types and Non-Null Counts:\")\n",
    "print(acs_b08119_df.info()) # Get info again for clarity\n",
    "\n",
    "print(\"\\nMissing Values in ACS B08119:\")\n",
    "print(acs_b08119_df.isnull().sum()) # Count missing values per column\n",
    "\n",
    "print(\"\\nFirst 5 rows of ACS B08119:\")\n",
    "print(acs_b08119_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6966fb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning ACS B08119 Data ---\n",
      "Dropped 1 'Unnamed' columns.\n",
      "Dropped 63 'Margin of Error' columns.\n",
      "Columns renamed to clean, snake_case format.\n",
      "Filtered to 25 key earnings and commuting columns.\n",
      "Numerical columns converted to int and NaNs filled with 0.\n",
      "\n",
      "--- ACS B08119 Data Cleaned ---\n",
      "Cleaned ACS B08119 DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 328 entries, 0 to 327\n",
      "Data columns (total 25 columns):\n",
      " #   Column                                          Non-Null Count  Dtype \n",
      "---  ------                                          --------------  ----- \n",
      " 0   geo_id                                          328 non-null    object\n",
      " 1   geographic_area_name                            328 non-null    object\n",
      " 2   workers_earnings_total                          328 non-null    int32 \n",
      " 3   workers_earnings_1_to_9999                      328 non-null    int32 \n",
      " 4   workers_earnings_10000_to_14999                 328 non-null    int32 \n",
      " 5   workers_earnings_15000_to_24999                 328 non-null    int32 \n",
      " 6   workers_earnings_25000_to_34999                 328 non-null    int32 \n",
      " 7   workers_earnings_35000_to_49999                 328 non-null    int32 \n",
      " 8   workers_earnings_50000_to_64999                 328 non-null    int32 \n",
      " 9   workers_earnings_65000_to_74999                 328 non-null    int32 \n",
      " 10  workers_earnings_75000_plus                     328 non-null    int32 \n",
      " 11  commute_drove_alone_total                       328 non-null    int32 \n",
      " 12  commute_carpooled_total                         328 non-null    int32 \n",
      " 13  commute_public_transit_total                    328 non-null    int32 \n",
      " 14  commute_public_transit_earnings_1_to_9999       328 non-null    int32 \n",
      " 15  commute_public_transit_earnings_10000_to_14999  328 non-null    int32 \n",
      " 16  commute_public_transit_earnings_15000_to_24999  328 non-null    int32 \n",
      " 17  commute_public_transit_earnings_25000_to_34999  328 non-null    int32 \n",
      " 18  commute_public_transit_earnings_35000_to_49999  328 non-null    int32 \n",
      " 19  commute_public_transit_earnings_50000_to_64999  328 non-null    int32 \n",
      " 20  commute_public_transit_earnings_65000_to_74999  328 non-null    int32 \n",
      " 21  commute_public_transit_earnings_75000_plus      328 non-null    int32 \n",
      " 22  commute_walked_total                            328 non-null    int32 \n",
      " 23  commute_other_means_total                       328 non-null    int32 \n",
      " 24  commute_worked_from_home_total                  328 non-null    int32 \n",
      "dtypes: int32(23), object(2)\n",
      "memory usage: 34.7+ KB\n",
      "None\n",
      "\n",
      "Cleaned ACS B08119 Head:\n",
      "                 geo_id                      geographic_area_name  \\\n",
      "0  1400000US39049000110  Census Tract 1.10; Franklin County; Ohio   \n",
      "1  1400000US39049000120  Census Tract 1.20; Franklin County; Ohio   \n",
      "2  1400000US39049000210  Census Tract 2.10; Franklin County; Ohio   \n",
      "3  1400000US39049000220  Census Tract 2.20; Franklin County; Ohio   \n",
      "4  1400000US39049000310  Census Tract 3.10; Franklin County; Ohio   \n",
      "\n",
      "   workers_earnings_total  workers_earnings_1_to_9999  \\\n",
      "0                    2245                         130   \n",
      "1                    1963                         188   \n",
      "2                    1949                          90   \n",
      "3                    2405                         206   \n",
      "4                    1397                         123   \n",
      "\n",
      "   workers_earnings_10000_to_14999  workers_earnings_15000_to_24999  \\\n",
      "0                               88                              100   \n",
      "1                               20                               79   \n",
      "2                               45                              140   \n",
      "3                               85                              168   \n",
      "4                              104                              166   \n",
      "\n",
      "   workers_earnings_25000_to_34999  workers_earnings_35000_to_49999  \\\n",
      "0                               65                              225   \n",
      "1                               69                              227   \n",
      "2                              166                              209   \n",
      "3                               83                              245   \n",
      "4                              170                              289   \n",
      "\n",
      "   workers_earnings_50000_to_64999  workers_earnings_65000_to_74999  ...  \\\n",
      "0                              388                              240  ...   \n",
      "1                              116                              106  ...   \n",
      "2                              123                              127  ...   \n",
      "3                              365                              116  ...   \n",
      "4                              315                               98  ...   \n",
      "\n",
      "   commute_public_transit_earnings_10000_to_14999  \\\n",
      "0                                               0   \n",
      "1                                               0   \n",
      "2                                               0   \n",
      "3                                               0   \n",
      "4                                               0   \n",
      "\n",
      "   commute_public_transit_earnings_15000_to_24999  \\\n",
      "0                                               0   \n",
      "1                                               0   \n",
      "2                                               0   \n",
      "3                                               0   \n",
      "4                                               0   \n",
      "\n",
      "   commute_public_transit_earnings_25000_to_34999  \\\n",
      "0                                               0   \n",
      "1                                              28   \n",
      "2                                               0   \n",
      "3                                               0   \n",
      "4                                               0   \n",
      "\n",
      "   commute_public_transit_earnings_35000_to_49999  \\\n",
      "0                                               0   \n",
      "1                                               0   \n",
      "2                                              62   \n",
      "3                                              10   \n",
      "4                                               0   \n",
      "\n",
      "   commute_public_transit_earnings_50000_to_64999  \\\n",
      "0                                               0   \n",
      "1                                               0   \n",
      "2                                               0   \n",
      "3                                              21   \n",
      "4                                               0   \n",
      "\n",
      "   commute_public_transit_earnings_65000_to_74999  \\\n",
      "0                                               0   \n",
      "1                                               0   \n",
      "2                                               0   \n",
      "3                                               0   \n",
      "4                                               0   \n",
      "\n",
      "   commute_public_transit_earnings_75000_plus  commute_walked_total  \\\n",
      "0                                           0                     9   \n",
      "1                                           8                    20   \n",
      "2                                          68                    52   \n",
      "3                                           8                    31   \n",
      "4                                           0                     0   \n",
      "\n",
      "   commute_other_means_total  commute_worked_from_home_total  \n",
      "0                        157                             463  \n",
      "1                         16                             734  \n",
      "2                         52                             613  \n",
      "3                         76                             576  \n",
      "4                         18                             223  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Clean ACS B08119 (Means of Transportation to Work by Workers' Earnings) Data ---\n",
    "print(\"\\n--- Cleaning ACS B08119 Data ---\")\n",
    "if acs_b08119_df is not None:\n",
    "    acs_b08119_cleaned_df = acs_b08119_df.copy() # Create a copy to work on\n",
    "\n",
    "    # Drop 'Unnamed' columns if they exist and are empty\n",
    "    cols_to_drop_unnamed = [col for col in acs_b08119_cleaned_df.columns if 'Unnamed' in col and acs_b08119_cleaned_df[col].isnull().all()]\n",
    "    if cols_to_drop_unnamed:\n",
    "        acs_b08119_cleaned_df = acs_b08119_cleaned_df.drop(columns=cols_to_drop_unnamed)\n",
    "        print(f\"Dropped {len(cols_to_drop_unnamed)} 'Unnamed' columns.\")\n",
    "\n",
    "    # Drop Margin of Error columns\n",
    "    cols_to_drop_moe = [col for col in acs_b08119_cleaned_df.columns if 'Margin of Error' in col]\n",
    "    acs_b08119_cleaned_df = acs_b08119_cleaned_df.drop(columns=cols_to_drop_moe)\n",
    "    print(f\"Dropped {len(cols_to_drop_moe)} 'Margin of Error' columns.\")\n",
    "\n",
    "    # --- Direct Mapping for B08119 Column Renaming ---\n",
    "    # This maps the EXACT original column names to your desired clean, snake_case names.\n",
    "    b08119_column_rename_map = {\n",
    "        'Geography': 'geo_id',\n",
    "        'Geographic Area Name': 'geographic_area_name',\n",
    "        \n",
    "        # Total Workers by Earnings (Universe: Workers 16 years and over with earnings)\n",
    "        'Estimate!!Total:': 'workers_earnings_total', # Overall total workers with earnings\n",
    "        'Estimate!!Total:!!$1 to $9,999 or loss': 'workers_earnings_1_to_9999',\n",
    "        'Estimate!!Total:!!$10,000 to $14,999': 'workers_earnings_10000_to_14999',\n",
    "        'Estimate!!Total:!!$15,000 to $24,999': 'workers_earnings_15000_to_24999',\n",
    "        'Estimate!!Total:!!$25,000 to $34,999': 'workers_earnings_25000_to_34999',\n",
    "        'Estimate!!Total:!!$35,000 to $49,999': 'workers_earnings_35000_to_49999',\n",
    "        'Estimate!!Total:!!$50,000 to $64,999': 'workers_earnings_50000_to_64999',\n",
    "        'Estimate!!Total:!!$65,000 to $74,999': 'workers_earnings_65000_to_74999',\n",
    "        'Estimate!!Total:!!$75,000 or more': 'workers_earnings_75000_plus',\n",
    "\n",
    "        # Commute by Public Transportation (excluding taxicab) by Earnings Group\n",
    "        # These are crucial for understanding who uses public transit based on income.\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):': 'commute_public_transit_total', # Total public transit commuters (all incomes)\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!$1 to $9,999 or loss': 'commute_public_transit_earnings_1_to_9999',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!$10,000 to $14,999': 'commute_public_transit_earnings_10000_to_14999',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!$15,000 to $24,999': 'commute_public_transit_earnings_15000_to_24999',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!$25,000 to $34,999': 'commute_public_transit_earnings_25000_to_34999',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!$35,000 to $49,999': 'commute_public_transit_earnings_35000_to_49999',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!$50,000 to $64,999': 'commute_public_transit_earnings_50000_to_64999',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!$65,000 to $74,999': 'commute_public_transit_earnings_65000_to_74999',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!$75,000 or more': 'commute_public_transit_earnings_75000_plus',\n",
    "\n",
    "        # Other useful total commute modes (not broken down by earnings here, but overall)\n",
    "        'Estimate!!Total:!!Car, truck, or van - drove alone:': 'commute_drove_alone_total',\n",
    "        'Estimate!!Total:!!Car, truck, or van - carpooled:': 'commute_carpooled_total',\n",
    "        'Estimate!!Total:!!Walked:': 'commute_walked_total',\n",
    "        'Estimate!!Total:!!Worked from home:': 'commute_worked_from_home_total',\n",
    "        'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:': 'commute_other_means_total'\n",
    "    }\n",
    "\n",
    "    # Apply the direct renaming. Only rename columns that exist in our DataFrame.\n",
    "    acs_b08119_cleaned_df = acs_b08119_cleaned_df.rename(columns={k: v for k, v in b08119_column_rename_map.items() if k in acs_b08119_cleaned_df.columns})\n",
    "    print(\"Columns renamed to clean, snake_case format.\")\n",
    "\n",
    "    # --- Select Key Columns for Analysis from B08119 ---\n",
    "    final_b08119_cols = [\n",
    "        'geo_id',\n",
    "        'geographic_area_name',\n",
    "        'workers_earnings_total',\n",
    "        'workers_earnings_1_to_9999',\n",
    "        'workers_earnings_10000_to_14999',\n",
    "        'workers_earnings_15000_to_24999',\n",
    "        'workers_earnings_25000_to_34999',\n",
    "        'workers_earnings_35000_to_49999',\n",
    "        'workers_earnings_50000_to_64999',\n",
    "        'workers_earnings_65000_to_74999',\n",
    "        'workers_earnings_75000_plus',\n",
    "        'commute_public_transit_total',\n",
    "        'commute_public_transit_earnings_1_to_9999',\n",
    "        'commute_public_transit_earnings_10000_to_14999',\n",
    "        'commute_public_transit_earnings_15000_to_24999',\n",
    "        'commute_public_transit_earnings_25000_to_34999',\n",
    "        'commute_public_transit_earnings_35000_to_49999',\n",
    "        'commute_public_transit_earnings_50000_to_64999',\n",
    "        'commute_public_transit_earnings_65000_to_74999',\n",
    "        'commute_public_transit_earnings_75000_plus',\n",
    "        'commute_drove_alone_total',\n",
    "        'commute_carpooled_total',\n",
    "        'commute_walked_total',\n",
    "        'commute_worked_from_home_total',\n",
    "        'commute_other_means_total'\n",
    "    ]\n",
    "    acs_b08119_cleaned_df = acs_b08119_cleaned_df[acs_b08119_cleaned_df.columns.intersection(final_b08119_cols)].copy()\n",
    "    print(f\"Filtered to {len(acs_b08119_cleaned_df.columns)} key earnings and commuting columns.\")\n",
    "\n",
    "    # Convert all numerical columns to numeric and fill NaNs with 0\n",
    "    for col in acs_b08119_cleaned_df.columns:\n",
    "        if col not in ['geo_id', 'geographic_area_name']:\n",
    "            acs_b08119_cleaned_df[col] = pd.to_numeric(acs_b08119_cleaned_df[col], errors='coerce').fillna(0).astype(int)\n",
    "    print(\"Numerical columns converted to int and NaNs filled with 0.\")\n",
    "\n",
    "    print(\"\\n--- ACS B08119 Data Cleaned ---\")\n",
    "    print(\"Cleaned ACS B08119 DataFrame Info:\")\n",
    "    print(acs_b08119_cleaned_df.info())\n",
    "    print(\"\\nCleaned ACS B08119 Head:\")\n",
    "    print(acs_b08119_cleaned_df.head())\n",
    "\n",
    "else:\n",
    "    print(\"ACS B08119 DataFrame not loaded. Cleaning skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5987becd",
   "metadata": {},
   "source": [
    "#### Cleaning ACS_B08122 (Means of Transportation to Work by Poverty Status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79f6fba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initial Inspection: ACS B08122 ---\n",
      "\n",
      "ACS B08122 Columns:\n",
      "['Geography', 'Geographic Area Name', 'Estimate!!Total:', 'Margin of Error!!Total:', 'Estimate!!Total:!!Below 100 percent of the poverty level', 'Margin of Error!!Total:!!Below 100 percent of the poverty level', 'Estimate!!Total:!!100 to 149 percent of the poverty level', 'Margin of Error!!Total:!!100 to 149 percent of the poverty level', 'Estimate!!Total:!!At or above 150 percent of the poverty level', 'Margin of Error!!Total:!!At or above 150 percent of the poverty level', 'Estimate!!Total:!!Car, truck, or van - drove alone:', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!Below 100 percent of the poverty level', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!Below 100 percent of the poverty level', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!100 to 149 percent of the poverty level', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!100 to 149 percent of the poverty level', 'Estimate!!Total:!!Car, truck, or van - drove alone:!!At or above 150 percent of the poverty level', 'Margin of Error!!Total:!!Car, truck, or van - drove alone:!!At or above 150 percent of the poverty level', 'Estimate!!Total:!!Car, truck, or van - carpooled:', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!Below 100 percent of the poverty level', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!Below 100 percent of the poverty level', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!100 to 149 percent of the poverty level', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!100 to 149 percent of the poverty level', 'Estimate!!Total:!!Car, truck, or van - carpooled:!!At or above 150 percent of the poverty level', 'Margin of Error!!Total:!!Car, truck, or van - carpooled:!!At or above 150 percent of the poverty level', 'Estimate!!Total:!!Public transportation (excluding taxicab):', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!Below 100 percent of the poverty level', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!Below 100 percent of the poverty level', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!100 to 149 percent of the poverty level', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!100 to 149 percent of the poverty level', 'Estimate!!Total:!!Public transportation (excluding taxicab):!!At or above 150 percent of the poverty level', 'Margin of Error!!Total:!!Public transportation (excluding taxicab):!!At or above 150 percent of the poverty level', 'Estimate!!Total:!!Walked:', 'Margin of Error!!Total:!!Walked:', 'Estimate!!Total:!!Walked:!!Below 100 percent of the poverty level', 'Margin of Error!!Total:!!Walked:!!Below 100 percent of the poverty level', 'Estimate!!Total:!!Walked:!!100 to 149 percent of the poverty level', 'Margin of Error!!Total:!!Walked:!!100 to 149 percent of the poverty level', 'Estimate!!Total:!!Walked:!!At or above 150 percent of the poverty level', 'Margin of Error!!Total:!!Walked:!!At or above 150 percent of the poverty level', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!Below 100 percent of the poverty level', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!Below 100 percent of the poverty level', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!100 to 149 percent of the poverty level', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!100 to 149 percent of the poverty level', 'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!At or above 150 percent of the poverty level', 'Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!At or above 150 percent of the poverty level', 'Estimate!!Total:!!Worked from home', 'Margin of Error!!Total:!!Worked from home', 'Estimate!!Total:!!Worked from home!!Below 100 percent of the poverty level', 'Margin of Error!!Total:!!Worked from home!!Below 100 percent of the poverty level', 'Estimate!!Total:!!Worked from home!!100 to 149 percent of the poverty level', 'Margin of Error!!Total:!!Worked from home!!100 to 149 percent of the poverty level', 'Estimate!!Total:!!Worked from home!!At or above 150 percent of the poverty level', 'Margin of Error!!Total:!!Worked from home!!At or above 150 percent of the poverty level', 'Unnamed: 58']\n",
      "\n",
      "ACS B08122 Data Types and Non-Null Counts:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 328 entries, 0 to 327\n",
      "Data columns (total 59 columns):\n",
      " #   Column                                                                                                                Non-Null Count  Dtype  \n",
      "---  ------                                                                                                                --------------  -----  \n",
      " 0   Geography                                                                                                             328 non-null    object \n",
      " 1   Geographic Area Name                                                                                                  328 non-null    object \n",
      " 2   Estimate!!Total:                                                                                                      328 non-null    int64  \n",
      " 3   Margin of Error!!Total:                                                                                               328 non-null    int64  \n",
      " 4   Estimate!!Total:!!Below 100 percent of the poverty level                                                              328 non-null    int64  \n",
      " 5   Margin of Error!!Total:!!Below 100 percent of the poverty level                                                       328 non-null    int64  \n",
      " 6   Estimate!!Total:!!100 to 149 percent of the poverty level                                                             328 non-null    int64  \n",
      " 7   Margin of Error!!Total:!!100 to 149 percent of the poverty level                                                      328 non-null    int64  \n",
      " 8   Estimate!!Total:!!At or above 150 percent of the poverty level                                                        328 non-null    int64  \n",
      " 9   Margin of Error!!Total:!!At or above 150 percent of the poverty level                                                 328 non-null    int64  \n",
      " 10  Estimate!!Total:!!Car, truck, or van - drove alone:                                                                   328 non-null    int64  \n",
      " 11  Margin of Error!!Total:!!Car, truck, or van - drove alone:                                                            328 non-null    int64  \n",
      " 12  Estimate!!Total:!!Car, truck, or van - drove alone:!!Below 100 percent of the poverty level                           328 non-null    int64  \n",
      " 13  Margin of Error!!Total:!!Car, truck, or van - drove alone:!!Below 100 percent of the poverty level                    328 non-null    int64  \n",
      " 14  Estimate!!Total:!!Car, truck, or van - drove alone:!!100 to 149 percent of the poverty level                          328 non-null    int64  \n",
      " 15  Margin of Error!!Total:!!Car, truck, or van - drove alone:!!100 to 149 percent of the poverty level                   328 non-null    int64  \n",
      " 16  Estimate!!Total:!!Car, truck, or van - drove alone:!!At or above 150 percent of the poverty level                     328 non-null    int64  \n",
      " 17  Margin of Error!!Total:!!Car, truck, or van - drove alone:!!At or above 150 percent of the poverty level              328 non-null    int64  \n",
      " 18  Estimate!!Total:!!Car, truck, or van - carpooled:                                                                     328 non-null    int64  \n",
      " 19  Margin of Error!!Total:!!Car, truck, or van - carpooled:                                                              328 non-null    int64  \n",
      " 20  Estimate!!Total:!!Car, truck, or van - carpooled:!!Below 100 percent of the poverty level                             328 non-null    int64  \n",
      " 21  Margin of Error!!Total:!!Car, truck, or van - carpooled:!!Below 100 percent of the poverty level                      328 non-null    int64  \n",
      " 22  Estimate!!Total:!!Car, truck, or van - carpooled:!!100 to 149 percent of the poverty level                            328 non-null    int64  \n",
      " 23  Margin of Error!!Total:!!Car, truck, or van - carpooled:!!100 to 149 percent of the poverty level                     328 non-null    int64  \n",
      " 24  Estimate!!Total:!!Car, truck, or van - carpooled:!!At or above 150 percent of the poverty level                       328 non-null    int64  \n",
      " 25  Margin of Error!!Total:!!Car, truck, or van - carpooled:!!At or above 150 percent of the poverty level                328 non-null    int64  \n",
      " 26  Estimate!!Total:!!Public transportation (excluding taxicab):                                                          328 non-null    int64  \n",
      " 27  Margin of Error!!Total:!!Public transportation (excluding taxicab):                                                   328 non-null    int64  \n",
      " 28  Estimate!!Total:!!Public transportation (excluding taxicab):!!Below 100 percent of the poverty level                  328 non-null    int64  \n",
      " 29  Margin of Error!!Total:!!Public transportation (excluding taxicab):!!Below 100 percent of the poverty level           328 non-null    int64  \n",
      " 30  Estimate!!Total:!!Public transportation (excluding taxicab):!!100 to 149 percent of the poverty level                 328 non-null    int64  \n",
      " 31  Margin of Error!!Total:!!Public transportation (excluding taxicab):!!100 to 149 percent of the poverty level          328 non-null    int64  \n",
      " 32  Estimate!!Total:!!Public transportation (excluding taxicab):!!At or above 150 percent of the poverty level            328 non-null    int64  \n",
      " 33  Margin of Error!!Total:!!Public transportation (excluding taxicab):!!At or above 150 percent of the poverty level     328 non-null    int64  \n",
      " 34  Estimate!!Total:!!Walked:                                                                                             328 non-null    int64  \n",
      " 35  Margin of Error!!Total:!!Walked:                                                                                      328 non-null    int64  \n",
      " 36  Estimate!!Total:!!Walked:!!Below 100 percent of the poverty level                                                     328 non-null    int64  \n",
      " 37  Margin of Error!!Total:!!Walked:!!Below 100 percent of the poverty level                                              328 non-null    int64  \n",
      " 38  Estimate!!Total:!!Walked:!!100 to 149 percent of the poverty level                                                    328 non-null    int64  \n",
      " 39  Margin of Error!!Total:!!Walked:!!100 to 149 percent of the poverty level                                             328 non-null    int64  \n",
      " 40  Estimate!!Total:!!Walked:!!At or above 150 percent of the poverty level                                               328 non-null    int64  \n",
      " 41  Margin of Error!!Total:!!Walked:!!At or above 150 percent of the poverty level                                        328 non-null    int64  \n",
      " 42  Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:                                                       328 non-null    int64  \n",
      " 43  Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:                                                328 non-null    int64  \n",
      " 44  Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!Below 100 percent of the poverty level               328 non-null    int64  \n",
      " 45  Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!Below 100 percent of the poverty level        328 non-null    int64  \n",
      " 46  Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!100 to 149 percent of the poverty level              328 non-null    int64  \n",
      " 47  Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!100 to 149 percent of the poverty level       328 non-null    int64  \n",
      " 48  Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!At or above 150 percent of the poverty level         328 non-null    int64  \n",
      " 49  Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!At or above 150 percent of the poverty level  328 non-null    int64  \n",
      " 50  Estimate!!Total:!!Worked from home                                                                                    328 non-null    int64  \n",
      " 51  Margin of Error!!Total:!!Worked from home                                                                             328 non-null    int64  \n",
      " 52  Estimate!!Total:!!Worked from home!!Below 100 percent of the poverty level                                            328 non-null    int64  \n",
      " 53  Margin of Error!!Total:!!Worked from home!!Below 100 percent of the poverty level                                     328 non-null    int64  \n",
      " 54  Estimate!!Total:!!Worked from home!!100 to 149 percent of the poverty level                                           328 non-null    int64  \n",
      " 55  Margin of Error!!Total:!!Worked from home!!100 to 149 percent of the poverty level                                    328 non-null    int64  \n",
      " 56  Estimate!!Total:!!Worked from home!!At or above 150 percent of the poverty level                                      328 non-null    int64  \n",
      " 57  Margin of Error!!Total:!!Worked from home!!At or above 150 percent of the poverty level                               328 non-null    int64  \n",
      " 58  Unnamed: 58                                                                                                           0 non-null      float64\n",
      "dtypes: float64(1), int64(56), object(2)\n",
      "memory usage: 151.3+ KB\n",
      "None\n",
      "\n",
      "Missing Values in ACS B08122:\n",
      "Geography                                                                                                                 0\n",
      "Geographic Area Name                                                                                                      0\n",
      "Estimate!!Total:                                                                                                          0\n",
      "Margin of Error!!Total:                                                                                                   0\n",
      "Estimate!!Total:!!Below 100 percent of the poverty level                                                                  0\n",
      "Margin of Error!!Total:!!Below 100 percent of the poverty level                                                           0\n",
      "Estimate!!Total:!!100 to 149 percent of the poverty level                                                                 0\n",
      "Margin of Error!!Total:!!100 to 149 percent of the poverty level                                                          0\n",
      "Estimate!!Total:!!At or above 150 percent of the poverty level                                                            0\n",
      "Margin of Error!!Total:!!At or above 150 percent of the poverty level                                                     0\n",
      "Estimate!!Total:!!Car, truck, or van - drove alone:                                                                       0\n",
      "Margin of Error!!Total:!!Car, truck, or van - drove alone:                                                                0\n",
      "Estimate!!Total:!!Car, truck, or van - drove alone:!!Below 100 percent of the poverty level                               0\n",
      "Margin of Error!!Total:!!Car, truck, or van - drove alone:!!Below 100 percent of the poverty level                        0\n",
      "Estimate!!Total:!!Car, truck, or van - drove alone:!!100 to 149 percent of the poverty level                              0\n",
      "Margin of Error!!Total:!!Car, truck, or van - drove alone:!!100 to 149 percent of the poverty level                       0\n",
      "Estimate!!Total:!!Car, truck, or van - drove alone:!!At or above 150 percent of the poverty level                         0\n",
      "Margin of Error!!Total:!!Car, truck, or van - drove alone:!!At or above 150 percent of the poverty level                  0\n",
      "Estimate!!Total:!!Car, truck, or van - carpooled:                                                                         0\n",
      "Margin of Error!!Total:!!Car, truck, or van - carpooled:                                                                  0\n",
      "Estimate!!Total:!!Car, truck, or van - carpooled:!!Below 100 percent of the poverty level                                 0\n",
      "Margin of Error!!Total:!!Car, truck, or van - carpooled:!!Below 100 percent of the poverty level                          0\n",
      "Estimate!!Total:!!Car, truck, or van - carpooled:!!100 to 149 percent of the poverty level                                0\n",
      "Margin of Error!!Total:!!Car, truck, or van - carpooled:!!100 to 149 percent of the poverty level                         0\n",
      "Estimate!!Total:!!Car, truck, or van - carpooled:!!At or above 150 percent of the poverty level                           0\n",
      "Margin of Error!!Total:!!Car, truck, or van - carpooled:!!At or above 150 percent of the poverty level                    0\n",
      "Estimate!!Total:!!Public transportation (excluding taxicab):                                                              0\n",
      "Margin of Error!!Total:!!Public transportation (excluding taxicab):                                                       0\n",
      "Estimate!!Total:!!Public transportation (excluding taxicab):!!Below 100 percent of the poverty level                      0\n",
      "Margin of Error!!Total:!!Public transportation (excluding taxicab):!!Below 100 percent of the poverty level               0\n",
      "Estimate!!Total:!!Public transportation (excluding taxicab):!!100 to 149 percent of the poverty level                     0\n",
      "Margin of Error!!Total:!!Public transportation (excluding taxicab):!!100 to 149 percent of the poverty level              0\n",
      "Estimate!!Total:!!Public transportation (excluding taxicab):!!At or above 150 percent of the poverty level                0\n",
      "Margin of Error!!Total:!!Public transportation (excluding taxicab):!!At or above 150 percent of the poverty level         0\n",
      "Estimate!!Total:!!Walked:                                                                                                 0\n",
      "Margin of Error!!Total:!!Walked:                                                                                          0\n",
      "Estimate!!Total:!!Walked:!!Below 100 percent of the poverty level                                                         0\n",
      "Margin of Error!!Total:!!Walked:!!Below 100 percent of the poverty level                                                  0\n",
      "Estimate!!Total:!!Walked:!!100 to 149 percent of the poverty level                                                        0\n",
      "Margin of Error!!Total:!!Walked:!!100 to 149 percent of the poverty level                                                 0\n",
      "Estimate!!Total:!!Walked:!!At or above 150 percent of the poverty level                                                   0\n",
      "Margin of Error!!Total:!!Walked:!!At or above 150 percent of the poverty level                                            0\n",
      "Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:                                                           0\n",
      "Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:                                                    0\n",
      "Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!Below 100 percent of the poverty level                   0\n",
      "Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!Below 100 percent of the poverty level            0\n",
      "Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!100 to 149 percent of the poverty level                  0\n",
      "Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!100 to 149 percent of the poverty level           0\n",
      "Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!At or above 150 percent of the poverty level             0\n",
      "Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!At or above 150 percent of the poverty level      0\n",
      "Estimate!!Total:!!Worked from home                                                                                        0\n",
      "Margin of Error!!Total:!!Worked from home                                                                                 0\n",
      "Estimate!!Total:!!Worked from home!!Below 100 percent of the poverty level                                                0\n",
      "Margin of Error!!Total:!!Worked from home!!Below 100 percent of the poverty level                                         0\n",
      "Estimate!!Total:!!Worked from home!!100 to 149 percent of the poverty level                                               0\n",
      "Margin of Error!!Total:!!Worked from home!!100 to 149 percent of the poverty level                                        0\n",
      "Estimate!!Total:!!Worked from home!!At or above 150 percent of the poverty level                                          0\n",
      "Margin of Error!!Total:!!Worked from home!!At or above 150 percent of the poverty level                                   0\n",
      "Unnamed: 58                                                                                                             328\n",
      "dtype: int64\n",
      "\n",
      "First 5 rows of ACS B08122:\n",
      "              Geography                      Geographic Area Name  \\\n",
      "0  1400000US39049000110  Census Tract 1.10; Franklin County; Ohio   \n",
      "1  1400000US39049000120  Census Tract 1.20; Franklin County; Ohio   \n",
      "2  1400000US39049000210  Census Tract 2.10; Franklin County; Ohio   \n",
      "3  1400000US39049000220  Census Tract 2.20; Franklin County; Ohio   \n",
      "4  1400000US39049000310  Census Tract 3.10; Franklin County; Ohio   \n",
      "\n",
      "   Estimate!!Total:  Margin of Error!!Total:  \\\n",
      "0              2245                      304   \n",
      "1              1963                      248   \n",
      "2              1949                      288   \n",
      "3              2405                      213   \n",
      "4              1397                      185   \n",
      "\n",
      "   Estimate!!Total:!!Below 100 percent of the poverty level  \\\n",
      "0                                                 77          \n",
      "1                                                 79          \n",
      "2                                                 35          \n",
      "3                                                 54          \n",
      "4                                                121          \n",
      "\n",
      "   Margin of Error!!Total:!!Below 100 percent of the poverty level  \\\n",
      "0                                                 41                 \n",
      "1                                                 64                 \n",
      "2                                                 26                 \n",
      "3                                                 48                 \n",
      "4                                                 90                 \n",
      "\n",
      "   Estimate!!Total:!!100 to 149 percent of the poverty level  \\\n",
      "0                                                  6           \n",
      "1                                                 30           \n",
      "2                                                 51           \n",
      "3                                                 73           \n",
      "4                                                 49           \n",
      "\n",
      "   Margin of Error!!Total:!!100 to 149 percent of the poverty level  \\\n",
      "0                                                 10                  \n",
      "1                                                 23                  \n",
      "2                                                 47                  \n",
      "3                                                 68                  \n",
      "4                                                 60                  \n",
      "\n",
      "   Estimate!!Total:!!At or above 150 percent of the poverty level  \\\n",
      "0                                               2162                \n",
      "1                                               1854                \n",
      "2                                               1863                \n",
      "3                                               2278                \n",
      "4                                               1227                \n",
      "\n",
      "   Margin of Error!!Total:!!At or above 150 percent of the poverty level  ...  \\\n",
      "0                                                303                      ...   \n",
      "1                                                253                      ...   \n",
      "2                                                289                      ...   \n",
      "3                                                201                      ...   \n",
      "4                                                177                      ...   \n",
      "\n",
      "   Margin of Error!!Total:!!Taxicab, motorcycle, bicycle, or other means:!!At or above 150 percent of the poverty level  \\\n",
      "0                                                225                                                                      \n",
      "1                                                 17                                                                      \n",
      "2                                                 42                                                                      \n",
      "3                                                 52                                                                      \n",
      "4                                                 15                                                                      \n",
      "\n",
      "   Estimate!!Total:!!Worked from home  \\\n",
      "0                                 463   \n",
      "1                                 734   \n",
      "2                                 613   \n",
      "3                                 576   \n",
      "4                                 223   \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home  \\\n",
      "0                                        148   \n",
      "1                                        199   \n",
      "2                                        180   \n",
      "3                                        130   \n",
      "4                                        105   \n",
      "\n",
      "   Estimate!!Total:!!Worked from home!!Below 100 percent of the poverty level  \\\n",
      "0                                                  7                            \n",
      "1                                                 59                            \n",
      "2                                                  0                            \n",
      "3                                                  8                            \n",
      "4                                                 18                            \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home!!Below 100 percent of the poverty level  \\\n",
      "0                                                 11                                   \n",
      "1                                                 59                                   \n",
      "2                                                 13                                   \n",
      "3                                                 15                                   \n",
      "4                                                 21                                   \n",
      "\n",
      "   Estimate!!Total:!!Worked from home!!100 to 149 percent of the poverty level  \\\n",
      "0                                                  0                             \n",
      "1                                                 16                             \n",
      "2                                                 15                             \n",
      "3                                                  0                             \n",
      "4                                                  0                             \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home!!100 to 149 percent of the poverty level  \\\n",
      "0                                                 13                                    \n",
      "1                                                 17                                    \n",
      "2                                                 21                                    \n",
      "3                                                 13                                    \n",
      "4                                                 13                                    \n",
      "\n",
      "   Estimate!!Total:!!Worked from home!!At or above 150 percent of the poverty level  \\\n",
      "0                                                456                                  \n",
      "1                                                659                                  \n",
      "2                                                598                                  \n",
      "3                                                568                                  \n",
      "4                                                205                                  \n",
      "\n",
      "   Margin of Error!!Total:!!Worked from home!!At or above 150 percent of the poverty level  \\\n",
      "0                                                148                                         \n",
      "1                                                198                                         \n",
      "2                                                177                                         \n",
      "3                                                129                                         \n",
      "4                                                102                                         \n",
      "\n",
      "   Unnamed: 58  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "\n",
      "[5 rows x 59 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Initial Inspection: ACS B08122 (Transportation by Poverty Status) ---\n",
    "print(\"\\n--- Initial Inspection: ACS B08122 ---\")\n",
    "print(\"\\nACS B08122 Columns:\")\n",
    "print(acs_b08122_df.columns.tolist()) # List all column names\n",
    "\n",
    "print(\"\\nACS B08122 Data Types and Non-Null Counts:\")\n",
    "print(acs_b08122_df.info()) # Get info again for clarity\n",
    "\n",
    "print(\"\\nMissing Values in ACS B08122:\")\n",
    "print(acs_b08122_df.isnull().sum()) # Count missing values per column\n",
    "\n",
    "print(\"\\nFirst 5 rows of ACS B08122:\")\n",
    "print(acs_b08122_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37c88b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning ACS B08122 Data ---\n",
      "Dropped 1 'Unnamed' columns.\n",
      "Dropped 28 'Margin of Error' columns.\n",
      "Columns renamed to clean, snake_case format.\n",
      "Filtered to 14 key poverty and commuting columns.\n",
      "Numerical columns converted to int and NaNs filled with 0.\n",
      "\n",
      "--- ACS B08122 Data Cleaned ---\n",
      "Cleaned ACS B08122 DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 328 entries, 0 to 327\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                     Non-Null Count  Dtype \n",
      "---  ------                                     --------------  ----- \n",
      " 0   geo_id                                     328 non-null    object\n",
      " 1   geographic_area_name                       328 non-null    object\n",
      " 2   workers_poverty_total                      328 non-null    int32 \n",
      " 3   workers_poverty_below_100                  328 non-null    int32 \n",
      " 4   workers_poverty_100_to_149                 328 non-null    int32 \n",
      " 5   workers_poverty_above_150                  328 non-null    int32 \n",
      " 6   commute_drove_alone_total                  328 non-null    int32 \n",
      " 7   commute_carpooled_total                    328 non-null    int32 \n",
      " 8   commute_public_transit_total               328 non-null    int32 \n",
      " 9   commute_public_transit_poverty_below_100   328 non-null    int32 \n",
      " 10  commute_public_transit_poverty_100_to_149  328 non-null    int32 \n",
      " 11  commute_public_transit_poverty_above_150   328 non-null    int32 \n",
      " 12  commute_walked_total                       328 non-null    int32 \n",
      " 13  commute_other_means_total                  328 non-null    int32 \n",
      "dtypes: int32(12), object(2)\n",
      "memory usage: 20.6+ KB\n",
      "None\n",
      "\n",
      "Cleaned ACS B08122 Head:\n",
      "                 geo_id                      geographic_area_name  \\\n",
      "0  1400000US39049000110  Census Tract 1.10; Franklin County; Ohio   \n",
      "1  1400000US39049000120  Census Tract 1.20; Franklin County; Ohio   \n",
      "2  1400000US39049000210  Census Tract 2.10; Franklin County; Ohio   \n",
      "3  1400000US39049000220  Census Tract 2.20; Franklin County; Ohio   \n",
      "4  1400000US39049000310  Census Tract 3.10; Franklin County; Ohio   \n",
      "\n",
      "   workers_poverty_total  workers_poverty_below_100  \\\n",
      "0                   2245                         77   \n",
      "1                   1963                         79   \n",
      "2                   1949                         35   \n",
      "3                   2405                         54   \n",
      "4                   1397                        121   \n",
      "\n",
      "   workers_poverty_100_to_149  workers_poverty_above_150  \\\n",
      "0                           6                       2162   \n",
      "1                          30                       1854   \n",
      "2                          51                       1863   \n",
      "3                          73                       2278   \n",
      "4                          49                       1227   \n",
      "\n",
      "   commute_drove_alone_total  commute_carpooled_total  \\\n",
      "0                       1551                       56   \n",
      "1                       1114                       43   \n",
      "2                        978                      124   \n",
      "3                       1530                      153   \n",
      "4                        979                      177   \n",
      "\n",
      "   commute_public_transit_total  commute_public_transit_poverty_below_100  \\\n",
      "0                             9                                         0   \n",
      "1                            36                                         0   \n",
      "2                           130                                         0   \n",
      "3                            39                                         0   \n",
      "4                             0                                         0   \n",
      "\n",
      "   commute_public_transit_poverty_100_to_149  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "\n",
      "   commute_public_transit_poverty_above_150  commute_walked_total  \\\n",
      "0                                         9                     9   \n",
      "1                                        36                    20   \n",
      "2                                       130                    52   \n",
      "3                                        39                    31   \n",
      "4                                         0                     0   \n",
      "\n",
      "   commute_other_means_total  \n",
      "0                        157  \n",
      "1                         16  \n",
      "2                         52  \n",
      "3                         76  \n",
      "4                         18  \n"
     ]
    }
   ],
   "source": [
    "# --- Clean ACS B08122 (Means of Transportation to Work by Poverty Status) Data ---\n",
    "print(\"\\n--- Cleaning ACS B08122 Data ---\")\n",
    "if acs_b08122_df is not None:\n",
    "    acs_b08122_cleaned_df = acs_b08122_df.copy() # Create a copy to work on\n",
    "\n",
    "    # Drop 'Unnamed' columns if they exist and are empty\n",
    "    cols_to_drop_unnamed = [col for col in acs_b08122_cleaned_df.columns if 'Unnamed' in col and acs_b08122_cleaned_df[col].isnull().all()]\n",
    "    if cols_to_drop_unnamed:\n",
    "        acs_b08122_cleaned_df = acs_b08122_cleaned_df.drop(columns=cols_to_drop_unnamed)\n",
    "        print(f\"Dropped {len(cols_to_drop_unnamed)} 'Unnamed' columns.\")\n",
    "\n",
    "    # Drop Margin of Error columns\n",
    "    cols_to_drop_moe = [col for col in acs_b08122_cleaned_df.columns if 'Margin of Error' in col]\n",
    "    acs_b08122_cleaned_df = acs_b08122_cleaned_df.drop(columns=cols_to_drop_moe)\n",
    "    print(f\"Dropped {len(cols_to_drop_moe)} 'Margin of Error' columns.\")\n",
    "\n",
    "    # --- Direct Mapping for B08122 Column Renaming ---\n",
    "    # This maps the EXACT original column names to your desired clean, snake_case names.\n",
    "    b08122_column_rename_map = {\n",
    "        'Geography': 'geo_id',\n",
    "        'Geographic Area Name': 'geographic_area_name',\n",
    "        \n",
    "        # Total Workers by Poverty Level (Universe: Workers 16 years and over)\n",
    "        'Estimate!!Total:': 'workers_poverty_total', # Overall total workers\n",
    "        'Estimate!!Total:!!Below 100 percent of the poverty level': 'workers_poverty_below_100',\n",
    "        'Estimate!!Total:!!100 to 149 percent of the poverty level': 'workers_poverty_100_to_149',\n",
    "        'Estimate!!Total:!!At or above 150 percent of the poverty level': 'workers_poverty_above_150',\n",
    "\n",
    "        # Commute by Public Transportation (excluding taxicab) by Poverty Level\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):': 'commute_public_transit_total', # Total public transit commuters (all poverty levels)\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!Below 100 percent of the poverty level': 'commute_public_transit_poverty_below_100',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!100 to 149 percent of the poverty level': 'commute_public_transit_poverty_100_to_149',\n",
    "        'Estimate!!Total:!!Public transportation (excluding taxicab):!!At or above 150 percent of the poverty level': 'commute_public_transit_poverty_above_150',\n",
    "\n",
    "        # Other useful total commute modes (not broken down by poverty level here, but overall)\n",
    "        'Estimate!!Total:!!Car, truck, or van - drove alone:': 'commute_drove_alone_total',\n",
    "        'Estimate!!Total:!!Car, truck, or van - carpooled:': 'commute_carpooled_total',\n",
    "        'Estimate!!Total:!!Walked:': 'commute_walked_total',\n",
    "        'Estimate!!Total:!!Worked from home:': 'commute_worked_from_home_total',\n",
    "        'Estimate!!Total:!!Taxicab, motorcycle, bicycle, or other means:': 'commute_other_means_total'\n",
    "    }\n",
    "\n",
    "    # Apply the direct renaming. Only rename columns that exist in our DataFrame.\n",
    "    acs_b08122_cleaned_df = acs_b08122_cleaned_df.rename(columns={k: v for k, v in b08122_column_rename_map.items() if k in acs_b08122_cleaned_df.columns})\n",
    "    print(\"Columns renamed to clean, snake_case format.\")\n",
    "\n",
    "    # --- Select Key Columns for Analysis from B08122 ---\n",
    "    final_b08122_cols = [\n",
    "        'geo_id',\n",
    "        'geographic_area_name',\n",
    "        'workers_poverty_total',\n",
    "        'workers_poverty_below_100',\n",
    "        'workers_poverty_100_to_149',\n",
    "        'workers_poverty_above_150',\n",
    "        'commute_public_transit_total',\n",
    "        'commute_public_transit_poverty_below_100',\n",
    "        'commute_public_transit_poverty_100_to_149',\n",
    "        'commute_public_transit_poverty_above_150',\n",
    "        'commute_drove_alone_total',\n",
    "        'commute_carpooled_total',\n",
    "        'commute_walked_total',\n",
    "        'commute_worked_from_home_total',\n",
    "        'commute_other_means_total'\n",
    "    ]\n",
    "    acs_b08122_cleaned_df = acs_b08122_cleaned_df[acs_b08122_cleaned_df.columns.intersection(final_b08122_cols)].copy()\n",
    "    print(f\"Filtered to {len(acs_b08122_cleaned_df.columns)} key poverty and commuting columns.\")\n",
    "\n",
    "    # Convert all numerical columns to numeric and fill NaNs with 0\n",
    "    for col in acs_b08122_cleaned_df.columns:\n",
    "        if col not in ['geo_id', 'geographic_area_name']:\n",
    "            acs_b08122_cleaned_df[col] = pd.to_numeric(acs_b08122_cleaned_df[col], errors='coerce').fillna(0).astype(int)\n",
    "    print(\"Numerical columns converted to int and NaNs filled with 0.\")\n",
    "\n",
    "    print(\"\\n--- ACS B08122 Data Cleaned ---\")\n",
    "    print(\"Cleaned ACS B08122 DataFrame Info:\")\n",
    "    print(acs_b08122_cleaned_df.info())\n",
    "    print(\"\\nCleaned ACS B08122 Head:\")\n",
    "    print(acs_b08122_cleaned_df.head())\n",
    "\n",
    "else:\n",
    "    print(\"ACS B08122 DataFrame not loaded. Cleaning skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fbca10",
   "metadata": {},
   "source": [
    "#### Cleaning Decennial DHC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa0858b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning Decennial DHC2020.P1 Data ---\n",
      "Dropped 1 'Unnamed' columns.\n",
      "Identified and mapped original population column ' !!Total' to 'total_pop_2020'.\n",
      "Columns renamed.\n",
      "Filtered to 3 key columns.\n",
      "Population column converted to numeric and NaNs filled.\n",
      "\n",
      "--- Decennial DHC2020.P1 Data Cleaned ---\n"
     ]
    }
   ],
   "source": [
    "# --- Clean Decennial DHC2020.P1 Data (Comprehensive) ---\n",
    "print(\"\\n--- Cleaning Decennial DHC2020.P1 Data ---\")\n",
    "if decennial_dhc_p1_df is not None:\n",
    "    decennial_dhc_p1_cleaned_df = decennial_dhc_p1_df.copy() # Create a copy to work on\n",
    "\n",
    "    # Drop 'Unnamed' columns if they exist and are empty\n",
    "    # Ensure this uses the current DataFrame for check\n",
    "    cols_to_drop_unnamed = [col for col in decennial_dhc_p1_cleaned_df.columns if 'Unnamed' in col and decennial_dhc_p1_cleaned_df[col].isnull().all()]\n",
    "    if cols_to_drop_unnamed:\n",
    "        decennial_dhc_p1_cleaned_df = decennial_dhc_p1_cleaned_df.drop(columns=cols_to_drop_unnamed)\n",
    "        print(f\"Dropped {len(cols_to_drop_unnamed)} 'Unnamed' columns.\")\n",
    "\n",
    "    # 1. Standardize column names\n",
    "    rename_map = {\n",
    "        'Geography': 'geo_id',\n",
    "        'Geographic Area Name': 'geographic_area_name'\n",
    "    }\n",
    "    \n",
    "    # --- ROBUSTLY FIND AND RENAME THE TOTAL POPULATION COLUMN ---\n",
    "    population_col_original_name = None\n",
    "    for col in decennial_dhc_p1_cleaned_df.columns:\n",
    "        # Look for a column that contains 'Total' but is not an 'Error', 'Margin', or 'Percent' column\n",
    "        # This handles '!!Total' or 'Total' after load_csv's potential processing (which is currently off)\n",
    "        if 'Total' in str(col) and \\\n",
    "           'Error' not in str(col) and \\\n",
    "           'Margin' not in str(col) and \\\n",
    "           'Percent' not in str(col) and \\\n",
    "           str(col) != 'Geography' and str(col) != 'Geographic Area Name':\n",
    "            \n",
    "            rename_map[col] = 'total_pop_2020'\n",
    "            population_col_original_name = col # Store the actual found name for verification\n",
    "            print(f\"Identified and mapped original population column '{col}' to 'total_pop_2020'.\")\n",
    "            break # Stop after finding the first match\n",
    "    \n",
    "    if not population_col_original_name:\n",
    "        print(\"Warning: Original total population column (containing 'Total' and not error/percent terms) not found for renaming.\")\n",
    "\n",
    "    # Apply the rename map\n",
    "    decennial_dhc_p1_cleaned_df = decennial_dhc_p1_cleaned_df.rename(columns={k: v for k, v in rename_map.items() if k in decennial_dhc_p1_cleaned_df.columns})\n",
    "    print(\"Columns renamed.\")\n",
    "\n",
    "    # 2. Select only the necessary columns (final filter)\n",
    "    final_dhc_cols = ['geo_id', 'geographic_area_name', 'total_pop_2020']\n",
    "    \n",
    "    # Use intersection to ensure robustness\n",
    "    decennial_dhc_p1_cleaned_df = decennial_dhc_p1_cleaned_df[decennial_dhc_p1_cleaned_df.columns.intersection(final_dhc_cols)].copy()\n",
    "    print(f\"Filtered to {len(decennial_dhc_p1_cleaned_df.columns)} key columns.\")\n",
    "\n",
    "    # 3. Convert population column to numeric and fill NaNs\n",
    "    if 'total_pop_2020' in decennial_dhc_p1_cleaned_df.columns:\n",
    "        decennial_dhc_p1_cleaned_df['total_pop_2020'] = pd.to_numeric(decennial_dhc_p1_cleaned_df['total_pop_2020'], errors='coerce').fillna(0).astype(int)\n",
    "        print(\"Population column converted to numeric and NaNs filled.\")\n",
    "    else:\n",
    "        print(\"Warning: 'total_pop_2020' column not found in final DataFrame. This means it was either not identified or filtered out.\")\n",
    "\n",
    "    print(\"\\n--- Decennial DHC2020.P1 Data Cleaned ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b39a0f",
   "metadata": {},
   "source": [
    "#### Cleaning MORPC TAZ Forecast Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53fb89d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initial Inspection: MORPC TAZ Forecasts ---\n",
      "\n",
      "MORPC TAZ Columns:\n",
      "['TraffDist', 'county', 'TAZ2020', 'Centroid20', 'TAZ2020_N', 'MPO', 'POP2021', 'U182021', 'A18642021', 'O652021', 'POPGQ2021', 'WRK2021', 'HHINC2021', 'TOTHH2021', 'K8ENR2021', 'HSENR2021', 'ENRUNV21', 'OFF2021', 'RTG2021', 'RTS2021', 'IND2021', 'OTH2021', 'POP2025', 'U182025', 'A18642025', 'O652025', 'POPGQ2025', 'WRK2025', 'HHINC2025', 'TOTHH2025', 'K8ENR2025', 'HSENR2025', 'ENRUNV25', 'OFF2025', 'RTG2025', 'RTS2025', 'IND2025', 'OTH2025', 'POP2030', 'U182030', 'A18642030', 'O652030', 'POPGQ2030', 'WRK2030', 'HHINC2030', 'TOTHH2030', 'K8ENR2030', 'HSENR2030', 'ENRUNV30', 'OFF2030', 'RTG2030', 'RTS2030', 'IND2030', 'OTH2030', 'POP2035', 'U182035', 'A18642035', 'O652035', 'POPGQ2035', 'WRK2035', 'HHINC2035', 'TOTHH2035', 'K8ENR2035', 'HSENR2035', 'ENRUNV35', 'OFF2035', 'RTG2035', 'RTS2035', 'IND2035', 'OTH2035', 'POP2040', 'U182040', 'A18642040', 'O652040', 'POPGQ2040', 'WRK2040', 'HHINC2040', 'TOTHH2040', 'K8ENR2040', 'HSENR2040', 'ENRUNV40', 'OFF2040', 'RTG2040', 'RTS2040', 'IND2040', 'OTH2040', 'POP2045', 'U182045', 'A18642045', 'O652045', 'POPGQ2045', 'WRK2045', 'HHINC2045', 'TOTHH2045', 'K8ENR2045', 'HSENR2045', 'ENRUNV45', 'OFF2045', 'RTG2045', 'RTS2045', 'IND2045', 'OTH2045', 'POP2050', 'U182050', 'A18642050', 'O652050', 'POPGQ2050', 'WRK2050', 'HHINC2050', 'TOTHH2050', 'K8ENR2050', 'HSENR2050', 'ENRUNV50', 'OFF2050', 'RTG2050', 'RTS2050', 'IND2050', 'OTH2050', 'Jobs2021', 'Jobs2050', 'TAZacre', 'Job2150Gr', 'Job2150GD', 'Pop2150Gr', 'Jobs21n', 'Jobs30n', 'Jobs40n', 'Jobs50n', 'Job21dp', 'Job30dp', 'Job40dp', 'Job50dp', 'geometry']\n",
      "\n",
      "MORPC TAZ Data Types and Non-Null Counts:\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 2469 entries, 0 to 2468\n",
      "Columns: 133 entries, TraffDist to geometry\n",
      "dtypes: float64(73), geometry(1), int32(2), int64(11), object(46)\n",
      "memory usage: 2.5+ MB\n",
      "None\n",
      "\n",
      "Missing Values in MORPC TAZ:\n",
      "TraffDist     0\n",
      "county        0\n",
      "TAZ2020       0\n",
      "Centroid20    0\n",
      "TAZ2020_N     0\n",
      "             ..\n",
      "Job21dp       0\n",
      "Job30dp       0\n",
      "Job40dp       0\n",
      "Job50dp       0\n",
      "geometry      0\n",
      "Length: 133, dtype: int64\n",
      "\n",
      "First 5 rows of MORPC TAZ Data:\n",
      "  TraffDist county TAZ2020  Centroid20  TAZ2020_N  MPO  POP2021  U182021  \\\n",
      "0        87    UNI   87011        2098      87011    2    150.0       63   \n",
      "1        87    UNI   87019        2106      87019    2   6598.0     2353   \n",
      "2        87    UNI   87018        2105      87018    2     39.0       22   \n",
      "3        87    UNI   87017        2104      87017    2    135.0       59   \n",
      "4        87    UNI   87007        2094      87007    2    121.0       59   \n",
      "\n",
      "   A18642021  O652021  ...  Pop2150Gr  Jobs21n  Jobs30n  Jobs40n  Jobs50n  \\\n",
      "0         18       69  ...        444        0        0        0        0   \n",
      "1       3900      345  ...        595      490      560      640      650   \n",
      "2          0       17  ...        363        5       15       15       20   \n",
      "3          0       76  ...        131        0        0        0        0   \n",
      "4          0       62  ...         86        0        0        0        5   \n",
      "\n",
      "   Job21dp  Job30dp Job40dp Job50dp  \\\n",
      "0   Lowest   Lowest  Lowest  Lowest   \n",
      "1   Medium   Medium  Medium  Medium   \n",
      "2   Lowest   Lowest  Lowest     Low   \n",
      "3      Low   Lowest  Lowest  Lowest   \n",
      "4   Lowest   Lowest  Lowest  Lowest   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((1718945.454 819566.559, 1718889.488 ...  \n",
      "1  POLYGON ((1724184.293 829444.912, 1724187.53 8...  \n",
      "2  POLYGON ((1732537.662 834874.43, 1732376.512 8...  \n",
      "3  POLYGON ((1745913.727 832881.498, 1746017.775 ...  \n",
      "4  POLYGON ((1753260.63 832094.391, 1753260.797 8...  \n",
      "\n",
      "[5 rows x 133 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Initial Inspection: MORPC TAZ Forecast Data ---\n",
    "print(\"\\n--- Initial Inspection: MORPC TAZ Forecasts ---\")\n",
    "print(\"\\nMORPC TAZ Columns:\")\n",
    "print(morpc_taz_gdf.columns.tolist()) # List all column names\n",
    "\n",
    "print(\"\\nMORPC TAZ Data Types and Non-Null Counts:\")\n",
    "print(morpc_taz_gdf.info()) # Get info for raw DataFrame\n",
    "\n",
    "print(\"\\nMissing Values in MORPC TAZ:\")\n",
    "print(morpc_taz_gdf.isnull().sum()) # Count missing values per column\n",
    "\n",
    "print(\"\\nFirst 5 rows of MORPC TAZ Data:\")\n",
    "print(morpc_taz_gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbe4804f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning MORPC TAZ Forecast Data ---\n",
      "Columns renamed to clean, snake_case format.\n",
      "Filtered to 55 key TAZ forecast columns.\n",
      "Numerical columns converted and NaNs filled.\n",
      "\n",
      "--- MORPC TAZ Forecast Data Cleaned ---\n",
      "Cleaned MORPC TAZ GeoDataFrame Info:\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 2469 entries, 0 to 2468\n",
      "Data columns (total 55 columns):\n",
      " #   Column                             Non-Null Count  Dtype   \n",
      "---  ------                             --------------  -----   \n",
      " 0   county_name                        2469 non-null   object  \n",
      " 1   taz_id                             2469 non-null   object  \n",
      " 2   pop_2021                           2469 non-null   int32   \n",
      " 3   pop_under_18_2021                  2469 non-null   int64   \n",
      " 4   pop_18_to_64_2021                  2469 non-null   int64   \n",
      " 5   pop_over_65_2021                   2469 non-null   int64   \n",
      " 6   pop_group_quarters_2021            2469 non-null   int32   \n",
      " 7   jobs_total_2021                    2469 non-null   int64   \n",
      " 8   households_total_2021              2469 non-null   int64   \n",
      " 9   enroll_k8_2021                     2469 non-null   int32   \n",
      " 10  enroll_hs_2021                     2469 non-null   int32   \n",
      " 11  enroll_univ_2021                   2469 non-null   int32   \n",
      " 12  jobs_office_2021                   2469 non-null   int32   \n",
      " 13  jobs_retail_goods_2021             2469 non-null   int32   \n",
      " 14  jobs_retail_service_2021           2469 non-null   int32   \n",
      " 15  jobs_industrial_2021               2469 non-null   int32   \n",
      " 16  jobs_other_2021                    2469 non-null   int32   \n",
      " 17  pop_2025                           2469 non-null   int32   \n",
      " 18  jobs_total_2025                    2469 non-null   int32   \n",
      " 19  pop_2030                           2469 non-null   int32   \n",
      " 20  pop_under_18_2030                  2469 non-null   int32   \n",
      " 21  pop_18_to_64_2030                  2469 non-null   int32   \n",
      " 22  pop_over_65_2030                   2469 non-null   int32   \n",
      " 23  pop_group_quarters_2030            2469 non-null   int32   \n",
      " 24  jobs_total_2030                    2469 non-null   int32   \n",
      " 25  households_total_2030              2469 non-null   int32   \n",
      " 26  enroll_univ_2030                   2469 non-null   int32   \n",
      " 27  pop_2035                           2469 non-null   int32   \n",
      " 28  jobs_total_2035                    2469 non-null   int32   \n",
      " 29  pop_2040                           2469 non-null   int32   \n",
      " 30  jobs_total_2040                    2469 non-null   int32   \n",
      " 31  pop_2045                           2469 non-null   int32   \n",
      " 32  jobs_total_2045                    2469 non-null   int32   \n",
      " 33  pop_2050                           2469 non-null   int32   \n",
      " 34  pop_under_18_2050                  2469 non-null   int32   \n",
      " 35  pop_18_to_64_2050                  2469 non-null   int32   \n",
      " 36  pop_over_65_2050                   2469 non-null   int32   \n",
      " 37  pop_group_quarters_2050            2469 non-null   int32   \n",
      " 38  jobs_total_2050                    2469 non-null   int32   \n",
      " 39  households_total_2050              2469 non-null   int32   \n",
      " 40  enroll_univ_2050                   2469 non-null   int32   \n",
      " 41  jobs_office_2050                   2469 non-null   int32   \n",
      " 42  jobs_retail_goods_2050             2469 non-null   int32   \n",
      " 43  jobs_retail_service_2050           2469 non-null   int32   \n",
      " 44  jobs_industrial_2050               2469 non-null   int32   \n",
      " 45  jobs_other_2050                    2469 non-null   int32   \n",
      " 46  taz_acres                          2469 non-null   float64 \n",
      " 47  job_growth_21_50_category          2469 non-null   object  \n",
      " 48  job_growth_by_acre_21_50_category  2469 non-null   object  \n",
      " 49  pop_growth_21_50_total             2469 non-null   int64   \n",
      " 50  jobs_2021_density_category         2469 non-null   object  \n",
      " 51  jobs_2030_density_category         2469 non-null   object  \n",
      " 52  jobs_2040_density_category         2469 non-null   object  \n",
      " 53  jobs_2050_density_category         2469 non-null   object  \n",
      " 54  geometry                           2469 non-null   geometry\n",
      "dtypes: float64(1), geometry(1), int32(39), int64(6), object(8)\n",
      "memory usage: 684.9+ KB\n",
      "None\n",
      "\n",
      "Cleaned MORPC TAZ Head:\n",
      "  county_name taz_id  pop_2021  pop_under_18_2021  pop_18_to_64_2021  \\\n",
      "0         UNI  87011       150                 63                 18   \n",
      "1         UNI  87019      6598               2353               3900   \n",
      "2         UNI  87018        39                 22                  0   \n",
      "3         UNI  87017       135                 59                  0   \n",
      "4         UNI  87007       121                 59                  0   \n",
      "\n",
      "   pop_over_65_2021  pop_group_quarters_2021  jobs_total_2021  \\\n",
      "0                69                        0               58   \n",
      "1               345                        0             3278   \n",
      "2                17                        0               10   \n",
      "3                76                        0               53   \n",
      "4                62                        0               43   \n",
      "\n",
      "   households_total_2021  enroll_k8_2021  ...  jobs_other_2050    taz_acres  \\\n",
      "0                     54               0  ...                0  1244.687404   \n",
      "1                   2131            1494  ...              270  1220.319744   \n",
      "2                     13               0  ...                0   799.589154   \n",
      "3                     48               0  ...                0  1718.240212   \n",
      "4                     45               0  ...                0  1801.386383   \n",
      "\n",
      "   job_growth_21_50_category  job_growth_by_acre_21_50_category  \\\n",
      "0                     Lowest                             Lowest   \n",
      "1                       High                             Medium   \n",
      "2                        Low                                Low   \n",
      "3                     Lowest                             Lowest   \n",
      "4                     Lowest                             Lowest   \n",
      "\n",
      "   pop_growth_21_50_total  jobs_2021_density_category  \\\n",
      "0                     444                      Lowest   \n",
      "1                     595                      Medium   \n",
      "2                     363                      Lowest   \n",
      "3                     131                         Low   \n",
      "4                      86                      Lowest   \n",
      "\n",
      "   jobs_2030_density_category  jobs_2040_density_category  \\\n",
      "0                      Lowest                      Lowest   \n",
      "1                      Medium                      Medium   \n",
      "2                      Lowest                      Lowest   \n",
      "3                      Lowest                      Lowest   \n",
      "4                      Lowest                      Lowest   \n",
      "\n",
      "   jobs_2050_density_category  \\\n",
      "0                      Lowest   \n",
      "1                      Medium   \n",
      "2                         Low   \n",
      "3                      Lowest   \n",
      "4                      Lowest   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((1718945.454 819566.559, 1718889.488 ...  \n",
      "1  POLYGON ((1724184.293 829444.912, 1724187.53 8...  \n",
      "2  POLYGON ((1732537.662 834874.43, 1732376.512 8...  \n",
      "3  POLYGON ((1745913.727 832881.498, 1746017.775 ...  \n",
      "4  POLYGON ((1753260.63 832094.391, 1753260.797 8...  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Clean MORPC TAZ Forecast Data ---\n",
    "print(\"\\n--- Cleaning MORPC TAZ Forecast Data ---\")\n",
    "morpc_taz_cleaned_gdf = morpc_taz_gdf.copy() # Create a copy to work on\n",
    "\n",
    "# 1. Rename Columns using the provided data dictionary aliases\n",
    "# We'll create a direct mapping from the raw column name to the alias\n",
    "taz_column_rename_map = {\n",
    "    'TraffDist': 'traffic_district',\n",
    "    'county': 'county_name',\n",
    "    'TAZ2020': 'taz_id', # This is your primary TAZ identifier\n",
    "    'Centroid20': 'taz_centroid_id',\n",
    "    'TAZ2020_N': 'taz_numeric_id', # A numeric version of TAZ ID\n",
    "    'MPO': 'mpo_code', # Metropolitan Planning Organization code\n",
    "    \n",
    "    # Population Forecasts by Year\n",
    "    'POP2021': 'pop_2021',\n",
    "    'U182021': 'pop_under_18_2021',\n",
    "    'A18642021': 'pop_18_to_64_2021',\n",
    "    'O652021': 'pop_over_65_2021',\n",
    "    'POPGQ2021': 'pop_group_quarters_2021', # Group Quarters (e.g., dorms, prisons)\n",
    "    'POP2025': 'pop_2025',\n",
    "    'U182025': 'pop_under_18_2025',\n",
    "    'A18642025': 'pop_18_to_64_2025',\n",
    "    'O652025': 'pop_over_65_2025',\n",
    "    'POPGQ2025': 'pop_group_quarters_2025',\n",
    "    'POP2030': 'pop_2030',\n",
    "    'U182030': 'pop_under_18_2030',\n",
    "    'A18642030': 'pop_18_to_64_2030',\n",
    "    'O652030': 'pop_over_65_2030',\n",
    "    'POPGQ2030': 'pop_group_quarters_2030',\n",
    "    'POP2035': 'pop_2035',\n",
    "    'U182035': 'pop_under_18_2035',\n",
    "    'A18642035': 'pop_18_to_64_2035',\n",
    "    'O652035': 'pop_over_65_2035',\n",
    "    'POPGQ2035': 'pop_group_quarters_2035',\n",
    "    'POP2040': 'pop_2040',\n",
    "    'U182040': 'pop_under_18_2040',\n",
    "    'A18642040': 'pop_18_to_64_2040',\n",
    "    'O652040': 'pop_over_65_2040',\n",
    "    'POPGQ2040': 'pop_group_quarters_2040',\n",
    "    'POP2045': 'pop_2045',\n",
    "    'U182045': 'pop_under_18_2045',\n",
    "    'A18642045': 'pop_18_to_64_2045',\n",
    "    'O652045': 'pop_over_65_2045',\n",
    "    'POPGQ2045': 'pop_group_quarters_2045',\n",
    "    'POP2050': 'pop_2050',\n",
    "    'U182050': 'pop_under_18_2050',\n",
    "    'A18642050': 'pop_18_to_64_2050',\n",
    "    'O652050': 'pop_over_65_2050',\n",
    "    'POPGQ2050': 'pop_group_quarters_2050',\n",
    "\n",
    "    # Job Forecasts by Year and Type\n",
    "    'WRK2021': 'jobs_total_2021',\n",
    "    'OFF2021': 'jobs_office_2021',\n",
    "    'RTG2021': 'jobs_retail_goods_2021',\n",
    "    'RTS2021': 'jobs_retail_service_2021',\n",
    "    'IND2021': 'jobs_industrial_2021',\n",
    "    'OTH2021': 'jobs_other_2021',\n",
    "    'WRK2025': 'jobs_total_2025',\n",
    "    'OFF2025': 'jobs_office_2025',\n",
    "    'RTG2025': 'jobs_retail_goods_2025',\n",
    "    'RTS2025': 'jobs_retail_service_2025',\n",
    "    'IND2025': 'jobs_industrial_2025',\n",
    "    'OTH2025': 'jobs_other_2025',\n",
    "    'WRK2030': 'jobs_total_2030',\n",
    "    'OFF2030': 'jobs_office_2030',\n",
    "    'RTG2030': 'jobs_retail_goods_2030',\n",
    "    'RTS2030': 'jobs_retail_service_2030',\n",
    "    'IND2030': 'jobs_industrial_2030',\n",
    "    'OTH2030': 'jobs_other_2030',\n",
    "    'WRK2035': 'jobs_total_2035',\n",
    "    'OFF2035': 'jobs_office_2035',\n",
    "    'RTG2035': 'jobs_retail_goods_2035',\n",
    "    'RTS2035': 'jobs_retail_service_2035',\n",
    "    'IND2035': 'jobs_industrial_2035',\n",
    "    'OTH2035': 'jobs_other_2035',\n",
    "    'WRK2040': 'jobs_total_2040',\n",
    "    'OFF2040': 'jobs_office_2040',\n",
    "    'RTG2040': 'jobs_retail_goods_2040',\n",
    "    'RTS2040': 'jobs_retail_service_2040',\n",
    "    'IND2040': 'jobs_industrial_2040',\n",
    "    'OTH2040': 'jobs_other_2040',\n",
    "    'WRK2045': 'jobs_total_2045',\n",
    "    'OFF2045': 'jobs_office_2045',\n",
    "    'RTG2045': 'jobs_retail_goods_2045',\n",
    "    'RTS2045': 'jobs_retail_service_2045',\n",
    "    'IND2045': 'jobs_industrial_2045',\n",
    "    'OTH2045': 'jobs_other_2045',\n",
    "    'WRK2050': 'jobs_total_2050',\n",
    "    'OFF2050': 'jobs_office_2050',\n",
    "    'RTG2050': 'jobs_retail_goods_2050',\n",
    "    'RTS2050': 'jobs_retail_service_2050',\n",
    "    'IND2050': 'jobs_industrial_2050',\n",
    "    'OTH2050': 'jobs_other_2050',\n",
    "    'Jobs2021': 'jobs_total_raw_2021', # Keep raw if needed for comparison to WRK2021\n",
    "    'Jobs2050': 'jobs_total_raw_2050', # Keep raw if needed for comparison to WRK2050\n",
    "\n",
    "    # Household Data\n",
    "    'HHINC2021': 'household_income_2021',\n",
    "    'TOTHH2021': 'households_total_2021',\n",
    "    'HHINC2025': 'household_income_2025',\n",
    "    'TOTHH2025': 'households_total_2025',\n",
    "    'HHINC2030': 'household_income_2030',\n",
    "    'TOTHH2030': 'households_total_2030',\n",
    "    'HHINC2035': 'household_income_2035',\n",
    "    'TOTHH2035': 'households_total_2035',\n",
    "    'HHINC2040': 'household_income_2040',\n",
    "    'TOTHH2040': 'households_total_2040',\n",
    "    'HHINC2045': 'household_income_2045',\n",
    "    'TOTHH2045': 'households_total_2045',\n",
    "    'HHINC2050': 'household_income_2050',\n",
    "    'TOTHH2050': 'households_total_2050',\n",
    "\n",
    "    # School Enrollment Data (Univ enrollment is highly relevant for Columbus)\n",
    "    'K8ENR2021': 'enroll_k8_2021',\n",
    "    'HSENR2021': 'enroll_hs_2021',\n",
    "    'ENRUNV21': 'enroll_univ_2021',\n",
    "    'K8ENR2025': 'enroll_k8_2025',\n",
    "    'HSENR25': 'enroll_hs_2025', # Correcting potential typo in provided alias HSENR25 vs HSENR2025\n",
    "    'ENRUNV25': 'enroll_univ_2025',\n",
    "    'K8ENR2030': 'enroll_k8_2030',\n",
    "    'HSENR2030': 'enroll_hs_2030',\n",
    "    'ENRUNV30': 'enroll_univ_2030',\n",
    "    'K8ENR2035': 'enroll_k8_2035',\n",
    "    'HSENR2035': 'enroll_hs_2035',\n",
    "    'ENRUNV35': 'enroll_univ_2035',\n",
    "    'K8ENR2040': 'enroll_k8_2040',\n",
    "    'HSENR2040': 'enroll_hs_2040',\n",
    "    'ENRUNV40': 'enroll_univ_2040',\n",
    "    'K8ENR2045': 'enroll_k8_2045',\n",
    "    'HSENR2045': 'enroll_hs_2045',\n",
    "    'ENRUNV45': 'enroll_univ_2045',\n",
    "    'K8ENR2050': 'enroll_k8_2050',\n",
    "    'HSENR2050': 'enroll_hs_2050',\n",
    "    'ENRUNV50': 'enroll_univ_2050',\n",
    "\n",
    "    # Growth and Density Indicators\n",
    "    'Job2150Gr': 'job_growth_21_50_category', # String like 'Lowest', 'Medium'\n",
    "    'Job2150GD': 'job_growth_by_acre_21_50_category', # String like 'Lowest', 'Medium'\n",
    "    'Pop2150Gr': 'pop_growth_21_50_total', # Integer\n",
    "    'Jobs21n': 'jobs_2021_number',\n",
    "    'Jobs30n': 'jobs_2030_number',\n",
    "    'Jobs40n': 'jobs_2040_number',\n",
    "    'Jobs50n': 'jobs_2050_number',\n",
    "    'Job21dp': 'jobs_2021_density_category', # String like 'Lowest', 'Medium'\n",
    "    'Job30dp': 'jobs_2030_density_category',\n",
    "    'Job40dp': 'jobs_2040_density_category',\n",
    "    'Job50dp': 'jobs_2050_density_category',\n",
    "    'TAZacre': 'taz_acres',\n",
    "    'Shape__Area': 'shape_area',\n",
    "    'Shape__Length': 'shape_length'\n",
    "}\n",
    "\n",
    "# Apply the direct renaming. Only rename columns that exist in our GeoDataFrame.\n",
    "morpc_taz_cleaned_gdf = morpc_taz_cleaned_gdf.rename(columns={k: v for k, v in taz_column_rename_map.items() if k in morpc_taz_cleaned_gdf.columns})\n",
    "print(\"Columns renamed to clean, snake_case format.\")\n",
    "\n",
    "# 2. Select Key Columns for Analysis from MORPC TAZ\n",
    "# We'll select a subset of population, jobs, and enrollment forecasts for key years.\n",
    "# Also include the growth and density categories.\n",
    "final_taz_cols_to_keep = [\n",
    "    'taz_id', # Primary identifier\n",
    "    'county_name', # Useful for Franklin County filtering\n",
    "    'pop_2021', 'pop_2025', 'pop_2030', 'pop_2035', 'pop_2040', 'pop_2045', 'pop_2050',\n",
    "    'pop_under_18_2021', 'pop_18_to_64_2021', 'pop_over_65_2021', # Age breakdowns for 2021\n",
    "    'pop_under_18_2030', 'pop_18_to_64_2030', 'pop_over_65_2030', # Age breakdowns for 2030\n",
    "    'pop_under_18_2050', 'pop_18_to_64_2050', 'pop_over_65_2050', # Age breakdowns for 2050\n",
    "    'pop_group_quarters_2021', 'pop_group_quarters_2030', 'pop_group_quarters_2050', # Group quarters (dorm-like)\n",
    "\n",
    "    'jobs_total_2021', 'jobs_total_2025', 'jobs_total_2030', 'jobs_total_2035', 'jobs_total_2040', 'jobs_total_2045', 'jobs_total_2050',\n",
    "    'jobs_office_2021', 'jobs_retail_goods_2021', 'jobs_retail_service_2021', 'jobs_industrial_2021', 'jobs_other_2021', # 2021 Job types\n",
    "    'jobs_office_2050', 'jobs_retail_goods_2050', 'jobs_retail_service_2050', 'jobs_industrial_2050', 'jobs_other_2050', # 2050 Job types\n",
    "\n",
    "    'households_total_2021', 'households_total_2030', 'households_total_2050',\n",
    "    \n",
    "    'enroll_k8_2021', 'enroll_hs_2021', 'enroll_univ_2021', # School enrollment 2021\n",
    "    'enroll_univ_2030', 'enroll_univ_2050', # University enrollment forecasts\n",
    "\n",
    "    'pop_growth_21_50_total', # Integer growth\n",
    "    'job_growth_21_50_category', # Categorical growth\n",
    "    'job_growth_by_acre_21_50_category', # Categorical growth by acre\n",
    "\n",
    "    'jobs_2021_density_category', # Categorical density\n",
    "    'jobs_2030_density_category',\n",
    "    'jobs_2040_density_category',\n",
    "    'jobs_2050_density_category',\n",
    "\n",
    "    'taz_acres', # For calculating densities later if needed\n",
    "    'geometry' # Essential for GeoDataFrame\n",
    "]\n",
    "\n",
    "# Filter to keep only the desired columns (using intersection for robustness)\n",
    "morpc_taz_cleaned_gdf = morpc_taz_cleaned_gdf[morpc_taz_cleaned_gdf.columns.intersection(final_taz_cols_to_keep)].copy()\n",
    "print(f\"Filtered to {len(morpc_taz_cleaned_gdf.columns)} key TAZ forecast columns.\")\n",
    "\n",
    "# 3. Convert all relevant numerical columns to numeric (coerce errors to NaN, then fill with 0)\n",
    "# The dictionary provided indicates types, but let's be robust\n",
    "for col in morpc_taz_cleaned_gdf.columns:\n",
    "    if col not in ['taz_id', 'county_name', 'job_growth_21_50_category', 'job_growth_by_acre_21_50_category',\n",
    "                    'jobs_2021_density_category', 'jobs_2030_density_category', 'jobs_2040_density_category', 'jobs_2050_density_category',\n",
    "                    'geometry']: # Exclude string/object and geometry columns\n",
    "        morpc_taz_cleaned_gdf[col] = pd.to_numeric(morpc_taz_cleaned_gdf[col], errors='coerce').fillna(0)\n",
    "        # Convert to int if appropriate for counts, after filling NaNs\n",
    "        if morpc_taz_cleaned_gdf[col].dtype == 'float64':\n",
    "                # Check if column contains only integers after conversion and fillna\n",
    "            if (morpc_taz_cleaned_gdf[col] == morpc_taz_cleaned_gdf[col].astype(int)).all():\n",
    "                morpc_taz_cleaned_gdf[col] = morpc_taz_cleaned_gdf[col].astype(int)\n",
    "print(\"Numerical columns converted and NaNs filled.\")\n",
    "\n",
    "print(\"\\n--- MORPC TAZ Forecast Data Cleaned ---\")\n",
    "print(\"Cleaned MORPC TAZ GeoDataFrame Info:\")\n",
    "print(morpc_taz_cleaned_gdf.info())\n",
    "print(\"\\nCleaned MORPC TAZ Head:\")\n",
    "print(morpc_taz_cleaned_gdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5615d9f6",
   "metadata": {},
   "source": [
    "#### Cleaning Columbus Building Permits Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e1bff5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initial Inspection: Columbus Building Permits ---\n",
      "\n",
      "Columbus Building Permits Columns:\n",
      "['B1_ALT_ID', 'B1_PER_GRO', 'B1_PER_TYP', 'B1_PER_SUB', 'B1_PER_CAT', 'GENERAL_TY', 'B1_PARCEL_', 'COLS_KEY', 'SITE_ADDRE', 'B1_SITUS_Z', 'PERMIT_STA', 'APPLICANT_', 'APPLICANT1', 'SQFT', 'G3_VALUE_T', 'ISSUED_YEA', 'ISSUED_DT', 'LAST_STATU', 'CONST_TYPE', 'VALUE_DESC', 'ACA_URL', 'UNITS', 'geometry']\n",
      "\n",
      "Columbus Building Permits Data Types and Non-Null Counts:\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 631247 entries, 0 to 631246\n",
      "Data columns (total 23 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   B1_ALT_ID   631247 non-null  object        \n",
      " 1   B1_PER_GRO  631247 non-null  object        \n",
      " 2   B1_PER_TYP  631247 non-null  object        \n",
      " 3   B1_PER_SUB  631247 non-null  object        \n",
      " 4   B1_PER_CAT  631247 non-null  object        \n",
      " 5   GENERAL_TY  629827 non-null  object        \n",
      " 6   B1_PARCEL_  631247 non-null  object        \n",
      " 7   COLS_KEY    631247 non-null  int64         \n",
      " 8   SITE_ADDRE  630798 non-null  object        \n",
      " 9   B1_SITUS_Z  626857 non-null  object        \n",
      " 10  PERMIT_STA  631247 non-null  object        \n",
      " 11  APPLICANT_  589935 non-null  object        \n",
      " 12  APPLICANT1  470642 non-null  object        \n",
      " 13  SQFT        631247 non-null  float64       \n",
      " 14  G3_VALUE_T  631247 non-null  float64       \n",
      " 15  ISSUED_YEA  631247 non-null  int64         \n",
      " 16  ISSUED_DT   631247 non-null  datetime64[ms]\n",
      " 17  LAST_STATU  631247 non-null  datetime64[ms]\n",
      " 18  CONST_TYPE  304812 non-null  object        \n",
      " 19  VALUE_DESC  304644 non-null  object        \n",
      " 20  ACA_URL     631247 non-null  object        \n",
      " 21  UNITS       631247 non-null  int64         \n",
      " 22  geometry    631247 non-null  geometry      \n",
      "dtypes: datetime64[ms](2), float64(2), geometry(1), int64(3), object(15)\n",
      "memory usage: 110.8+ MB\n",
      "None\n",
      "\n",
      "Missing Values in Columbus Building Permits:\n",
      "B1_ALT_ID          0\n",
      "B1_PER_GRO         0\n",
      "B1_PER_TYP         0\n",
      "B1_PER_SUB         0\n",
      "B1_PER_CAT         0\n",
      "GENERAL_TY      1420\n",
      "B1_PARCEL_         0\n",
      "COLS_KEY           0\n",
      "SITE_ADDRE       449\n",
      "B1_SITUS_Z      4390\n",
      "PERMIT_STA         0\n",
      "APPLICANT_     41312\n",
      "APPLICANT1    160605\n",
      "SQFT               0\n",
      "G3_VALUE_T         0\n",
      "ISSUED_YEA         0\n",
      "ISSUED_DT          0\n",
      "LAST_STATU         0\n",
      "CONST_TYPE    326435\n",
      "VALUE_DESC    326603\n",
      "ACA_URL            0\n",
      "UNITS              0\n",
      "geometry           0\n",
      "dtype: int64\n",
      "\n",
      "Unique values in key columns (e.g., B1_PER_GRO, B1_PER_TYP):\n",
      "B1_PER_GRO: ['Building']\n",
      "B1_PER_TYP: ['Multi Family' '1,2,3 Family' 'Residential' 'Commercial' 'Demolition'\n",
      " 'Festival' 'Graphics Building Wall' 'Graphics Building Ground'\n",
      " 'Graphics Building Projecting' 'Graphics' 'Tent' 'Graphics Building Neon'\n",
      " 'Graphics Building Roof']\n",
      "B1_PER_SUB: ['MEP' 'Structural' 'Fire Protection' 'Repair Replace' 'New Construction'\n",
      " 'Major Alteration' 'Minor Alteration' 'Demolition' 'Emergency'\n",
      " 'Minor Limited Scope' 'NA' 'Non-Illuminated' 'Special' 'Addition'\n",
      " 'Regular' 'Illuminated' 'Resurface Illuminated Sign' 'Sign' 'Graphic'\n",
      " 'Resurface Non-Illuminated Sign' 'Billboard' 'Temporary'\n",
      " 'Plans Examination' 'Outline Lighting']\n",
      "B1_PER_CAT: ['Plumbing' 'Roof, Siding, Windows, Doors' 'Fire Alarm'\n",
      " 'Mechanical Single Trade ACA' 'Alteration' 'Electrical' 'Windows, Doors'\n",
      " 'Fence, Retaining Wall' 'Mechanical' 'Fire Suppression' 'New Structure'\n",
      " 'Structural' 'Re-Roofing' 'NA' 'Structure' 'Garage' 'Addition'\n",
      " 'Garage-Accessory' 'Dwelling' 'Environmental Air' 'Interior Renovation'\n",
      " 'Window Replacement' 'Deck, Patio' 'Fireplace Stove' 'Fuel Gas Piping'\n",
      " 'Roof Siding Windows Doors' 'Fire Damage' 'Festival'\n",
      " 'Product Refrigeration' 'Removal Start' 'Siding' 'Temporary Structure'\n",
      " 'Damage' 'Deck' 'Perimeter Drainage Tile' 'Re Roofing' 'Roof'\n",
      " 'Plumbing-Water Heater' 'Final Certificate of Occupancy' 'Renovation'\n",
      " 'Unheated Porch' 'Change of Use' 'Accessory Structure'\n",
      " 'Advance Construction Start' 'Ventilation Exhaust System'\n",
      " 'Secure Building' 'Foundation' 'Swimming Pool' 'Antenna'\n",
      " 'Relocated Structure' 'Industrial Units New or Moved' 'Foundation Only'\n",
      " 'Fence' 'Swimming Pools' 'Final Cert of Occupancy' 'Medical Gas Piping'\n",
      " 'Parking Lot' 'Secure Permit' 'Deck or Patio' 'Retain Walls' 'Walkthru'\n",
      " 'Masonry Fireplace' 'Boiler' 'Plans Revision' 'Plans Examination'\n",
      " 'Plan Revision' 'CO Needed' 'Structure Project App' 'Model Home'\n",
      " 'Accessory Building']\n",
      "\n",
      "First 5 rows of Columbus Building Permits Data:\n",
      "      B1_ALT_ID B1_PER_GRO    B1_PER_TYP  B1_PER_SUB  \\\n",
      "0  PMLSM1602159   Building  Multi Family         MEP   \n",
      "1  RSWDR1803525   Building  1,2,3 Family  Structural   \n",
      "2  PMLSM1609202   Building  Multi Family         MEP   \n",
      "3  RSWDR1900573   Building  1,2,3 Family  Structural   \n",
      "4  PMLSM1605284   Building  Multi Family         MEP   \n",
      "\n",
      "                     B1_PER_CAT            GENERAL_TY   B1_PARCEL_  COLS_KEY  \\\n",
      "0                      Plumbing  Multi Family - Other    010161540   1499753   \n",
      "1  Roof, Siding, Windows, Doors  1,2,3 Family - Other  01016569600    164423   \n",
      "2                      Plumbing  Multi Family - Other    010183222   1667976   \n",
      "3  Roof, Siding, Windows, Doors  1,2,3 Family - Other  01018562700   1012663   \n",
      "4                      Plumbing  Multi Family - Other    010189298   1599235   \n",
      "\n",
      "              SITE_ADDRE B1_SITUS_Z  ...   SQFT G3_VALUE_T ISSUED_YEA  \\\n",
      "0    3831 CHARBONNETT CT      43232  ...    0.0        0.0       2016   \n",
      "1         2406 BRIERS DR      43209  ...  903.0     2685.0       2018   \n",
      "2     5796 HALLRIDGE CIR      43232  ...    0.0        0.0       2016   \n",
      "3  892 CHATHAM LN UNIT C      43221  ...  375.0     2400.0       2019   \n",
      "4  5650 GREAT WOODS BLVD      43231  ...    0.0        0.0       2016   \n",
      "\n",
      "   ISSUED_DT  LAST_STATU  CONST_TYPE  \\\n",
      "0 2016-06-16  2016-06-27        None   \n",
      "1 2018-07-30  2018-07-30         434   \n",
      "2 2016-09-22  2016-09-22        None   \n",
      "3 2019-02-25  2021-08-23         434   \n",
      "4 2016-07-28  2016-08-04        None   \n",
      "\n",
      "                                          VALUE_DESC  \\\n",
      "0                                               None   \n",
      "1  Additions, Alterations and Conversions - Resid...   \n",
      "2                                               None   \n",
      "3  Additions, Alterations and Conversions - Resid...   \n",
      "4                                               None   \n",
      "\n",
      "                                             ACA_URL UNITS  \\\n",
      "0  https://ca.columbus.gov/permits/urlrouting.ash...     0   \n",
      "1  https://ca.columbus.gov/permits/urlrouting.ash...     0   \n",
      "2  https://ca.columbus.gov/permits/urlrouting.ash...     0   \n",
      "3  https://ca.columbus.gov/permits/urlrouting.ash...     0   \n",
      "4  https://ca.columbus.gov/permits/urlrouting.ash...     0   \n",
      "\n",
      "                           geometry  \n",
      "0  POINT (-9227758.248 4854524.908)  \n",
      "1  POINT (-9231598.821 4855493.593)  \n",
      "2  POINT (-9222060.833 4858407.367)  \n",
      "3  POINT (-9243573.293 4868863.698)  \n",
      "4  POINT (-9232966.036 4878484.105)  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Initial Inspection: Columbus Building Permits Data ---\n",
    "print(\"\\n--- Initial Inspection: Columbus Building Permits ---\")\n",
    "print(\"\\nColumbus Building Permits Columns:\")\n",
    "print(columbus_permits_gdf.columns.tolist()) # List all column names\n",
    "\n",
    "print(\"\\nColumbus Building Permits Data Types and Non-Null Counts:\")\n",
    "print(columbus_permits_gdf.info()) # Get info for raw GeoDataFrame\n",
    "\n",
    "print(\"\\nMissing Values in Columbus Building Permits:\")\n",
    "print(columbus_permits_gdf.isnull().sum()) # Count missing values per column\n",
    "\n",
    "print(\"\\nUnique values in key columns (e.g., B1_PER_GRO, B1_PER_TYP):\")\n",
    "if 'B1_PER_GRO' in columbus_permits_gdf.columns:\n",
    "    print(\"B1_PER_GRO:\", columbus_permits_gdf['B1_PER_GRO'].unique())\n",
    "if 'B1_PER_TYP' in columbus_permits_gdf.columns:\n",
    "    print(\"B1_PER_TYP:\", columbus_permits_gdf['B1_PER_TYP'].unique())\n",
    "if 'B1_PER_SUB' in columbus_permits_gdf.columns:\n",
    "    print(\"B1_PER_SUB:\", columbus_permits_gdf['B1_PER_SUB'].unique())\n",
    "if 'B1_PER_CAT' in columbus_permits_gdf.columns:\n",
    "    print(\"B1_PER_CAT:\", columbus_permits_gdf['B1_PER_CAT'].unique())\n",
    "\n",
    "print(\"\\nFirst 5 rows of Columbus Building Permits Data:\")\n",
    "print(columbus_permits_gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fc3301c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning Columbus Building Permits Data ---\n",
      "Dropped 5 unnecessary/high-missing columns.\n",
      "Columns renamed.\n",
      "Missing values in selected columns handled.\n",
      "Filtered to 614451 relevant development-related permits.\n",
      "Extracted issued_month and issued_quarter.\n",
      "num_units converted to integer and NaNs filled.\n",
      "Calculated value_per_sqft.\n",
      "\n",
      "--- Columbus Building Permits Data Cleaned ---\n",
      "Cleaned Columbus Building Permits GeoDataFrame Info:\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Index: 614451 entries, 0 to 631246\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   permit_id         614451 non-null  object        \n",
      " 1   permit_group      614451 non-null  object        \n",
      " 2   permit_type       614451 non-null  object        \n",
      " 3   permit_subtype    614451 non-null  object        \n",
      " 4   permit_category   614451 non-null  object        \n",
      " 5   general_type      614451 non-null  object        \n",
      " 6   parcel_id         614451 non-null  object        \n",
      " 7   columbus_key_id   614451 non-null  int64         \n",
      " 8   site_address      614451 non-null  object        \n",
      " 9   situs_zoning      614451 non-null  object        \n",
      " 10  permit_status     614451 non-null  object        \n",
      " 11  square_footage    614451 non-null  float64       \n",
      " 12  declared_value    614451 non-null  float64       \n",
      " 13  issued_year       614451 non-null  int64         \n",
      " 14  issued_date       614451 non-null  datetime64[ms]\n",
      " 15  last_status_date  614451 non-null  datetime64[ms]\n",
      " 16  num_units         614451 non-null  int32         \n",
      " 17  geometry          614451 non-null  geometry      \n",
      " 18  issued_month      614451 non-null  int32         \n",
      " 19  issued_quarter    614451 non-null  int32         \n",
      " 20  value_per_sqft    614451 non-null  float64       \n",
      "dtypes: datetime64[ms](2), float64(3), geometry(1), int32(3), int64(2), object(10)\n",
      "memory usage: 96.1+ MB\n",
      "None\n",
      "\n",
      "Cleaned Columbus Building Permits Head:\n",
      "      permit_id permit_group   permit_type permit_subtype  \\\n",
      "0  PMLSM1602159     Building  Multi Family            MEP   \n",
      "1  RSWDR1803525     Building  1,2,3 Family     Structural   \n",
      "2  PMLSM1609202     Building  Multi Family            MEP   \n",
      "3  RSWDR1900573     Building  1,2,3 Family     Structural   \n",
      "4  PMLSM1605284     Building  Multi Family            MEP   \n",
      "\n",
      "                permit_category          general_type    parcel_id  \\\n",
      "0                      Plumbing  Multi Family - Other    010161540   \n",
      "1  Roof, Siding, Windows, Doors  1,2,3 Family - Other  01016569600   \n",
      "2                      Plumbing  Multi Family - Other    010183222   \n",
      "3  Roof, Siding, Windows, Doors  1,2,3 Family - Other  01018562700   \n",
      "4                      Plumbing  Multi Family - Other    010189298   \n",
      "\n",
      "   columbus_key_id           site_address situs_zoning  ... square_footage  \\\n",
      "0          1499753    3831 CHARBONNETT CT        43232  ...            0.0   \n",
      "1           164423         2406 BRIERS DR        43209  ...          903.0   \n",
      "2          1667976     5796 HALLRIDGE CIR        43232  ...            0.0   \n",
      "3          1012663  892 CHATHAM LN UNIT C        43221  ...          375.0   \n",
      "4          1599235  5650 GREAT WOODS BLVD        43231  ...            0.0   \n",
      "\n",
      "   declared_value  issued_year  issued_date last_status_date num_units  \\\n",
      "0             0.0         2016   2016-06-16       2016-06-27         0   \n",
      "1          2685.0         2018   2018-07-30       2018-07-30         0   \n",
      "2             0.0         2016   2016-09-22       2016-09-22         0   \n",
      "3          2400.0         2019   2019-02-25       2021-08-23         0   \n",
      "4             0.0         2016   2016-07-28       2016-08-04         0   \n",
      "\n",
      "                           geometry issued_month  issued_quarter  \\\n",
      "0  POINT (-9227758.248 4854524.908)            6               2   \n",
      "1  POINT (-9231598.821 4855493.593)            7               3   \n",
      "2  POINT (-9222060.833 4858407.367)            9               3   \n",
      "3  POINT (-9243573.293 4868863.698)            2               1   \n",
      "4  POINT (-9232966.036 4878484.105)            7               3   \n",
      "\n",
      "   value_per_sqft  \n",
      "0        0.000000  \n",
      "1        2.973422  \n",
      "2        0.000000  \n",
      "3        6.400000  \n",
      "4        0.000000  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Clean Columbus Building Permits Data ---\n",
    "print(\"\\n--- Cleaning Columbus Building Permits Data ---\")\n",
    "if columbus_permits_gdf is not None:\n",
    "    columbus_permits_cleaned_gdf = columbus_permits_gdf.copy() # Create a copy to work on\n",
    "\n",
    "    # 1. Drop Unnecessary or High-Missing Columns (as per your decision)\n",
    "    cols_to_drop_final = [\n",
    "        'APPLICANT_',       # High missingness, not relevant\n",
    "        'APPLICANT1',       # High missingness, not relevant\n",
    "        'CONST_TYPE',       # High missingness (~50%), unreliable for direct use\n",
    "        'VALUE_DESC',       # High missingness (~50%), not directly actionable\n",
    "        'ACA_URL'           # Link to external URL, not for direct analysis\n",
    "    ]\n",
    "    # Filter to keep only columns that are actually in the DataFrame after renaming.\n",
    "    columbus_permits_cleaned_gdf = columbus_permits_cleaned_gdf.drop(columns=[col for col in cols_to_drop_final if col in columbus_permits_cleaned_gdf.columns])\n",
    "    print(f\"Dropped {len(cols_to_drop_final)} unnecessary/high-missing columns.\")\n",
    "\n",
    "    # 2. Rename Columns to clean, snake_case names\n",
    "    permits_column_rename_map = {\n",
    "        'B1_ALT_ID': 'permit_id',\n",
    "        'B1_PER_GRO': 'permit_group',      # e.g., 'Building'\n",
    "        'B1_PER_TYP': 'permit_type',       # e.g., 'Multi Family', 'Commercial', 'Demolition'\n",
    "        'B1_PER_SUB': 'permit_subtype',    # e.g., 'MEP', 'Structural', 'New Construction'\n",
    "        'B1_PER_CAT': 'permit_category',   # e.g., 'Plumbing', 'New Structure', 'Alteration'\n",
    "        'GENERAL_TY': 'general_type',      # e.g., 'Multi Family - Other', '1,2,3 Family - Other'\n",
    "        'B1_PARCEL_': 'parcel_id',         # Parcel identifier\n",
    "        'COLS_KEY': 'columbus_key_id',     # Another identifier\n",
    "        'SITE_ADDRE': 'site_address',\n",
    "        'B1_SITUS_Z': 'situs_zoning',      # Zoning code\n",
    "        'PERMIT_STA': 'permit_status',     # e.g., 'Issued', 'Completed'\n",
    "        'SQFT': 'square_footage',          # Square footage involved\n",
    "        'G3_VALUE_T': 'declared_value',    # Declared value of construction\n",
    "        'ISSUED_YEA': 'issued_year',\n",
    "        'ISSUED_DT': 'issued_date',        # Already datetime\n",
    "        'LAST_STATU': 'last_status_date',  # Already datetime\n",
    "        'UNITS': 'num_units',              # Number of units (crucial for residential)\n",
    "    }\n",
    "    columbus_permits_cleaned_gdf = columbus_permits_cleaned_gdf.rename(columns={k: v for k, v in permits_column_rename_map.items() if k in columbus_permits_cleaned_gdf.columns})\n",
    "    print(\"Columns renamed.\")\n",
    "\n",
    "    # 3. Handle Missing Values in remaining columns\n",
    "    # Fill categorical columns with 'Unknown' where there are missing values.\n",
    "    # Check if column exists first before trying to fill.\n",
    "    for col in ['general_type', 'site_address', 'situs_zoning', 'permit_status']: \n",
    "        if col in columbus_permits_cleaned_gdf.columns and columbus_permits_cleaned_gdf[col].isnull().any():\n",
    "            columbus_permits_cleaned_gdf[col] = columbus_permits_cleaned_gdf[col].fillna('Unknown')\n",
    "    print(\"Missing values in selected columns handled.\")\n",
    "\n",
    "    # 4. Filter to Relevant Permit Types (Focus on development/density-impacting permits)\n",
    "    # We define broad categories that indicate potential for population or job change.\n",
    "    relevant_permit_keywords = [\n",
    "        'Family', 'Residential', 'Commercial', 'Demolition', 'New Construction', \n",
    "        'Alteration', 'Addition', 'Structure', 'Dwelling', 'Units', 'Garage'\n",
    "    ]\n",
    "    \n",
    "    # Create a boolean mask to filter rows. We check across several permit classification columns.\n",
    "    # We want permits where *any* of the key classification columns contain a relevant keyword.\n",
    "    mask_relevant_permits = columbus_permits_cleaned_gdf['permit_type'].fillna('').str.contains('|'.join(relevant_permit_keywords), case=False, regex=True) | \\\n",
    "                            columbus_permits_cleaned_gdf['permit_subtype'].fillna('').str.contains('|'.join(relevant_permit_keywords), case=False, regex=True) | \\\n",
    "                            columbus_permits_cleaned_gdf['permit_category'].fillna('').str.contains('|'.join(relevant_permit_keywords), case=False, regex=True) | \\\n",
    "                            columbus_permits_cleaned_gdf['general_type'].fillna('').str.contains('|'.join(relevant_permit_keywords), case=False, regex=True)\n",
    "    \n",
    "    columbus_permits_cleaned_gdf = columbus_permits_cleaned_gdf[mask_relevant_permits].copy()\n",
    "    print(f\"Filtered to {len(columbus_permits_cleaned_gdf)} relevant development-related permits.\")\n",
    "\n",
    "    # 5. Feature Engineering (Time & Value)\n",
    "    columbus_permits_cleaned_gdf['issued_month'] = columbus_permits_cleaned_gdf['issued_date'].dt.month\n",
    "    columbus_permits_cleaned_gdf['issued_quarter'] = columbus_permits_cleaned_gdf['issued_date'].dt.quarter\n",
    "    print(\"Extracted issued_month and issued_quarter.\")\n",
    "\n",
    "    # Ensure num_units is numeric and handle potential zeros/NaNs if units are not applicable\n",
    "    # Convert to int, coercing errors (like non-numeric entries) to NaN, then filling those NaNs with 0\n",
    "    columbus_permits_cleaned_gdf['num_units'] = pd.to_numeric(columbus_permits_cleaned_gdf['num_units'], errors='coerce').fillna(0).astype(int)\n",
    "    print(\"num_units converted to integer and NaNs filled.\")\n",
    "\n",
    "    # Calculate permit value per square foot (handle division by zero and NaNs from SQFT)\n",
    "    # Use fillna(0) for square_footage before division to avoid NaN results from division by zero or NaN\n",
    "    columbus_permits_cleaned_gdf['square_footage'] = pd.to_numeric(columbus_permits_cleaned_gdf['square_footage'], errors='coerce').fillna(0)\n",
    "    columbus_permits_cleaned_gdf['declared_value'] = pd.to_numeric(columbus_permits_cleaned_gdf['declared_value'], errors='coerce').fillna(0)\n",
    "\n",
    "    columbus_permits_cleaned_gdf['value_per_sqft'] = columbus_permits_cleaned_gdf.apply(\n",
    "        lambda row: row['declared_value'] / row['square_footage'] if row['square_footage'] > 0 else 0, axis=1\n",
    "    )\n",
    "    print(\"Calculated value_per_sqft.\")\n",
    "\n",
    "    print(\"\\n--- Columbus Building Permits Data Cleaned ---\")\n",
    "    print(\"Cleaned Columbus Building Permits GeoDataFrame Info:\")\n",
    "    print(columbus_permits_cleaned_gdf.info())\n",
    "    print(\"\\nCleaned Columbus Building Permits Head:\")\n",
    "    print(columbus_permits_cleaned_gdf.head())\n",
    "\n",
    "else:\n",
    "    print(\"Columbus Building Permits GeoDataFrame not loaded. Cleaning skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d1b02",
   "metadata": {},
   "source": [
    "#### Cleaning FTA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4db55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initial Inspection: FTA Monthly Ridership Data ---\n",
    "print(\"\\n--- Initial Inspection: FTA Monthly Ridership ---\")\n",
    "print(\"\\nFTA Monthly Ridership Columns:\")\n",
    "print(fta_ridership_df.columns.tolist()) # List all column names\n",
    "\n",
    "print(\"\\nFTA Monthly Ridership Data Types and Non-Null Counts:\")\n",
    "print(fta_ridership_df.info()) # Get info for raw DataFrame\n",
    "\n",
    "print(\"\\nMissing Values in FTA Monthly Ridership:\")\n",
    "print(fta_ridership_df.isnull().sum()) # Count missing values per column\n",
    "\n",
    "print(\"\\nFirst 5 rows of FTA Monthly Ridership Data:\")\n",
    "print(fta_ridership_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b547a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clean FTA Monthly Ridership Data ---\n",
    "print(\"\\n--- Cleaning FTA Monthly Ridership Data ---\")\n",
    "if fta_ridership_df is not None:\n",
    "    fta_ridership_cleaned_df = fta_ridership_df.copy() # Create a copy to work on\n",
    "\n",
    "    # 1. Filter to COTA's main fixed-route Motorbus service\n",
    "    # This filter relies on the original column names.\n",
    "    fta_ridership_cleaned_df = fta_ridership_cleaned_df[\n",
    "        (fta_ridership_cleaned_df['Agency'] == 'Central Ohio Transit Authority') &\n",
    "        (fta_ridership_cleaned_df['Mode'] == 'MB') &\n",
    "        (fta_ridership_cleaned_df['TOS'] == 'DO') &\n",
    "        (fta_ridership_cleaned_df['3 Mode'] == 'Bus')\n",
    "    ].copy()\n",
    "\n",
    "    if fta_ridership_cleaned_df.empty:\n",
    "        print(\"Error: Could not find the main COTA Motorbus row. Check filtering conditions.\")\n",
    "        fta_ridership_cleaned_df = None # Set to None if filter results in empty DF\n",
    "    else:\n",
    "        print(\"Filtered to main COTA Motorbus service row.\")\n",
    "        fta_ridership_cleaned_df.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "    if fta_ridership_cleaned_df is not None and not fta_ridership_cleaned_df.empty:\n",
    "        # --- NEW: Strip whitespace from all column names immediately ---\n",
    "        # This is CRITICAL if there are hidden spaces causing rename issues.\n",
    "        fta_ridership_cleaned_df.columns = fta_ridership_cleaned_df.columns.str.strip()\n",
    "        print(\"Stripped whitespace from column names.\")\n",
    "\n",
    "        # 2. Define the columns that are NOT dates (these are our id_vars)\n",
    "        # Use the exact names from your initial inspection output after stripping\n",
    "        non_date_id_cols_original = [\n",
    "            'NTD ID', 'Legacy NTD ID', 'Agency', 'Mode/Type of Service Status', 'Reporter Type',\n",
    "            'UACE CD', 'UZA Name', 'Mode', 'TOS', '3 Mode'\n",
    "        ]\n",
    "        # Identify the monthly ridership columns (which are value_vars)\n",
    "        date_cols = [col for col in fta_ridership_cleaned_df.columns if col not in non_date_id_cols_original]\n",
    "        print(f\"Identified {len(date_cols)} date columns and {len(non_date_id_cols_original)} ID columns.\")\n",
    "\n",
    "        # 3. Rename non-date columns for cleanliness *before* melting\n",
    "        # This must happen before melt so melt gets the clean names in id_vars\n",
    "        fta_ridership_cleaned_df = fta_ridership_cleaned_df.rename(columns={\n",
    "            'NTD ID': 'ntd_id',\n",
    "            'Legacy NTD ID': 'legacy_ntd_id',\n",
    "            'Agency': 'agency_name',\n",
    "            'Mode/Type of Service Status': 'service_status', # This mapping should now work\n",
    "            'Reporter Type': 'reporter_type',\n",
    "            'UACE CD': 'uace_cd',\n",
    "            'UZA Name': 'uza_name',\n",
    "            'Mode': 'mode_code',\n",
    "            'TOS': 'type_of_service_code',\n",
    "            '3 Mode': 'mode_description'\n",
    "        })\n",
    "        print(\"Base columns renamed.\")\n",
    "\n",
    "        # 4. Melt the DataFrame from wide to long format\n",
    "        # id_vars are the *newly renamed* columns\n",
    "        fta_ridership_long_df = fta_ridership_cleaned_df.melt(\n",
    "            id_vars=['ntd_id', 'legacy_ntd_id', 'agency_name', 'service_status', 'reporter_type',\n",
    "                     'uace_cd', 'uza_name', 'mode_code', 'type_of_service_code', 'mode_description'], # Use the clean, new names here\n",
    "            value_vars=date_cols, # Date columns remain as identified\n",
    "            var_name='date_month_year',\n",
    "            value_name='ridership'\n",
    "        )\n",
    "        print(\"DataFrame melted from wide to long format.\")\n",
    "\n",
    "        # 5. Convert 'date_month_year' to datetime objects\n",
    "        fta_ridership_long_df['date'] = pd.to_datetime(fta_ridership_long_df['date_month_year'], format='%m/%Y')\n",
    "        print(\"Date column created from month/year string.\")\n",
    "\n",
    "        # 6. Convert ridership to integer, coercing errors to NaN and filling with 0\n",
    "        fta_ridership_long_df['ridership'] = pd.to_numeric(fta_ridership_long_df['ridership'], errors='coerce').fillna(0).astype(int)\n",
    "        print(\"Ridership column converted to integer and NaNs filled.\")\n",
    "\n",
    "        # 7. Select final columns and sort\n",
    "        fta_ridership_cleaned_df = fta_ridership_long_df[[\n",
    "            'agency_name', 'mode_description', 'date', 'ridership', 'uza_name'\n",
    "        ]].sort_values(by='date').reset_index(drop=True).copy()\n",
    "        \n",
    "        print(\"\\n--- FTA Monthly Ridership Data Cleaned ---\")\n",
    "        print(\"Cleaned FTA Monthly Ridership DataFrame Info:\")\n",
    "        print(fta_ridership_cleaned_df.info())\n",
    "        print(\"\\nCleaned FTA Monthly Ridership Head:\")\n",
    "        print(fta_ridership_cleaned_df.head())\n",
    "        print(\"\\nCleaned FTA Monthly Ridership Tail (last 5 rows):\")\n",
    "        print(fta_ridership_cleaned_df.tail())\n",
    "\n",
    "else:\n",
    "    print(\"FTA Monthly Ridership DataFrame not loaded or filtered to empty. Cleaning skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c64204c",
   "metadata": {},
   "source": [
    "## Merging data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbe6887",
   "metadata": {},
   "source": [
    "#### Standardize GeoIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5762d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standardize Geographic IDs for Merging ---\n",
    "print(\"\\n--- Standardizing Geographic IDs across Census DataFrames ---\")\n",
    "\n",
    "# List of cleaned Census DataFrames\n",
    "census_dfs = {\n",
    "    \"decennial_dhc_p1\": decennial_dhc_p1_cleaned_df,\n",
    "    \"acs_s0101\": acs_s0101_cleaned_df,\n",
    "    \"acs_b08141\": acs_b08141_cleaned_df,\n",
    "    \"acs_b08101\": acs_b08101_cleaned_df,\n",
    "    \"acs_b08119\": acs_b08119_cleaned_df,\n",
    "    \"acs_b08122\": acs_b08122_cleaned_df,\n",
    "}\n",
    "\n",
    "for name, df in census_dfs.items():\n",
    "    if df is not None and 'geo_id' in df.columns:\n",
    "        # The 'geo_id' from data.census.gov is typically '1400000US39049XXXXXX' for tracts.\n",
    "        # We want to standardize it to just the FIPS code for the tract (e.g., '39049XXXXXX')\n",
    "        # or the simpler tract identifier. For now, let's remove '1400000US'.\n",
    "        df['geo_id'] = df['geo_id'].astype(str).str.replace('1400000US', '')\n",
    "        print(f\"Standardized 'geo_id' in {name}_cleaned_df. Example: {df['geo_id'].iloc[0]}\")\n",
    "    else:\n",
    "        print(f\"Warning: {name}_cleaned_df not loaded or missing 'geo_id'. Skipping standardization.\")\n",
    "\n",
    "print(\"\\n--- Geo ID Standardization Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad46974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Merge All Cleaned Census DataFrames ---\n",
    "print(\"\\n--- Merging Cleaned Census DataFrames (with Dynamic Duplicate Handling) ---\")\n",
    "\n",
    "# Start with Decennial DHC2020.P1 as the base DataFrame\n",
    "merged_census_df = decennial_dhc_p1_cleaned_df.copy()\n",
    "print(f\"Starting merge with decennial_dhc_p1_cleaned_df. Shape: {merged_census_df.shape}\")\n",
    "\n",
    "# List of other Census DataFrames to merge\n",
    "other_census_dfs = {\n",
    "    \"acs_s0101\": acs_s0101_cleaned_df,\n",
    "    \"acs_b08141\": acs_b08141_cleaned_df,\n",
    "    \"acs_b08101\": acs_b08101_cleaned_df,\n",
    "    \"acs_b08119\": acs_b08119_cleaned_df,\n",
    "    \"acs_b08122\": acs_b08122_cleaned_df,\n",
    "}\n",
    "\n",
    "# Define the common 'commute_total' columns that might cause duplicates\n",
    "# These are the columns we want to keep only from our chosen source (B08141)\n",
    "common_commute_totals = [\n",
    "    'commute_drove_alone_total',\n",
    "    'commute_carpooled_total',\n",
    "    'commute_public_transit_total',\n",
    "    'commute_walked_total',\n",
    "    'commute_worked_from_home_total',\n",
    "    'commute_other_means_total'\n",
    "]\n",
    "\n",
    "# Perform sequential merges\n",
    "for name, df_to_merge in other_census_dfs.items():\n",
    "    if df_to_merge is not None and 'geo_id' in df_to_merge.columns:\n",
    "        df_to_merge_clean = df_to_merge.copy() # Work on a copy for this merge iteration\n",
    "\n",
    "        # 1. Drop 'geographic_area_name' from df_to_merge_clean if present in both\n",
    "        if 'geographic_area_name' in df_to_merge_clean.columns and 'geographic_area_name' in merged_census_df.columns:\n",
    "            df_to_merge_clean = df_to_merge_clean.drop(columns=['geographic_area_name'])\n",
    "        \n",
    "        # 2. Dynamically drop common 'commute_total' columns from df_to_merge_clean\n",
    "        # if they are already present in merged_census_df (the left DataFrame).\n",
    "        # This ensures B08141's versions of these columns are kept if B08141 merges first.\n",
    "        cols_to_drop_from_right = [col for col in common_commute_totals if col in merged_census_df.columns and col in df_to_merge_clean.columns]\n",
    "        if cols_to_drop_from_right:\n",
    "            df_to_merge_clean = df_to_merge_clean.drop(columns=cols_to_drop_from_right)\n",
    "            print(f\"  - Dropped duplicate general commute totals from {name}_cleaned_df: {cols_to_drop_from_right}\")\n",
    "\n",
    "        # Perform the merge\n",
    "        initial_cols = merged_census_df.shape[1]\n",
    "        merged_census_df = pd.merge(merged_census_df, df_to_merge_clean, on='geo_id', how='left')\n",
    "        final_cols = merged_census_df.shape[1]\n",
    "        \n",
    "        print(f\"Merged {name}_cleaned_df. Added {final_cols - initial_cols} columns. New shape: {merged_census_df.shape}\")\n",
    "        \n",
    "        # After merge, check for *unexpected* duplicates (should be none with this logic)\n",
    "        duplicates = merged_census_df.columns[merged_census_df.columns.duplicated()].tolist()\n",
    "        if duplicates:\n",
    "            print(f\"Warning: Unexpected duplicate columns detected after merging {name}: {duplicates}\")\n",
    "    else:\n",
    "        print(f\"Warning: {name}_cleaned_df not loaded or missing 'geo_id'. Skipping merge for this DataFrame.\")\n",
    "\n",
    "print(\"\\n--- Census DataFrames Merged ---\")\n",
    "print(\"Merged Census DataFrame Info:\")\n",
    "print(merged_census_df.info())\n",
    "print(\"\\nMerged Census DataFrame Head:\")\n",
    "print(merged_census_df.head())\n",
    "print(\"\\nMissing values in Merged Census DataFrame after merge:\")\n",
    "print(merged_census_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8effc7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inspect CRS of MORPC TAZ Data ---\n",
    "print(\"\\n--- Inspecting MORPC TAZ GeoDataFrame CRS ---\")\n",
    "print(morpc_taz_cleaned_gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a195013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inspect CRS of COTA Bus Stops Data ---\n",
    "print(\"\\n--- Inspecting COTA Bus Stops GeoDataFrame CRS ---\")\n",
    "print(cota_stops_gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79185f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reproject COTA Bus Stops Data to match TAZ CRS ---\n",
    "print(\"\\n--- Reprojecting COTA Bus Stops Data ---\")\n",
    "if cota_stops_gdf is not None:\n",
    "    # Ensure current CRS is known before reprojecting\n",
    "    print(f\"Original COTA Stops CRS: {cota_stops_gdf.crs}\")\n",
    "    \n",
    "    # Reproject to EPSG:3735 (matching MORPC TAZ data)\n",
    "    cota_stops_gdf = cota_stops_gdf.to_crs(epsg=3735)\n",
    "    \n",
    "    print(f\"New COTA Stops CRS: {cota_stops_gdf.crs}\")\n",
    "    print(\"\\nReprojection complete for COTA Bus Stops.\")\n",
    "else:\n",
    "    print(\"COTA Bus Stops GeoDataFrame not loaded. Reprojection skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfde455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob # Used for finding files matching a pattern\n",
    "\n",
    "# --- Load and Inspect ALL Census Tract Boundaries (ROBUST 2020 FILTERING) ---\n",
    "print(\"\\n--- Loading and Inspecting Census Tract Boundaries (from multiple files) ---\")\n",
    "\n",
    "# Define the base directory where your individual tract shapefile sets are\n",
    "# IMPORTANT: Verify this path. It should be 'Tract_Shapefiles' with an 's'\n",
    "census_tract_shapefile_dir = \"../data/US_Census/Tract_Shapefiles/\" # <--- VERIFY THIS PATH (Added 's')\n",
    "\n",
    "# Use glob to find all .shp files for tracts in Franklin County.\n",
    "# This pattern is more general to catch variations (e.g., tl_2020_39049_tract10.shp, tl_2020_39049_001.shp, etc.)\n",
    "# We'll filter to 2020 data specifically later.\n",
    "shp_files = glob.glob(os.path.join(census_tract_shapefile_dir, \"tl_2020_39049_*.shp\")) # More general pattern\n",
    "\n",
    "# Check if any files were found\n",
    "if not shp_files:\n",
    "    print(f\"Error: No .shp files found in {census_tract_shapefile_dir} matching 'tl_2020_39049_*.shp'.\")\n",
    "    print(\"Please ensure your individual tract shapefiles are correctly unzipped in this folder and the path is correct.\")\n",
    "    census_tracts_gdf = None\n",
    "else:\n",
    "    print(f\"Found {len(shp_files)} potential Census Tract shapefiles matching pattern.\")\n",
    "    \n",
    "    list_of_gdfs = []\n",
    "    for shp_file in shp_files:\n",
    "        try:\n",
    "            gdf_part = gpd.read_file(shp_file)\n",
    "            list_of_gdfs.append(gdf_part)\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error loading {os.path.basename(shp_file)}: {e}\")\n",
    "    \n",
    "    if list_of_gdfs:\n",
    "        # Concatenate all individual GeoDataFrames into one\n",
    "        census_tracts_gdf = pd.concat(list_of_gdfs).reset_index(drop=True)\n",
    "        print(\"\\nAll individual Census Tract GeoDataFrames concatenated.\")\n",
    "        \n",
    "        # --- DEBUG: See ALL columns after concatenation ---\n",
    "        print(\"\\n--- DEBUG: Census Tracts GDF Columns AFTER Concatenation ---\")\n",
    "        print(census_tracts_gdf.columns.tolist())\n",
    "        print(\"--- END DEBUG ---\")\n",
    "\n",
    "        # --- IMPORTANT: Filter to ONLY 2020 Census Tracts for Franklin County ---\n",
    "        # The TIGER/Line files often have STATEFP/COUNTYFP/GEOID columns indicating FIPS codes.\n",
    "        # For 2020 tracts, these are typically STATEFP20, COUNTYFP20, GEOID20.\n",
    "        # Ohio FIPS: 39, Franklin County FIPS: 049\n",
    "        \n",
    "        # Ensure FIPS columns are strings for consistent comparison\n",
    "        if 'STATEFP20' in census_tracts_gdf.columns:\n",
    "            census_tracts_gdf['STATEFP20'] = census_tracts_gdf['STATEFP20'].astype(str)\n",
    "        if 'COUNTYFP20' in census_tracts_gdf.columns:\n",
    "            census_tracts_gdf['COUNTYFP20'] = census_tracts_gdf['COUNTYFP20'].astype(str)\n",
    "        \n",
    "        # Filter for 2020 data AND for Franklin County (39049)\n",
    "        if 'GEOID20' in census_tracts_gdf.columns and 'STATEFP20' in census_tracts_gdf.columns and 'COUNTYFP20' in census_tracts_gdf.columns:\n",
    "            initial_count = len(census_tracts_gdf)\n",
    "            census_tracts_gdf = census_tracts_gdf[\n",
    "                (census_tracts_gdf['STATEFP20'] == '39') &\n",
    "                (census_tracts_gdf['COUNTYFP20'] == '049')\n",
    "            ].copy()\n",
    "            print(f\"Filtered to {len(census_tracts_gdf)} features (originally {initial_count}) representing 2020 Franklin County Tracts.\")\n",
    "        else:\n",
    "            print(\"Warning: Missing STATEFP20/COUNTYFP20/GEOID20 for filtering. Proceeding without specific 2020 filtering.\")\n",
    "            # If these columns are missing, we can't definitively filter to 2020 Franklin County here.\n",
    "            # We will proceed with whatever was loaded and rely on GEOID cleanup later.\n",
    "\n",
    "    else:\n",
    "        print(\"No Census Tract GeoDataFrames were successfully loaded for concatenation.\")\n",
    "        census_tracts_gdf = None\n",
    "\n",
    "\n",
    "if census_tracts_gdf is not None:\n",
    "    print(f\"\\nCombined Census Tract Boundaries loaded. Total features: {len(census_tracts_gdf)}\")\n",
    "    print(f\"Original CRS: {census_tracts_gdf.crs}\")\n",
    "\n",
    "    # --- Reproject Census Tracts to EPSG:3735 if needed ---\n",
    "    if census_tracts_gdf.crs != 'EPSG:3735':\n",
    "        print(f\"\\nReprojecting Census Tract Boundaries from {census_tracts_gdf.crs} to EPSG:3735...\")\n",
    "        census_tracts_gdf = census_tracts_gdf.to_crs(epsg=3735)\n",
    "        print(f\"New Census Tract Boundaries CRS: {census_tracts_gdf.crs}\")\n",
    "    else:\n",
    "        print(\"\\nCensus Tract Boundaries are already in EPSG:3735. No reprojection needed.\")\n",
    "\n",
    "    # --- Standardize and Select Final Columns ---\n",
    "    # We will prioritize GEOID20 and NAME20 for 2020 Census Tracts.\n",
    "    cols_to_keep_from_tract_shapefile = ['GEOID20', 'NAME20', 'geometry']\n",
    "    \n",
    "    # Filter to keep only the intersection of existing and desired columns\n",
    "    census_tracts_gdf = census_tracts_gdf[census_tracts_gdf.columns.intersection(cols_to_keep_from_tract_shapefile)].copy()\n",
    "    \n",
    "    # Rename columns for consistency\n",
    "    census_tracts_gdf = census_tracts_gdf.rename(columns={\n",
    "        'GEOID20': 'geo_id', # This will match our merged_census_df 'geo_id'\n",
    "        'NAME20': 'tract_name' # A more specific name than 'geographic_area_name'\n",
    "    })\n",
    "    print(\"Census Tracts columns standardized and renamed.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Census Tract Boundaries Loaded and Standardized ---\")\n",
    "    print(\"Cleaned Census Tract Boundaries GeoDataFrame Info:\")\n",
    "    print(census_tracts_gdf.info())\n",
    "    print(\"\\nCleaned Census Tract Boundaries Head:\")\n",
    "    print(census_tracts_gdf.head())\n",
    "\n",
    "else:\n",
    "    print(\"Census Tract Boundaries GeoDataFrame not loaded or empty after filtering. Skipping standardization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0582e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Merge Tabular Census Data with Census Tract Boundaries ---\n",
    "print(\"\\n--- Merging Tabular Census Data with Boundaries ---\")\n",
    "\n",
    "if merged_census_df is not None and census_tracts_gdf is not None:\n",
    "    # Perform a left merge from the geographical data to the tabular data.\n",
    "    # This keeps all Census Tract geometries and adds their demographic data.\n",
    "    # We merge on the standardized 'geo_id' column.\n",
    "    initial_cols = census_tracts_gdf.shape[1]\n",
    "    final_census_gdf = pd.merge(census_tracts_gdf, merged_census_df, on='geo_id', how='left')\n",
    "    final_cols = final_census_gdf.shape[1]\n",
    "\n",
    "    print(f\"Merged Census Tract boundaries with tabular demographic data.\")\n",
    "    print(f\"Added {final_cols - initial_cols} columns. New shape: {final_census_gdf.shape}\")\n",
    "\n",
    "    # Check for missing values after merge (should be none if joins were perfect)\n",
    "    missing_after_merge = final_census_gdf.isnull().sum()\n",
    "    if missing_after_merge.any():\n",
    "        print(\"\\nWarning: Missing values detected after merging (this can happen if some geo_ids didn't match).\")\n",
    "        print(missing_after_merge[missing_after_merge > 0]) # Print only columns with missing data\n",
    "        # Fill numerical NaNs with 0 and object NaNs with 'Unknown'.\n",
    "        for col in final_census_gdf.columns:\n",
    "            if final_census_gdf[col].dtype in ['int64', 'float64', 'int32']:\n",
    "                final_census_gdf[col] = final_census_gdf[col].fillna(0)\n",
    "            elif final_census_gdf[col].dtype == 'object' and col != 'geo_id':\n",
    "                final_census_gdf[col] = final_census_gdf[col].fillna('Unknown')\n",
    "        print(\"Filled missing values introduced by merge.\")\n",
    "        \n",
    "    print(\"\\n--- Final Census GeoDataFrame Created ---\")\n",
    "    print(\"Final Census GeoDataFrame Info:\")\n",
    "    print(final_census_gdf.info())\n",
    "    print(\"\\nFinal Census GeoDataFrame Head:\")\n",
    "    print(final_census_gdf.head())\n",
    "    print(\"\\nFinal Census GeoDataFrame Tail:\") # Check last few rows too\n",
    "    print(final_census_gdf.tail())\n",
    "\n",
    "else:\n",
    "    print(\"One or both Census DataFrames not loaded for merging. Skipping final merge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9783c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Spatially Join MORPC TAZs with Final Census Data ---\n",
    "print(\"\\n--- Spatially Joining TAZs with Census Tract Demographics ---\")\n",
    "\n",
    "if morpc_taz_cleaned_gdf is not None and final_census_gdf is not None:\n",
    "    # Ensure both GeoDataFrames have valid geometries\n",
    "    if not morpc_taz_cleaned_gdf.geometry.is_valid.all():\n",
    "        morpc_taz_cleaned_gdf.geometry = morpc_taz_cleaned_gdf.geometry.buffer(0) # Fix invalid geometries if any\n",
    "        print(\"Fixed invalid geometries in morpc_taz_cleaned_gdf.\")\n",
    "    if not final_census_gdf.geometry.is_valid.all():\n",
    "        final_census_gdf.geometry = final_census_gdf.geometry.buffer(0) # Fix invalid geometries if any\n",
    "        print(\"Fixed invalid geometries in final_census_gdf.\")\n",
    "\n",
    "    # Perform a spatial join (sjoin) to find which Census Tract each TAZ falls within.\n",
    "    # We'll use 'intersects' as the predicate to catch any overlap, not just containment.\n",
    "    # 'how=left' keeps all TAZs and adds Census data where they intersect.\n",
    "\n",
    "    # Before joining, identify columns in final_census_gdf that would be duplicates and rename them\n",
    "    # This avoids generic '_right' suffixes.\n",
    "    # 'geo_id' is the join key, 'geometry' is special. 'geographic_area_name' and 'tract_name' overlap.\n",
    "    cols_to_rename_in_census_before_join = {\n",
    "        'geographic_area_name': 'census_geographic_area_name',\n",
    "        'tract_name': 'census_tract_name' # Rename to distinguish from potential TAZ 'name' or just keep specific\n",
    "    }\n",
    "    # Apply renaming only if the columns exist (they should, but for robustness)\n",
    "    census_for_join_gdf = final_census_gdf.rename(columns={k:v for k,v in cols_to_rename_in_census_before_join.items() if k in final_census_gdf.columns})\n",
    "    \n",
    "    # Drop the original 'geographic_area_name' and 'tract_name' from TAZs if they exist and are not needed\n",
    "    # This might happen if TAZs had a 'NAME' column.\n",
    "    # For now, let's proceed and see if duplicates cause issues in the sjoin result.\n",
    "\n",
    "    # Perform the spatial join\n",
    "    # A 'left' join ensures all TAZs are kept. The 'right' side is the Census Tracts.\n",
    "    taz_with_census_gdf = gpd.sjoin(\n",
    "        morpc_taz_cleaned_gdf, \n",
    "        census_for_join_gdf, # Use the renamed census GeoDataFrame\n",
    "        how=\"left\", \n",
    "        predicate=\"intersects\"\n",
    "    )\n",
    "    print(\"Spatial join of TAZs with Census Tracts complete.\")\n",
    "    print(f\"Initial TAZs: {len(morpc_taz_cleaned_gdf)}. Joined TAZs: {len(taz_with_census_gdf)}\")\n",
    "\n",
    "    # Some TAZs might intersect with multiple Census Tracts.\n",
    "    # This will result in duplicate TAZ_IDs. We need to decide how to handle these.\n",
    "    # For simplicity, let's keep the first match (e.g., based on area of intersection, or just first row).\n",
    "    # A common simple approach is to drop duplicates on the TAZ_ID.\n",
    "    initial_rows = len(taz_with_census_gdf)\n",
    "    taz_with_census_gdf.drop_duplicates(subset=['taz_id'], inplace=True)\n",
    "    print(f\"Dropped duplicate TAZs from spatial join (if a TAZ intersected multiple tracts). Remaining TAZs: {len(taz_with_census_gdf)} (from {initial_rows}).\")\n",
    "\n",
    "    # Check for missing values introduced by the spatial join (where TAZs might not intersect a tract)\n",
    "    missing_after_sjoin = taz_with_census_gdf.isnull().sum()\n",
    "    if missing_after_sjoin.any():\n",
    "        print(\"\\nWarning: Missing values detected after spatial join (some TAZs might not have intersected a Census Tract).\")\n",
    "        print(missing_after_sjoin[missing_after_sjoin > 0])\n",
    "        # Fill numerical NaNs with 0 and object NaNs with 'Unknown'.\n",
    "        for col in taz_with_census_gdf.columns:\n",
    "            if taz_with_census_gdf[col].dtype in ['int64', 'float64', 'int32']:\n",
    "                taz_with_census_gdf[col] = taz_with_census_gdf[col].fillna(0)\n",
    "            elif taz_with_census_gdf[col].dtype == 'object' and col != 'taz_id': # Exclude taz_id itself\n",
    "                taz_with_census_gdf[col] = taz_with_census_gdf[col].fillna('Unknown')\n",
    "        print(\"Filled missing values introduced by spatial join.\")\n",
    "\n",
    "    print(\"\\n--- TAZs Enriched with Census Data ---\")\n",
    "    print(\"TAZs with Census Data GeoDataFrame Info:\")\n",
    "    print(taz_with_census_gdf.info())\n",
    "    print(\"\\nTAZs with Census Data Head:\")\n",
    "    print(taz_with_census_gdf.head())\n",
    "    print(\"\\nTAZs with Census Data Tail:\")\n",
    "    print(taz_with_census_gdf.tail())\n",
    "\n",
    "else:\n",
    "    print(\"One or both GeoDataFrames not loaded for spatial join. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf4fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Spatially Join COTA Bus Stops with Census Tracts ---\n",
    "print(\"\\n--- Spatially Joining COTA Bus Stops with Census Tracts ---\")\n",
    "\n",
    "if cota_stops_gdf is not None and final_census_gdf is not None:\n",
    "    # Ensure both GeoDataFrames have valid geometries and are in the same CRS.\n",
    "    # We reprojected cota_stops_gdf to EPSG:3735 already.\n",
    "    # final_census_gdf has geometry from the tracts shapefile, which was also reprojected.\n",
    "    if cota_stops_gdf.crs != final_census_gdf.crs:\n",
    "        print(f\"Warning: CRSs do not match! COTA: {cota_stops_gdf.crs}, Census: {final_census_gdf.crs}\")\n",
    "        print(\"Attempting to reproject COTA stops to match Census CRS (EPSG:3735).\")\n",
    "        cota_stops_gdf = cota_stops_gdf.to_crs(final_census_gdf.crs).copy()\n",
    "    \n",
    "    # Fix invalid geometries if any (though usually not an issue with points/simple polygons)\n",
    "    if not cota_stops_gdf.geometry.is_valid.all():\n",
    "        cota_stops_gdf.geometry = cota_stops_gdf.geometry.buffer(0)\n",
    "        print(\"Fixed invalid geometries in cota_stops_gdf.\")\n",
    "    if not final_census_gdf.geometry.is_valid.all():\n",
    "        final_census_gdf.geometry = final_census_gdf.geometry.buffer(0)\n",
    "        print(\"Fixed invalid geometries in final_census_gdf.\")\n",
    "\n",
    "    # Perform a spatial join (sjoin) to find which Census Tract each COTA stop falls within.\n",
    "    # 'op=\"within\"' means the stop's geometry must be entirely within the tract's geometry.\n",
    "    # 'how=\"left\"' keeps all COTA stops and adds Census Tract data where they fall within a tract.\n",
    "    \n",
    "    # Before join, rename 'geo_id' in final_census_gdf for clarity after join\n",
    "    # It will become index_right, then the actual geo_id from Census will be added\n",
    "    # No, it's better to keep geo_id from final_census_gdf\n",
    "    \n",
    "    # The left dataframe (stops) will retain its columns. The right (census) will add its.\n",
    "    # We might have duplicate column names if not careful (e.g., 'geographic_area_name').\n",
    "    # Let's ensure the census_for_join_gdf has 'geo_id' and 'geographic_area_name' and the rest of census data.\n",
    "    # It already does (final_census_gdf has everything).\n",
    "\n",
    "    cota_stops_with_tracts_gdf = gpd.sjoin(\n",
    "        cota_stops_gdf, \n",
    "        final_census_gdf[['geo_id', 'tract_name', 'geometry'] + [col for col in final_census_gdf.columns if col not in ['geo_id', 'tract_name', 'geometry']]],\n",
    "        how=\"left\", \n",
    "        predicate=\"within\" # A stop should be *within* a tract.\n",
    "    )\n",
    "    print(\"Spatial join of COTA Stops with Census Tracts complete.\")\n",
    "    print(f\"Initial COTA Stops: {len(cota_stops_gdf)}. Joined COTA Stops: {len(cota_stops_with_tracts_gdf)}\")\n",
    "\n",
    "    # Check for missing values introduced by the spatial join (stops outside any tract)\n",
    "    missing_after_sjoin_stops = cota_stops_with_tracts_gdf.isnull().sum()\n",
    "    if missing_after_sjoin_stops.any():\n",
    "        print(\"\\nWarning: Missing values detected after spatial join (some COTA stops might not fall within a Census Tract).\")\n",
    "        print(missing_after_sjoin_stops[missing_after_sjoin_stops > 0])\n",
    "        # Fill numerical NaNs with 0 and object NaNs with 'Unknown'.\n",
    "        for col in cota_stops_with_tracts_gdf.columns:\n",
    "            if cota_stops_with_tracts_gdf[col].dtype in ['int64', 'float64', 'int32']:\n",
    "                cota_stops_with_tracts_gdf[col] = cota_stops_with_tracts_gdf[col].fillna(0)\n",
    "            elif cota_stops_with_tracts_gdf[col].dtype == 'object' and col != 'stop_id': # Exclude stop_id itself\n",
    "                cota_stops_with_tracts_gdf[col] = cota_stops_with_tracts_gdf[col].fillna('Unknown')\n",
    "        print(\"Filled missing values introduced by spatial join.\")\n",
    "\n",
    "    print(\"\\n--- COTA Bus Stops Enriched with Census Data ---\")\n",
    "    print(\"COTA Bus Stops with Census Data GeoDataFrame Info:\")\n",
    "    print(cota_stops_with_tracts_gdf.info())\n",
    "    print(\"\\nCOTA Bus Stops with Census Data Head:\")\n",
    "    print(cota_stops_with_tracts_gdf.head())\n",
    "\n",
    "else:\n",
    "    print(\"One or both GeoDataFrames not loaded for spatial join. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c7120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Spatially Join Columbus Building Permits with TAZs and Aggregate ---\n",
    "print(\"\\n--- Spatially Joining Building Permits with TAZs and Aggregating ---\")\n",
    "\n",
    "if columbus_permits_cleaned_gdf is not None and taz_with_census_gdf is not None:\n",
    "    # Ensure both GeoDataFrames are in the same CRS (EPSG:3735).\n",
    "    # columbus_permits_cleaned_gdf was reprojected in its cleaning step to 3735.\n",
    "    # taz_with_census_gdf is also in 3735.\n",
    "    if columbus_permits_cleaned_gdf.crs != taz_with_census_gdf.crs:\n",
    "        print(f\"Warning: CRSs do not match for permits/TAZ! Permits: {columbus_permits_cleaned_gdf.crs}, TAZ: {taz_with_census_gdf.crs}\")\n",
    "        print(\"Attempting to reproject Building Permits to match TAZ CRS (EPSG:3735).\")\n",
    "        columbus_permits_cleaned_gdf = columbus_permits_cleaned_gdf.to_crs(taz_with_census_gdf.crs).copy()\n",
    "    \n",
    "    # Ensure geometries are valid before joining\n",
    "    if not columbus_permits_cleaned_gdf.geometry.is_valid.all():\n",
    "        columbus_permits_cleaned_gdf.geometry = columbus_permits_cleaned_gdf.geometry.buffer(0)\n",
    "        print(\"Fixed invalid geometries in columbus_permits_cleaned_gdf.\")\n",
    "    if not taz_with_census_gdf.geometry.is_valid.all():\n",
    "        taz_with_census_gdf.geometry = taz_with_census_gdf.geometry.buffer(0)\n",
    "        print(\"Fixed invalid geometries in taz_with_census_gdf.\")\n",
    "\n",
    "    # Perform a spatial join (sjoin) to find which TAZ each permit falls within.\n",
    "    # 'predicate=\"within\"' means the permit's point geometry must be entirely within the TAZ's polygon.\n",
    "    # 'how=\"left\"' keeps all permits and adds the TAZ_ID they fall into.\n",
    "    permits_with_taz_gdf = gpd.sjoin(\n",
    "        columbus_permits_cleaned_gdf, \n",
    "        taz_with_census_gdf[['taz_id', 'geometry']], # Only need TAZ_ID and geometry from TAZs for the join\n",
    "        how=\"left\", \n",
    "        predicate=\"within\"\n",
    "    )\n",
    "    print(\"Spatial join of Building Permits with TAZs complete.\")\n",
    "    print(f\"Initial Permits: {len(columbus_permits_cleaned_gdf)}. Joined Permits: {len(permits_with_taz_gdf)}\")\n",
    "\n",
    "    # Handle permits that might not fall within any TAZ (resulting in NaN for taz_id)\n",
    "    missing_taz_for_permits = permits_with_taz_gdf['taz_id'].isnull().sum()\n",
    "    if missing_taz_for_permits > 0:\n",
    "        print(f\"Warning: {missing_taz_for_permits} Building Permits did not fall within any TAZ.\")\n",
    "        # For permits not in a TAZ, we can either drop them or assign 'Unknown' to taz_id.\n",
    "        # For aggregation, it's often best to drop them if they are truly outside the study area.\n",
    "        permits_with_taz_gdf = permits_with_taz_gdf.dropna(subset=['taz_id']).copy()\n",
    "        print(f\"Dropped {missing_taz_for_permits} permits that did not fall within a TAZ. Remaining permits: {len(permits_with_taz_gdf)}.\")\n",
    "    \n",
    "    # 2. Aggregate Permit Data by TAZ\n",
    "    # We want to count permits, sum declared values, sum units per TAZ.\n",
    "    # Ensure numerical columns are correctly handled for aggregation (fillna 0 if any NaNs exist)\n",
    "    agg_permits_by_taz = permits_with_taz_gdf.groupby('taz_id').agg(\n",
    "        total_permits_count=('permit_id', 'count'),\n",
    "        total_declared_value=('declared_value', 'sum'),\n",
    "        total_square_footage=('square_footage', 'sum'),\n",
    "        total_units_added=('num_units', 'sum')\n",
    "    ).reset_index()\n",
    "    print(\"Building Permits aggregated by TAZ.\")\n",
    "\n",
    "    # Convert taz_id in aggregated dataframe to string for merging (if not already)\n",
    "    agg_permits_by_taz['taz_id'] = agg_permits_by_taz['taz_id'].astype(str)\n",
    "\n",
    "    # 3. Merge aggregated permit data back into taz_with_census_gdf\n",
    "    # This will add the permit summary statistics to each TAZ.\n",
    "    initial_taz_cols = taz_with_census_gdf.shape[1]\n",
    "    taz_with_all_data_gdf = pd.merge(\n",
    "        taz_with_census_gdf, \n",
    "        agg_permits_by_taz, \n",
    "        on='taz_id', \n",
    "        how='left' # Keep all TAZs, even if they have no permits\n",
    "    )\n",
    "    final_taz_cols = taz_with_all_data_gdf.shape[1]\n",
    "    \n",
    "    print(f\"Aggregated permit data merged into TAZs. Added {final_taz_cols - initial_taz_cols} columns.\")\n",
    "    \n",
    "    # Fill NaN values introduced by the merge (TAZs with no permits will have NaN for permit counts/sums)\n",
    "    for col in agg_permits_by_taz.columns:\n",
    "        if col != 'taz_id' and taz_with_all_data_gdf[col].isnull().any():\n",
    "            taz_with_all_data_gdf[col] = taz_with_all_data_gdf[col].fillna(0)\n",
    "    print(\"Filled NaNs for TAZs with no permits.\")\n",
    "\n",
    "    print(\"\\n--- TAZs Enriched with All Data (Census + Permits) ---\")\n",
    "    print(\"Final TAZs GeoDataFrame Info:\")\n",
    "    print(taz_with_all_data_gdf.info())\n",
    "    print(\"\\nFinal TAZs GeoDataFrame Head:\")\n",
    "    print(taz_with_all_data_gdf.head())\n",
    "    print(\"\\nFinal TAZs GeoDataFrame Tail:\")\n",
    "    print(taz_with_all_data_gdf.tail())\n",
    "\n",
    "else:\n",
    "    print(\"One or both GeoDataFrames not loaded for spatial join/aggregation. Skipping.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cota_transit_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
